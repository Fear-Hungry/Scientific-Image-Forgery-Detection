{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9244e37a",
   "metadata": {},
   "source": [
    "# Pipeline único — Fases 1→4 (Kaggle / Offline)\n",
    "\n",
    "Este notebook junta tudo em um só lugar:\n",
    "\n",
    "1) **Setup offline + checagens**\n",
    "2) **Treino do classificador** (authentic vs forged) *(opcional)*\n",
    "3) **Treino do segmentador** (máscara de duplicação) *(opcional)*\n",
    "4) **Inferência + submissão** (`submission.csv`)\n",
    "\n",
    "## Regras / Decisões\n",
    "- Importa código do projeto em `src/forgeryseg/` (modularizado).\n",
    "- Compatível com Kaggle **internet OFF** (instala wheels locais se existirem).\n",
    "- Não esconde erros: exceções e tracebacks aparecem.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85807d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 1: Sanidade Kaggle (lembrete)\n",
    "print(\"Kaggle submission constraints (lembrete):\")\n",
    "print(\"- Submissions via Notebook\")\n",
    "print(\"- Runtime <= 4h (CPU/GPU)\")\n",
    "print(\"- Internet: OFF no submit\")\n",
    "print(\"- Output: /kaggle/working/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca341a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 2: Imports + ambiente\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import traceback\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "warnings.simplefilter(\"default\")\n",
    "os.environ.setdefault(\"NO_ALBUMENTATIONS_UPDATE\", \"1\")\n",
    "\n",
    "\n",
    "def is_kaggle() -> bool:\n",
    "    return bool(os.environ.get(\"KAGGLE_URL_BASE\")) or Path(\"/kaggle\").exists()\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(\"python:\", sys.version.split()[0])\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "print(\"device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cead31",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 2b: Instalação offline (wheels) — NÃO resolve deps\n",
    "#\n",
    "# Estruturas suportadas:\n",
    "# - `/kaggle/input/<dataset>/wheels/*.whl`\n",
    "# - `/kaggle/input/<dataset>/recodai_bundle/wheels/*.whl`\n",
    "#\n",
    "# Observação: instalamos com `--no-deps` para não tentar instalar dependências do torch offline.\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def _find_offline_bundle() -> Path | None:\n",
    "    if not is_kaggle():\n",
    "        return None\n",
    "    kaggle_input = Path(\"/kaggle/input\")\n",
    "    if not kaggle_input.exists():\n",
    "        return None\n",
    "\n",
    "    candidates: list[Path] = []\n",
    "    for ds in sorted(kaggle_input.glob(\"*\")):\n",
    "        for base in (ds, ds / \"recodai_bundle\"):\n",
    "            if (base / \"wheels\").exists():\n",
    "                candidates.append(base)\n",
    "\n",
    "    if not candidates:\n",
    "        return None\n",
    "    if len(candidates) > 1:\n",
    "        print(\"[OFFLINE INSTALL] múltiplos bundles com wheels encontrados; usando o primeiro:\")\n",
    "        for c in candidates:\n",
    "            print(\" -\", c)\n",
    "    return candidates[0]\n",
    "\n",
    "\n",
    "def _candidate_python_roots(base: Path) -> list[Path]:\n",
    "    roots = [\n",
    "        base,\n",
    "        base / \"src\",\n",
    "        base / \"vendor\",\n",
    "        base / \"third_party\",\n",
    "        base / \"recodai_bundle\",\n",
    "        base / \"recodai_bundle\" / \"src\",\n",
    "        base / \"recodai_bundle\" / \"vendor\",\n",
    "        base / \"recodai_bundle\" / \"third_party\",\n",
    "    ]\n",
    "    return [r for r in roots if r.exists()]\n",
    "\n",
    "\n",
    "def add_local_package_to_syspath(package_dir_name: str) -> list[Path]:\n",
    "    \"\"\"\n",
    "    Procura por `package_dir_name/__init__.py` em `/kaggle/input/*` e adiciona o root correspondente ao `sys.path`.\n",
    "\n",
    "    Nota: não excluímos o dataset da competição, pois alguns usuários empacotam o código junto com os dados\n",
    "    em um único Kaggle Dataset. A busca é rasa (não percorre imagens), então o custo é baixo.\n",
    "    \"\"\"\n",
    "    added: list[Path] = []\n",
    "    if not is_kaggle():\n",
    "        return added\n",
    "\n",
    "    kaggle_input = Path(\"/kaggle/input\")\n",
    "    if not kaggle_input.exists():\n",
    "        return added\n",
    "\n",
    "    for ds in sorted(kaggle_input.glob(\"*\")):\n",
    "        for root in _candidate_python_roots(ds):\n",
    "            pkg = root / package_dir_name\n",
    "            if (pkg / \"__init__.py\").exists():\n",
    "                if str(root) not in sys.path:\n",
    "                    sys.path.insert(0, str(root))\n",
    "                    added.append(root)\n",
    "                continue\n",
    "            try:\n",
    "                for child in sorted(p for p in root.glob(\"*\") if p.is_dir()):\n",
    "                    pkg2 = child / package_dir_name\n",
    "                    if (pkg2 / \"__init__.py\").exists():\n",
    "                        if str(child) not in sys.path:\n",
    "                            sys.path.insert(0, str(child))\n",
    "                            added.append(child)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    if added:\n",
    "        uniq = []\n",
    "        for p in added:\n",
    "            if p not in uniq:\n",
    "                uniq.append(p)\n",
    "        print(f\"[LOCAL IMPORT] adicionado ao sys.path para '{package_dir_name}':\")\n",
    "        for p in uniq[:10]:\n",
    "            print(\" -\", p)\n",
    "        if len(uniq) > 10:\n",
    "            print(\" ...\")\n",
    "        return uniq\n",
    "\n",
    "    print(f\"[LOCAL IMPORT] não encontrei '{package_dir_name}/__init__.py' em `/kaggle/input/*`.\")\n",
    "    return added\n",
    "\n",
    "\n",
    "OFFLINE_BUNDLE = _find_offline_bundle()\n",
    "if OFFLINE_BUNDLE is None:\n",
    "    print(\"[OFFLINE INSTALL] nenhum bundle com `wheels/` encontrado em `/kaggle/input`.\")\n",
    "else:\n",
    "    wheel_dir = OFFLINE_BUNDLE / \"wheels\"\n",
    "    whls = sorted(str(p) for p in wheel_dir.glob(\"*.whl\"))\n",
    "    print(\"[OFFLINE INSTALL] bundle:\", OFFLINE_BUNDLE)\n",
    "    print(\"[OFFLINE INSTALL] wheels:\", len(whls))\n",
    "    if not whls:\n",
    "        print(\"[OFFLINE INSTALL] aviso: diretório `wheels/` existe mas não há `.whl`.\")\n",
    "    else:\n",
    "        cmd = [\n",
    "            sys.executable,\n",
    "            \"-m\",\n",
    "            \"pip\",\n",
    "            \"install\",\n",
    "            \"--no-index\",\n",
    "            \"--find-links\",\n",
    "            str(wheel_dir),\n",
    "            \"--no-deps\",\n",
    "            *whls,\n",
    "        ]\n",
    "        print(\"[OFFLINE INSTALL] executando:\", \" \".join(cmd[:9]), \"...\", f\"(+{len(whls)} wheels)\")\n",
    "        subprocess.check_call(cmd)\n",
    "        print(\"[OFFLINE INSTALL] OK.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef2b444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 2c: Import do projeto (src/forgeryseg)\n",
    "\n",
    "def _maybe_add_src_to_syspath(src_root: Path) -> bool:\n",
    "    if (src_root / \"forgeryseg\" / \"__init__.py\").exists() and str(src_root) not in sys.path:\n",
    "        sys.path.insert(0, str(src_root))\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "try:\n",
    "    import forgeryseg  # type: ignore\n",
    "except Exception:\n",
    "    _maybe_add_src_to_syspath(Path(\"src\").resolve())\n",
    "    if is_kaggle():\n",
    "        add_local_package_to_syspath(\"forgeryseg\")\n",
    "    import forgeryseg  # type: ignore\n",
    "\n",
    "FORGERYSEG_FILE = Path(forgeryseg.__file__).resolve()\n",
    "print(\"forgeryseg:\", FORGERYSEG_FILE)\n",
    "\n",
    "PROJECT_ROOT: Path | None = None\n",
    "try:\n",
    "    if FORGERYSEG_FILE.parent.name == \"forgeryseg\" and FORGERYSEG_FILE.parent.parent.name == \"src\":\n",
    "        PROJECT_ROOT = FORGERYSEG_FILE.parents[2]\n",
    "except Exception:\n",
    "    PROJECT_ROOT = None\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset  # noqa: E402\n",
    "\n",
    "from forgeryseg.augment import get_train_augment, get_val_augment  # noqa: E402\n",
    "from forgeryseg.checkpoints import build_classifier_from_config, build_segmentation_from_config, load_checkpoint  # noqa: E402\n",
    "from forgeryseg.constants import AUTHENTIC_LABEL  # noqa: E402\n",
    "from forgeryseg.data_analysis import quick_dataset_stats  # noqa: E402\n",
    "from forgeryseg.dataset import PatchDataset, build_test_index, build_train_index, load_image  # noqa: E402\n",
    "from forgeryseg.inference import normalize_image, predict_image  # noqa: E402\n",
    "from forgeryseg.losses import BCETverskyLoss  # noqa: E402\n",
    "from forgeryseg.models import builders  # noqa: E402\n",
    "from forgeryseg.models.classifier import build_classifier, compute_pos_weight  # noqa: E402\n",
    "from forgeryseg.offline import configure_cache_dirs  # noqa: E402\n",
    "from forgeryseg.postprocess import binarize, extract_components  # noqa: E402\n",
    "from forgeryseg.rle import encode_instances  # noqa: E402\n",
    "from forgeryseg.train import train_one_epoch, validate  # noqa: E402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a95d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 2d: Cache dirs (offline weights)\n",
    "#\n",
    "# Para usar pesos pré-treinados no Kaggle com internet OFF, anexe um Dataset contendo caches e aponte aqui.\n",
    "# Exemplo de estrutura sugerida:\n",
    "# - <CACHE_ROOT>/torch  (TORCH_HOME)\n",
    "# - <CACHE_ROOT>/hf     (HF_HOME)\n",
    "CACHE_ROOT = os.environ.get(\"FORGERYSEG_CACHE_ROOT\", \"\")\n",
    "if CACHE_ROOT:\n",
    "    configure_cache_dirs(CACHE_ROOT)\n",
    "    print(\"[CACHE] FORGERYSEG_CACHE_ROOT:\", CACHE_ROOT)\n",
    "else:\n",
    "    print(\"[CACHE] FORGERYSEG_CACHE_ROOT vazio (seguindo sem caches).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e063b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 3: Dataset root + contagens\n",
    "\n",
    "\n",
    "def find_dataset_root() -> Path:\n",
    "    def _looks_like_root(p: Path) -> bool:\n",
    "        return (p / \"train_images\").exists() and (p / \"test_images\").exists()\n",
    "\n",
    "    if is_kaggle():\n",
    "        base = Path(\"/kaggle/input/recodai-luc-scientific-image-forgery-detection\")\n",
    "        if _looks_like_root(base):\n",
    "            return base\n",
    "        kaggle_input = Path(\"/kaggle/input\")\n",
    "        if kaggle_input.exists():\n",
    "            for ds in sorted(kaggle_input.glob(\"*\")):\n",
    "                if _looks_like_root(ds):\n",
    "                    return ds\n",
    "\n",
    "    local_candidates = [\n",
    "        Path(\"data/recodai\").resolve(),\n",
    "        Path(\"data\").resolve(),\n",
    "    ]\n",
    "    for cand in local_candidates:\n",
    "        if _looks_like_root(cand):\n",
    "            return cand\n",
    "\n",
    "    raise FileNotFoundError(\"Dataset não encontrado. No Kaggle: anexe o dataset da competição.\")\n",
    "\n",
    "\n",
    "DATA_ROOT = find_dataset_root()\n",
    "train_samples = build_train_index(DATA_ROOT, strict=False)\n",
    "train_labels = np.array([0 if s.is_authentic else 1 for s in train_samples], dtype=np.int64)\n",
    "test_samples = build_test_index(DATA_ROOT)\n",
    "\n",
    "print(\"DATA_ROOT:\", DATA_ROOT)\n",
    "print(\"train samples:\", len(train_samples), \"auth:\", int((train_labels == 0).sum()), \"forged:\", int((train_labels == 1).sum()))\n",
    "print(\"test samples:\", len(test_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3138fd02",
   "metadata": {},
   "source": [
    "## Análise dos Dados e Pré-processamento\n",
    "\n",
    "Antes de treinar modelos, fazemos uma exploração rápida do dataset:\n",
    "\n",
    "- Cada imagem tem um identificador único (`case_id` = nome do arquivo).\n",
    "- No treino, existem dois grupos: **authentic** e **forged**.\n",
    "- Para imagens **forged**, há uma máscara em `train_masks/<case_id>.npy` indicando pixels duplicados\n",
    "  (pode vir como máscara binária 2D ou como múltiplas instâncias 3D).\n",
    "- Para segmentação, montamos pares (**imagem**, **máscara-union**). Para imagens autênticas, a máscara é toda zero.\n",
    "- Para classificação, usamos rótulo binário: `0=authentic`, `1=forged`.\n",
    "\n",
    "### Dimensionamento e formato\n",
    "\n",
    "- As imagens têm tamanhos variados e podem ser coloridas ou em escala de cinza. Padronizamos a leitura para **3 canais RGB**\n",
    "  (via `PIL.Image.convert(\"RGB\")`, usado em `forgeryseg.dataset.load_image`).\n",
    "- Para segmentação, em vez de redimensionar agressivamente a imagem inteira, trabalhamos com **patches de tamanho fixo**\n",
    "  (`SEG_PATCH_SIZE`, ex.: 384/512) usando **padding + crop** durante o treino. Isso preserva detalhes finos de falsificações pequenas.\n",
    "- Em inferência, usamos **tiling** (`TILE_SIZE`/`OVERLAP`) para lidar com imagens grandes sem perder resolução.\n",
    "\n",
    "### Normalização\n",
    "\n",
    "- Aplicamos **normalização padronizada por canal** (médias/desvios do ImageNet) para manter a escala esperada pelos modelos\n",
    "  — especialmente útil com backbones pré-treinados.\n",
    "- Existe variação de contraste entre artigos/figuras; equalização/normalização por imagem pode ajudar, mas pode também\n",
    "  alterar evidências sutis. Preferimos manter o pré-processamento **mínimo** e ganhar robustez com augmentations.\n",
    "\n",
    "### Divisão de dados (validação local)\n",
    "\n",
    "- A competição avalia no **test set oculto**; para desenvolvimento usamos validação local a partir do treino.\n",
    "- Usamos **5-fold estratificado** (authentic vs forged) para melhor uso dos dados e para reduzir overfitting.\n",
    "- Na inferência, carregamos todos os checkpoints encontrados e fazemos **ensemble** (média das probabilidades).\n",
    "\n",
    "### Data augmentation (aumento de dados)\n",
    "\n",
    "`forgeryseg.augment.get_train_augment(...)` aplica (imagem + máscara) transforms geométricos e (só na imagem) transforms\n",
    "fotométricos para robustez:\n",
    "\n",
    "- Flips/rotações (`HorizontalFlip`, `VerticalFlip`, `RandomRotate90`)\n",
    "- Affine/escala (`Affine`, `RandomResizedCrop` quando `patch_size` é definido)\n",
    "- Ruído/desfoque (`GaussNoise`, `GaussianBlur`, `MotionBlur`)\n",
    "- Brilho/contraste/CLAHE (`RandomBrightnessContrast`, `RandomGamma`, `CLAHE`)\n",
    "- Copy-move sintético (custom `CopyMoveTransform`) para gerar falsificações on-the-fly em máscaras vazias\n",
    "\n",
    "### Modelo de classificação (forged vs authentic)\n",
    "\n",
    "Classificador opcional para (1) sinal global “tem fraude?” e (2) economizar tempo:\n",
    "\n",
    "- CNN pré-treinada (ex.: EfficientNet via `timm`) com saída binária (`num_classes=1`).\n",
    "- Loss: `BCEWithLogitsLoss` com `pos_weight`.\n",
    "- Inferência: se `p_forged < CLS_SKIP_THRESHOLD`, rotulamos como `AUTHENTIC_LABEL` e pulamos a segmentação.\n",
    "\n",
    "### Modelo de segmentação (localização)\n",
    "\n",
    "Segmentação prevê logits (1 canal); aplicamos **sigmóide** para probabilidades. O pipeline suporta ensemble heterogêneo:\n",
    "\n",
    "- **U-Net++** (detalhe fino) + **DeepLabV3+** (contexto multi-escala) + opcional **SegFormer** (atenção global).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bed8d02",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 3b: Stats rápidos (tamanho / canais / máscaras)\n",
    "RUN_DATA_ANALYSIS = not is_kaggle()\n",
    "ANALYSIS_MAX_ITEMS = 200\n",
    "\n",
    "if RUN_DATA_ANALYSIS:\n",
    "    quick_dataset_stats(train_samples, max_items=ANALYSIS_MAX_ITEMS, seed=SEED, name=\"train\")\n",
    "    quick_dataset_stats(test_samples, max_items=ANALYSIS_MAX_ITEMS, seed=SEED, name=\"test\")\n",
    "else:\n",
    "    print(\"[DATA] RUN_DATA_ANALYSIS=False (pulando).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f77838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 4: Config global (liga/desliga)\n",
    "def _has_any_ckpt(dir_name: str, pattern: str) -> bool:\n",
    "    # Procura primeiro em /kaggle/input (datasets anexados), depois em outputs/ local.\n",
    "    if is_kaggle():\n",
    "        ki = Path(\"/kaggle/input\")\n",
    "        if ki.exists():\n",
    "            for ds in sorted(ki.glob(\"*\")):\n",
    "                for base in (ds, ds / \"recodai_bundle\"):\n",
    "                    cand = base / \"outputs\" / dir_name\n",
    "                    if cand.exists():\n",
    "                        if any(cand.glob(pattern)):\n",
    "                            return True\n",
    "    local = (Path(\"/kaggle/working\") if is_kaggle() else Path(\".\").resolve()) / \"outputs\" / dir_name\n",
    "    return local.exists() and any(local.glob(pattern))\n",
    "\n",
    "\n",
    "HAS_SEG_CKPT = _has_any_ckpt(\"models_seg\", \"*/*/best.pt\")\n",
    "HAS_CLS_CKPT = _has_any_ckpt(\"models_cls\", \"fold_*/best.pt\")\n",
    "\n",
    "# Utils\n",
    "def _env_bool(name: str, default: bool) -> bool:\n",
    "    v = os.environ.get(name, \"\")\n",
    "    if v == \"\":\n",
    "        return bool(default)\n",
    "    return str(v).strip().lower() in {\"1\", \"true\", \"yes\", \"y\", \"on\"}\n",
    "\n",
    "\n",
    "# Modos:\n",
    "# - \"infer_only\": só inferência (exige checkpoints anexados)\n",
    "# - \"train_then_infer\": força treino antes da submissão\n",
    "# - \"auto\": se não houver checkpoints, treina o mínimo para conseguir gerar `submission.csv`\n",
    "_default_pipeline_mode = \"train_then_infer\" if is_kaggle() else \"auto\"\n",
    "PIPELINE_MODE = os.environ.get(\"FORGERYSEG_PIPELINE_MODE\", _default_pipeline_mode).strip().lower()\n",
    "\n",
    "# Defaults \"rodáveis\": por padrão, no Kaggle tentamos gerar `submission.csv` sem intervenção manual.\n",
    "# (Você pode sobrescrever manualmente aqui.)\n",
    "RUN_TRAIN_CLS = False\n",
    "if PIPELINE_MODE == \"infer_only\":\n",
    "    RUN_TRAIN_SEG = False\n",
    "elif PIPELINE_MODE == \"train_then_infer\":\n",
    "    RUN_TRAIN_SEG = True\n",
    "else:\n",
    "    RUN_TRAIN_SEG = not HAS_SEG_CKPT\n",
    "RUN_SUBMISSION = True\n",
    "\n",
    "N_FOLDS = 5\n",
    "FOLD = 0\n",
    "\n",
    "FAST_TRAIN = _env_bool(\"FORGERYSEG_FAST_TRAIN\", default=bool(is_kaggle() and not HAS_SEG_CKPT))\n",
    "\n",
    "print(\"PIPELINE_MODE:\", PIPELINE_MODE)\n",
    "print(\"FAST_TRAIN:\", FAST_TRAIN)\n",
    "print(\"RUN_TRAIN_CLS:\", RUN_TRAIN_CLS)\n",
    "print(\"RUN_TRAIN_SEG:\", RUN_TRAIN_SEG)\n",
    "print(\"RUN_SUBMISSION:\", RUN_SUBMISSION)\n",
    "print(\"HAS_SEG_CKPT:\", HAS_SEG_CKPT)\n",
    "print(\"HAS_CLS_CKPT:\", HAS_CLS_CKPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbc9f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 2 — Célula 5: Split (folds)\n",
    "try:\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "    folds = np.zeros(len(train_samples), dtype=np.int64)\n",
    "    for fold_id, (_, val_idx) in enumerate(skf.split(np.zeros(len(train_samples)), train_labels)):\n",
    "        folds[val_idx] = int(fold_id)\n",
    "except Exception:\n",
    "    print(\"[ERRO] scikit-learn falhou (StratifiedKFold). Usando split simples.\")\n",
    "    traceback.print_exc()\n",
    "    folds = np.arange(len(train_samples), dtype=np.int64) % int(N_FOLDS)\n",
    "\n",
    "train_idx = np.where(folds != int(FOLD))[0]\n",
    "val_idx = np.where(folds == int(FOLD))[0]\n",
    "print(f\"fold={FOLD}: train={len(train_idx)} val={len(val_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af713196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 2 — Célula 6: Treino do classificador (opcional)\n",
    "try:\n",
    "    import torchvision.transforms as T\n",
    "except Exception:\n",
    "    print(\"[ERRO] torchvision falhou no import.\")\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except Exception:\n",
    "    print(\"[WARN] tqdm indisponível; usando loop simples.\")\n",
    "\n",
    "    def tqdm(x, **kwargs):  # type: ignore\n",
    "        return x\n",
    "\n",
    "\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "CLS_MODEL_NAME = \"tf_efficientnet_b4_ns\"\n",
    "CLS_IMAGE_SIZE = 384\n",
    "CLS_BATCH_SIZE = 32\n",
    "CLS_EPOCHS = 10\n",
    "CLS_PATIENCE = 3\n",
    "CLS_LR = 3e-4\n",
    "CLS_WEIGHT_DECAY = 1e-2\n",
    "# Preferir recall (evitar falsos negativos): só pule a segmentação quando tiver alta confiança de autenticidade.\n",
    "CLS_SKIP_THRESHOLD = 0.10\n",
    "# Pesos pré-treinados ajudam, mas no Kaggle com internet OFF podem não estar disponíveis.\n",
    "CLS_PRETRAINED = True\n",
    "\n",
    "\n",
    "def build_transform(train: bool) -> T.Compose:\n",
    "    aug = []\n",
    "    if train:\n",
    "        aug += [T.RandomHorizontalFlip(p=0.5), T.RandomVerticalFlip(p=0.5)]\n",
    "    aug += [\n",
    "        T.Resize((CLS_IMAGE_SIZE, CLS_IMAGE_SIZE)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "    ]\n",
    "    return T.Compose(aug)\n",
    "\n",
    "\n",
    "class ClsDataset(Dataset):\n",
    "    def __init__(self, samples, transform: T.Compose):\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        s = self.samples[int(idx)]\n",
    "        from PIL import Image\n",
    "\n",
    "        img = Image.open(s.image_path).convert(\"RGB\")\n",
    "        x = self.transform(img)\n",
    "        y = torch.tensor([0.0 if s.is_authentic else 1.0], dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "if RUN_TRAIN_CLS:\n",
    "    ds_cls_train = ClsDataset([train_samples[i] for i in train_idx.tolist()], build_transform(train=True))\n",
    "    ds_cls_val = ClsDataset([train_samples[i] for i in val_idx.tolist()], build_transform(train=False))\n",
    "\n",
    "    num_workers = 2 if is_kaggle() else 0\n",
    "    dl_cls_train = DataLoader(ds_cls_train, batch_size=CLS_BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=(DEVICE == \"cuda\"), drop_last=True)\n",
    "    dl_cls_val = DataLoader(ds_cls_val, batch_size=CLS_BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=(DEVICE == \"cuda\"), drop_last=False)\n",
    "\n",
    "    try:\n",
    "        cls_model = build_classifier(model_name=CLS_MODEL_NAME, pretrained=CLS_PRETRAINED, num_classes=1).to(DEVICE)\n",
    "    except Exception:\n",
    "        if CLS_PRETRAINED:\n",
    "            print(\"[CLS] falha ao carregar pesos pré-treinados; fallback para pretrained=False.\")\n",
    "            traceback.print_exc()\n",
    "            cls_model = build_classifier(model_name=CLS_MODEL_NAME, pretrained=False, num_classes=1).to(DEVICE)\n",
    "        else:\n",
    "            raise\n",
    "    pos_weight = torch.tensor(compute_pos_weight(train_labels[train_idx]), dtype=torch.float32, device=DEVICE)\n",
    "    cls_criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    cls_optimizer = torch.optim.AdamW(cls_model.parameters(), lr=CLS_LR, weight_decay=CLS_WEIGHT_DECAY)\n",
    "    cls_scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE == \"cuda\"))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def cls_eval() -> dict:\n",
    "        cls_model.eval()\n",
    "        losses = []\n",
    "        logits_all = []\n",
    "        y_all = []\n",
    "        for x, yb in tqdm(dl_cls_val, desc=\"cls val\", leave=False):\n",
    "            x = x.to(DEVICE, non_blocking=True)\n",
    "            yb = yb.to(DEVICE, non_blocking=True)\n",
    "            logits = cls_model(x).view(-1, 1)\n",
    "            loss = cls_criterion(logits, yb)\n",
    "            losses.append(float(loss.item()))\n",
    "            logits_all.append(logits.detach().cpu().numpy())\n",
    "            y_all.append(yb.detach().cpu().numpy())\n",
    "        logits_np = np.concatenate(logits_all, axis=0).reshape(-1)\n",
    "        y_np = np.concatenate(y_all, axis=0).reshape(-1)\n",
    "        probs = 1.0 / (1.0 + np.exp(-logits_np))\n",
    "        acc = float(((probs >= 0.5).astype(np.int64) == y_np.astype(np.int64)).mean())\n",
    "        out = {\"loss\": float(np.mean(losses)) if losses else float(\"nan\"), \"acc@0.5\": acc}\n",
    "        try:\n",
    "            from sklearn.metrics import roc_auc_score\n",
    "\n",
    "            out[\"auc\"] = float(roc_auc_score(y_np, probs))\n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "        return out\n",
    "\n",
    "    def cls_train_one_epoch() -> float:\n",
    "        cls_model.train()\n",
    "        losses = []\n",
    "        for x, yb in tqdm(dl_cls_train, desc=\"cls train\", leave=False):\n",
    "            x = x.to(DEVICE, non_blocking=True)\n",
    "            yb = yb.to(DEVICE, non_blocking=True)\n",
    "            cls_optimizer.zero_grad(set_to_none=True)\n",
    "            with torch.cuda.amp.autocast(enabled=(DEVICE == \"cuda\")):\n",
    "                logits = cls_model(x).view(-1, 1)\n",
    "                loss = cls_criterion(logits, yb)\n",
    "            cls_scaler.scale(loss).backward()\n",
    "            cls_scaler.step(cls_optimizer)\n",
    "            cls_scaler.update()\n",
    "            losses.append(float(loss.item()))\n",
    "        return float(np.mean(losses)) if losses else float(\"nan\")\n",
    "\n",
    "    def output_root() -> Path:\n",
    "        return Path(\"/kaggle/working\") if is_kaggle() else Path(\".\").resolve()\n",
    "\n",
    "    cls_save_dir = output_root() / \"outputs\" / \"models_cls\" / f\"fold_{int(FOLD)}\"\n",
    "    cls_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    cls_best_path = cls_save_dir / \"best.pt\"\n",
    "\n",
    "    best_score = -1.0\n",
    "    best_epoch = 0\n",
    "    for epoch in range(1, int(CLS_EPOCHS) + 1):\n",
    "        tr_loss = cls_train_one_epoch()\n",
    "        val = cls_eval()\n",
    "        score = float(val.get(\"auc\", -val[\"loss\"]))\n",
    "        print(f\"[CLS] epoch {epoch:02d}/{CLS_EPOCHS} | train_loss={tr_loss:.4f} | val={val}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_epoch = int(epoch)\n",
    "            ckpt = {\n",
    "                \"model_state\": cls_model.state_dict(),\n",
    "                \"config\": {\n",
    "                    \"backend\": \"timm\",\n",
    "                    \"model_name\": CLS_MODEL_NAME,\n",
    "                    \"image_size\": int(CLS_IMAGE_SIZE),\n",
    "                    \"pretrained\": bool(CLS_PRETRAINED),\n",
    "                    \"fold\": int(FOLD),\n",
    "                    \"seed\": int(SEED),\n",
    "                },\n",
    "                \"score\": float(best_score),\n",
    "            }\n",
    "            torch.save(ckpt, cls_best_path)\n",
    "            print(\"[CLS] saved best ->\", cls_best_path)\n",
    "        if CLS_PATIENCE and best_epoch and (int(epoch) - int(best_epoch) >= int(CLS_PATIENCE)):\n",
    "            print(f\"[CLS] early stopping: sem melhora por {CLS_PATIENCE} épocas (best_epoch={best_epoch}).\")\n",
    "            break\n",
    "\n",
    "    print(\"[CLS] done. best score:\", best_score)\n",
    "else:\n",
    "    print(\"[CLS] RUN_TRAIN_CLS=False (pulando).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e381289c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 3 — Célula 7: Treino de segmentação (opcional)\n",
    "SEG_PATCH_SIZE = 384\n",
    "SEG_COPY_MOVE_PROB = 0.20\n",
    "SEG_BATCH_SIZE = 8\n",
    "SEG_EPOCHS = 8\n",
    "SEG_LR = 1e-3\n",
    "SEG_WEIGHT_DECAY = 1e-2\n",
    "SEG_PATIENCE = 3\n",
    "# Pesos pré-treinados: preferível (offline via cache); fallback para None se falhar.\n",
    "SEG_ENCODER_WEIGHTS = \"imagenet\"\n",
    "\n",
    "# Para performance máxima, treine mais de uma arquitetura e faça ensemble na inferência.\n",
    "SEG_TRAIN_SPECS = [\n",
    "    # SMP Unet++ + timm Universal ConvNeXt (tu-convnext_*) está quebrado no SMP 0.5.x (gera convs com out_channels=0).\n",
    "    # Usamos Unet (ConvNeXt) como base estável.\n",
    "    {\"model_id\": \"unet_tu_convnext_small\", \"arch\": \"unet\", \"encoder_name\": \"tu-convnext_small\"},\n",
    "    {\"model_id\": \"deeplabv3p_tu_resnest101e\", \"arch\": \"deeplabv3plus\", \"encoder_name\": \"tu-resnest101e\"},\n",
    "    {\"model_id\": \"segformer_mit_b2\", \"arch\": \"segformer\", \"encoder_name\": \"mit_b2\"},\n",
    "]\n",
    "\n",
    "if FAST_TRAIN:\n",
    "    print(\"[SEG] FAST_TRAIN=True -> preset rápido (1 modelo / poucas épocas).\")\n",
    "    SEG_EPOCHS = min(int(SEG_EPOCHS), 2)\n",
    "    SEG_TRAIN_SPECS = [\n",
    "        {\"model_id\": \"unet_tu_convnext_small\", \"arch\": \"unet\", \"encoder_name\": \"tu-convnext_small\"},\n",
    "    ]\n",
    "\n",
    "if RUN_TRAIN_SEG:\n",
    "    train_aug = get_train_augment(patch_size=SEG_PATCH_SIZE, copy_move_prob=SEG_COPY_MOVE_PROB)\n",
    "    val_aug = get_val_augment()\n",
    "\n",
    "    ds_seg_train = PatchDataset([train_samples[i] for i in train_idx.tolist()], patch_size=SEG_PATCH_SIZE, train=True, augment=train_aug, positive_prob=0.7, seed=SEED)\n",
    "    ds_seg_val = PatchDataset([train_samples[i] for i in val_idx.tolist()], patch_size=SEG_PATCH_SIZE, train=False, augment=val_aug, seed=SEED)\n",
    "\n",
    "    num_workers = 2 if is_kaggle() else 0\n",
    "    dl_seg_train = DataLoader(ds_seg_train, batch_size=SEG_BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=(DEVICE == \"cuda\"), drop_last=True)\n",
    "    dl_seg_val = DataLoader(ds_seg_val, batch_size=SEG_BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=(DEVICE == \"cuda\"), drop_last=False)\n",
    "\n",
    "    def output_root() -> Path:\n",
    "        return Path(\"/kaggle/working\") if is_kaggle() else Path(\".\").resolve()\n",
    "\n",
    "    use_amp = (DEVICE == \"cuda\")\n",
    "\n",
    "    def build_seg_model(arch: str, encoder_name: str, encoder_weights: str | None) -> nn.Module:\n",
    "        arch = str(arch).lower()\n",
    "        if arch == \"unet\":\n",
    "            return builders.build_unet(\n",
    "                encoder_name=encoder_name,\n",
    "                encoder_weights=encoder_weights,\n",
    "                classes=1,\n",
    "                strict_weights=True,\n",
    "            )\n",
    "        if arch in {\"unetplusplus\", \"unetpp\"}:\n",
    "            return builders.build_unetplusplus(\n",
    "                encoder_name=encoder_name,\n",
    "                encoder_weights=encoder_weights,\n",
    "                classes=1,\n",
    "                strict_weights=True,\n",
    "            )\n",
    "        if arch in {\"deeplabv3plus\", \"deeplabv3+\", \"deeplabv3p\"}:\n",
    "            return builders.build_deeplabv3plus(\n",
    "                encoder_name=encoder_name,\n",
    "                encoder_weights=encoder_weights,\n",
    "                classes=1,\n",
    "                strict_weights=True,\n",
    "            )\n",
    "        if arch in {\"segformer\", \"mit\"}:\n",
    "            return builders.build_segformer(\n",
    "                encoder_name=encoder_name,\n",
    "                encoder_weights=encoder_weights,\n",
    "                classes=1,\n",
    "                strict_weights=True,\n",
    "            )\n",
    "        raise ValueError(f\"SEG arch inválida: {arch!r}\")\n",
    "\n",
    "    for spec in SEG_TRAIN_SPECS:\n",
    "        model_id = str(spec[\"model_id\"])\n",
    "        arch = str(spec.get(\"arch\", \"unetplusplus\"))\n",
    "        encoder_name = str(spec.get(\"encoder_name\", \"efficientnet-b4\"))\n",
    "        encoder_weights: str | None = spec.get(\"encoder_weights\", SEG_ENCODER_WEIGHTS)\n",
    "\n",
    "        try:\n",
    "            seg_model = build_seg_model(arch, encoder_name, encoder_weights).to(DEVICE)\n",
    "        except Exception:\n",
    "            if encoder_weights is not None:\n",
    "                print(f\"[SEG] falha ao carregar encoder_weights={encoder_weights!r}; fallback para None.\")\n",
    "                traceback.print_exc()\n",
    "                encoder_weights = None\n",
    "                seg_model = build_seg_model(arch, encoder_name, encoder_weights).to(DEVICE)\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        seg_criterion = BCETverskyLoss(alpha=0.7, beta=0.3, tversky_weight=1.0)\n",
    "        seg_optimizer = torch.optim.AdamW(seg_model.parameters(), lr=SEG_LR, weight_decay=SEG_WEIGHT_DECAY)\n",
    "\n",
    "        seg_save_dir = output_root() / \"outputs\" / \"models_seg\" / model_id / f\"fold_{int(FOLD)}\"\n",
    "        seg_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        seg_best_path = seg_save_dir / \"best.pt\"\n",
    "\n",
    "        best_dice = -1.0\n",
    "        best_epoch = 0\n",
    "        for epoch in range(1, int(SEG_EPOCHS) + 1):\n",
    "            tr = train_one_epoch(seg_model, dl_seg_train, seg_criterion, seg_optimizer, DEVICE, use_amp=use_amp, progress=True, desc=f\"seg train ({model_id})\")\n",
    "            val_stats, val_dice = validate(seg_model, dl_seg_val, seg_criterion, DEVICE, progress=True, desc=f\"seg val ({model_id})\")\n",
    "            print(f\"[SEG {model_id}] epoch {epoch:02d}/{SEG_EPOCHS} | train_loss={tr.loss:.4f} | val_loss={val_stats.loss:.4f} | dice@0.5={val_dice:.4f}\")\n",
    "            if float(val_dice) > best_dice:\n",
    "                best_dice = float(val_dice)\n",
    "                best_epoch = int(epoch)\n",
    "                ckpt = {\n",
    "                    \"model_state\": seg_model.state_dict(),\n",
    "                    \"config\": {\n",
    "                        \"backend\": \"smp\",\n",
    "                        \"arch\": arch,\n",
    "                        \"encoder_name\": encoder_name,\n",
    "                        \"encoder_weights\": encoder_weights,\n",
    "                        \"classes\": 1,\n",
    "                        \"model_id\": model_id,\n",
    "                        \"patch_size\": int(SEG_PATCH_SIZE),\n",
    "                        \"fold\": int(FOLD),\n",
    "                        \"seed\": int(SEED),\n",
    "                    },\n",
    "                    \"score\": float(best_dice),\n",
    "                }\n",
    "                torch.save(ckpt, seg_best_path)\n",
    "                print(\"[SEG] saved best ->\", seg_best_path)\n",
    "            if SEG_PATIENCE and best_epoch and (int(epoch) - int(best_epoch) >= int(SEG_PATIENCE)):\n",
    "                print(f\"[SEG {model_id}] early stopping: sem melhora por {SEG_PATIENCE} épocas (best_epoch={best_epoch}).\")\n",
    "                break\n",
    "\n",
    "        print(f\"[SEG {model_id}] done. best dice:\", best_dice)\n",
    "else:\n",
    "    print(\"[SEG] RUN_TRAIN_SEG=False (pulando).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2de5c0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Fase 4 — Célula 8: Carregar checkpoints (para inferência/submissão)\n",
    "\n",
    "\n",
    "def output_root() -> Path:\n",
    "    return Path(\"/kaggle/working\") if is_kaggle() else Path(\".\").resolve()\n",
    "\n",
    "\n",
    "def _find_models_dir(dir_name: str) -> Path | None:\n",
    "    if is_kaggle():\n",
    "        ki = Path(\"/kaggle/input\")\n",
    "        if ki.exists():\n",
    "            candidates = []\n",
    "            for ds in sorted(ki.glob(\"*\")):\n",
    "                for base in (ds, ds / \"recodai_bundle\"):\n",
    "                    cand = base / \"outputs\" / dir_name\n",
    "                    if cand.exists():\n",
    "                        candidates.append(cand)\n",
    "            if candidates:\n",
    "                if len(candidates) > 1:\n",
    "                    print(f\"[CKPT] múltiplos candidatos para outputs/{dir_name}; usando o primeiro:\")\n",
    "                    for c in candidates:\n",
    "                        print(\" -\", c)\n",
    "                return candidates[0]\n",
    "\n",
    "    local = output_root() / \"outputs\" / dir_name\n",
    "    if local.exists():\n",
    "        return local\n",
    "    return None\n",
    "\n",
    "\n",
    "MODELS_SEG_DIR = _find_models_dir(\"models_seg\")\n",
    "MODELS_CLS_DIR = _find_models_dir(\"models_cls\")\n",
    "print(\"MODELS_SEG_DIR:\", MODELS_SEG_DIR)\n",
    "print(\"MODELS_CLS_DIR:\", MODELS_CLS_DIR)\n",
    "\n",
    "SEG_MODELS: list[nn.Module] = []\n",
    "if MODELS_SEG_DIR is not None:\n",
    "    for ckpt_path in sorted(MODELS_SEG_DIR.glob(\"*/*/best.pt\")):\n",
    "        try:\n",
    "            state, cfg = load_checkpoint(ckpt_path)\n",
    "            m = build_segmentation_from_config(cfg)\n",
    "            m.load_state_dict(state)\n",
    "            m.to(DEVICE)\n",
    "            m.eval()\n",
    "            SEG_MODELS.append(m)\n",
    "        except Exception:\n",
    "            print(\"[ERRO] falha ao carregar seg:\", ckpt_path)\n",
    "            traceback.print_exc()\n",
    "\n",
    "CLS_MODELS: list[nn.Module] = []\n",
    "CLS_INFER_IMAGE_SIZE = CLS_IMAGE_SIZE\n",
    "if MODELS_CLS_DIR is not None:\n",
    "    for ckpt_path in sorted(MODELS_CLS_DIR.glob(\"fold_*/best.pt\")):\n",
    "        try:\n",
    "            state, cfg = load_checkpoint(ckpt_path)\n",
    "            m, image_size = build_classifier_from_config(cfg)\n",
    "            CLS_INFER_IMAGE_SIZE = int(image_size)\n",
    "            m.load_state_dict(state)\n",
    "            m.to(DEVICE)\n",
    "            m.eval()\n",
    "            CLS_MODELS.append(m)\n",
    "        except Exception:\n",
    "            print(\"[ERRO] falha ao carregar cls:\", ckpt_path)\n",
    "            traceback.print_exc()\n",
    "\n",
    "print(\"loaded seg models:\", len(SEG_MODELS))\n",
    "print(\"loaded cls models:\", len(CLS_MODELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87cfb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 4 — Célula 9: Inferência + submission\n",
    "def _find_infer_cfg_path() -> Path | None:\n",
    "    candidates: list[Path] = []\n",
    "    if PROJECT_ROOT is not None:\n",
    "        candidates.append(PROJECT_ROOT / \"configs\" / \"infer_ensemble.json\")\n",
    "    candidates.append(Path(\"configs/infer_ensemble.json\").resolve())\n",
    "\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            return p\n",
    "\n",
    "    if is_kaggle():\n",
    "        kaggle_input = Path(\"/kaggle/input\")\n",
    "        if kaggle_input.exists():\n",
    "            for ds in sorted(kaggle_input.glob(\"*\")):\n",
    "                for base in (ds, ds / \"recodai_bundle\"):\n",
    "                    p = base / \"configs\" / \"infer_ensemble.json\"\n",
    "                    if p.exists():\n",
    "                        return p\n",
    "    return None\n",
    "\n",
    "\n",
    "INFER_CFG_PATH = _find_infer_cfg_path()\n",
    "INFER_CFG: dict = {}\n",
    "if INFER_CFG_PATH is not None:\n",
    "    with INFER_CFG_PATH.open(\"r\") as f:\n",
    "        INFER_CFG = json.load(f)\n",
    "    print(\"[INFER CFG] loaded:\", INFER_CFG_PATH)\n",
    "else:\n",
    "    print(\"[INFER CFG] configs/infer_ensemble.json não encontrado; usando defaults do notebook.\")\n",
    "\n",
    "TILE_SIZE = int(INFER_CFG.get(\"tile_size\", 1024))\n",
    "OVERLAP = int(INFER_CFG.get(\"overlap\", 128))\n",
    "MAX_SIZE = int(INFER_CFG.get(\"max_size\", 0))\n",
    "THRESHOLD = float(INFER_CFG.get(\"threshold\", 0.50))\n",
    "MIN_AREA = int(INFER_CFG.get(\"min_area\", 32))\n",
    "\n",
    "if isinstance(INFER_CFG.get(\"tta_modes\"), (list, tuple)):\n",
    "    TTA_MODES = tuple(str(x) for x in INFER_CFG.get(\"tta_modes\") if str(x).strip())\n",
    "else:\n",
    "    TTA_MODES = (\"none\", \"hflip\")\n",
    "\n",
    "USE_TTA = bool(TTA_MODES)\n",
    "if FAST_TRAIN:\n",
    "    USE_TTA = False\n",
    "\n",
    "CLS_SKIP_THRESHOLD = float(INFER_CFG.get(\"cls_skip_threshold\", CLS_SKIP_THRESHOLD))\n",
    "\n",
    "\n",
    "def _apply_tta(image: np.ndarray, mode: str) -> np.ndarray:\n",
    "    if mode == \"none\":\n",
    "        return image\n",
    "    if mode == \"hflip\":\n",
    "        return np.ascontiguousarray(image[:, ::-1])\n",
    "    if mode == \"vflip\":\n",
    "        return np.ascontiguousarray(image[::-1, :])\n",
    "    raise ValueError(f\"tta mode inválido: {mode}\")\n",
    "\n",
    "\n",
    "def _undo_tta(mask: np.ndarray, mode: str) -> np.ndarray:\n",
    "    if mode == \"none\":\n",
    "        return mask\n",
    "    if mode == \"hflip\":\n",
    "        return np.ascontiguousarray(mask[:, ::-1])\n",
    "    if mode == \"vflip\":\n",
    "        return np.ascontiguousarray(mask[::-1, :])\n",
    "    raise ValueError(f\"tta mode inválido: {mode}\")\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_prob_forged(image: np.ndarray) -> float:\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    img = normalize_image(image)\n",
    "    x = torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0).to(DEVICE)\n",
    "    if CLS_INFER_IMAGE_SIZE and x.shape[-2:] != (CLS_INFER_IMAGE_SIZE, CLS_INFER_IMAGE_SIZE):\n",
    "        x = F.interpolate(x, size=(CLS_INFER_IMAGE_SIZE, CLS_INFER_IMAGE_SIZE), mode=\"bilinear\", align_corners=False)\n",
    "    probs: list[float] = []\n",
    "    for m in CLS_MODELS:\n",
    "        logits = m(x).view(-1)\n",
    "        probs.append(float(torch.sigmoid(logits)[0].item()))\n",
    "    return float(np.mean(probs)) if probs else 0.0\n",
    "\n",
    "\n",
    "def predict_seg_ensemble_prob(image: np.ndarray) -> np.ndarray:\n",
    "    if not SEG_MODELS:\n",
    "        msg = (\n",
    "            \"Nenhum modelo de segmentação carregado.\\n\"\n",
    "            f\"- MODELS_SEG_DIR={MODELS_SEG_DIR}\\n\"\n",
    "            \"- Esperado: `outputs/models_seg/<model_id>/fold_*/best.pt` (no Kaggle: /kaggle/working/outputs/...)\\n\"\n",
    "            \"- Soluções:\\n\"\n",
    "            \"  1) Rode treino aqui: defina `RUN_TRAIN_SEG=True` e execute as células de treino.\\n\"\n",
    "            \"  2) Anexe um Dataset com checkpoints em `outputs/models_seg/...` e rode novamente.\\n\"\n",
    "        )\n",
    "        raise RuntimeError(msg)\n",
    "    probs_sum: np.ndarray | None = None\n",
    "    count = 0\n",
    "    modes = TTA_MODES if USE_TTA else (\"none\",)\n",
    "    for mode in modes:\n",
    "        img_t = _apply_tta(image, mode)\n",
    "        ens: np.ndarray | None = None\n",
    "        for m in SEG_MODELS:\n",
    "            p = predict_image(m, img_t, DEVICE, tile_size=TILE_SIZE, overlap=OVERLAP, max_size=MAX_SIZE)\n",
    "            ens = p if ens is None else (ens + p)\n",
    "        assert ens is not None\n",
    "        ens = ens / float(len(SEG_MODELS))\n",
    "        ens = _undo_tta(ens, mode)\n",
    "        probs_sum = ens if probs_sum is None else (probs_sum + ens)\n",
    "        count += 1\n",
    "    assert probs_sum is not None\n",
    "    return probs_sum / float(max(count, 1))\n",
    "\n",
    "\n",
    "def predict_instances(image: np.ndarray) -> list[np.ndarray]:\n",
    "    prob = predict_seg_ensemble_prob(image)\n",
    "    bin_mask = binarize(prob, threshold=THRESHOLD)\n",
    "    return extract_components(bin_mask, min_area=int(MIN_AREA))\n",
    "\n",
    "\n",
    "if RUN_SUBMISSION:\n",
    "    if not SEG_MODELS:\n",
    "        raise RuntimeError(\n",
    "            \"RUN_SUBMISSION=True, mas nenhum modelo de segmentação foi carregado.\\n\"\n",
    "            f\"- MODELS_SEG_DIR={MODELS_SEG_DIR}\\n\"\n",
    "            \"Treine (RUN_TRAIN_SEG=True) ou anexe um Dataset com `outputs/models_seg/<model_id>/fold_*/best.pt`.\"\n",
    "        )\n",
    "    SUBMISSION_PATH = Path(\"/kaggle/working/submission.csv\") if is_kaggle() else (output_root() / \"submission.csv\")\n",
    "    SUBMISSION_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with SUBMISSION_PATH.open(\"w\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"case_id\", \"annotation\"])\n",
    "        writer.writeheader()\n",
    "\n",
    "        for s in tqdm(test_samples, desc=\"infer\"):\n",
    "            img = load_image(s.image_path)\n",
    "            if CLS_MODELS:\n",
    "                p_forged = predict_prob_forged(img)\n",
    "                if float(p_forged) < float(CLS_SKIP_THRESHOLD):\n",
    "                    writer.writerow({\"case_id\": s.case_id, \"annotation\": AUTHENTIC_LABEL})\n",
    "                    continue\n",
    "            inst = predict_instances(img)\n",
    "            writer.writerow({\"case_id\": s.case_id, \"annotation\": encode_instances(inst)})\n",
    "\n",
    "    print(\"wrote:\", SUBMISSION_PATH)\n",
    "    try:\n",
    "        with SUBMISSION_PATH.open(\"r\") as f:\n",
    "            header = f.readline().strip()\n",
    "        if header != \"case_id,annotation\":\n",
    "            raise ValueError(f\"Header inesperado: {header!r}\")\n",
    "        print(\"[SUBMISSION] header OK:\", header)\n",
    "    except Exception:\n",
    "        print(\"[SUBMISSION] WARN: não consegui validar o header do CSV.\")\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"[SUBMISSION] RUN_SUBMISSION=False; não gerou CSV.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
