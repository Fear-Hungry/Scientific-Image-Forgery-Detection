{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8ab3470",
   "metadata": {},
   "source": [
    "# Treino + Submissão — Pipeline Kaggle (Offline)\n",
    "\n",
    "Este notebook é focado em **submissão no Kaggle** (internet OFF) e **treina por padrão**:\n",
    "\n",
    "1) **Setup offline + checagens**\n",
    "2) **Treino** (classificador + segmentadores)\n",
    "3) **Inferência + `submission.csv`** via `scripts/submit_ensemble.py`\n",
    "\n",
    "## Regras / Decisões\n",
    "- Importa código do projeto em `src/forgeryseg/` (modularizado).\n",
    "- Compatível com Kaggle **internet OFF** (instala wheels locais se existirem).\n",
    "- Não esconde erros: exceções e tracebacks aparecem.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035d818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 1: Sanidade Kaggle (lembrete)\n",
    "print(\"Kaggle constraints (lembrete):\")\n",
    "print(\"- Runtime <= 4h (CPU/GPU)\")\n",
    "print(\"- Internet: OFF no submit\")\n",
    "print(\"- Outputs: /kaggle/working/outputs (checkpoints)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25502575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 2: Imports + ambiente\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import traceback\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "warnings.simplefilter(\"default\")\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=ResourceWarning)\n",
    "os.environ.setdefault(\"NO_ALBUMENTATIONS_UPDATE\", \"1\")\n",
    "\n",
    "\n",
    "def is_kaggle() -> bool:\n",
    "    return bool(os.environ.get(\"KAGGLE_URL_BASE\")) or Path(\"/kaggle\").exists()\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Em notebooks, multiprocessing pode gerar warnings/instabilidade; use 0 por padrão.\n",
    "NUM_WORKERS = int(os.environ.get(\"FORGERYSEG_NUM_WORKERS\", \"0\"))\n",
    "if NUM_WORKERS > 0:\n",
    "    print(\"[WARN] FORGERYSEG_NUM_WORKERS>0 em notebooks pode gerar warnings/instabilidade.\")\n",
    "print(\"NUM_WORKERS:\", NUM_WORKERS)\n",
    "\n",
    "print(\"python:\", sys.version.split()[0])\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "print(\"device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a69ee9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 2b: Instalação offline (wheels) — NÃO resolve deps\n",
    "#\n",
    "# Estruturas suportadas:\n",
    "# - `/kaggle/input/<dataset>/wheels/*.whl`\n",
    "# - `/kaggle/input/<dataset>/recodai_bundle/wheels/*.whl`\n",
    "#\n",
    "# Observação: instalamos com `--no-deps` para não tentar instalar dependências do torch offline.\n",
    "import subprocess\n",
    "\n",
    "_install_wheels_env = os.environ.get(\"FORGERYSEG_INSTALL_WHEELS\", \"\")\n",
    "if _install_wheels_env == \"\":\n",
    "    INSTALL_WHEELS = bool(is_kaggle())\n",
    "else:\n",
    "    INSTALL_WHEELS = _install_wheels_env.strip().lower() in {\"1\", \"true\", \"yes\", \"y\", \"on\"}\n",
    "\n",
    "\n",
    "def _find_offline_bundle() -> Path | None:\n",
    "    if not is_kaggle():\n",
    "        return None\n",
    "    kaggle_input = Path(\"/kaggle/input\")\n",
    "    if not kaggle_input.exists():\n",
    "        return None\n",
    "\n",
    "    candidates: list[Path] = []\n",
    "    for ds in sorted(kaggle_input.glob(\"*\")):\n",
    "        for base in (ds, ds / \"recodai_bundle\"):\n",
    "            if (base / \"wheels\").exists():\n",
    "                candidates.append(base)\n",
    "\n",
    "    if not candidates:\n",
    "        return None\n",
    "    if len(candidates) > 1:\n",
    "        print(\"[OFFLINE INSTALL] múltiplos bundles com wheels encontrados; usando o primeiro:\")\n",
    "        for c in candidates:\n",
    "            print(\" -\", c)\n",
    "    return candidates[0]\n",
    "\n",
    "\n",
    "def _candidate_python_roots(base: Path) -> list[Path]:\n",
    "    roots = [\n",
    "        base,\n",
    "        base / \"src\",\n",
    "        base / \"vendor\",\n",
    "        base / \"third_party\",\n",
    "        base / \"recodai_bundle\",\n",
    "        base / \"recodai_bundle\" / \"src\",\n",
    "        base / \"recodai_bundle\" / \"vendor\",\n",
    "        base / \"recodai_bundle\" / \"third_party\",\n",
    "    ]\n",
    "    return [r for r in roots if r.exists()]\n",
    "\n",
    "\n",
    "def add_local_package_to_syspath(package_dir_name: str) -> list[Path]:\n",
    "    \"\"\"\n",
    "    Procura por `package_dir_name/__init__.py` em `/kaggle/input/*` e adiciona o root correspondente ao `sys.path`.\n",
    "\n",
    "    Nota: não excluímos o dataset da competição, pois alguns usuários empacotam o código junto com os dados\n",
    "    em um único Kaggle Dataset. A busca é rasa (não percorre imagens), então o custo é baixo.\n",
    "    \"\"\"\n",
    "    added: list[Path] = []\n",
    "    if not is_kaggle():\n",
    "        return added\n",
    "\n",
    "    kaggle_input = Path(\"/kaggle/input\")\n",
    "    if not kaggle_input.exists():\n",
    "        return added\n",
    "\n",
    "    for ds in sorted(kaggle_input.glob(\"*\")):\n",
    "        for root in _candidate_python_roots(ds):\n",
    "            pkg = root / package_dir_name\n",
    "            if (pkg / \"__init__.py\").exists():\n",
    "                if str(root) not in sys.path:\n",
    "                    sys.path.insert(0, str(root))\n",
    "                    added.append(root)\n",
    "                continue\n",
    "            try:\n",
    "                for child in sorted(p for p in root.glob(\"*\") if p.is_dir()):\n",
    "                    pkg2 = child / package_dir_name\n",
    "                    if (pkg2 / \"__init__.py\").exists():\n",
    "                        if str(child) not in sys.path:\n",
    "                            sys.path.insert(0, str(child))\n",
    "                            added.append(child)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    if added:\n",
    "        uniq = []\n",
    "        for p in added:\n",
    "            if p not in uniq:\n",
    "                uniq.append(p)\n",
    "        print(f\"[LOCAL IMPORT] adicionado ao sys.path para '{package_dir_name}':\")\n",
    "        for p in uniq[:10]:\n",
    "            print(\" -\", p)\n",
    "        if len(uniq) > 10:\n",
    "            print(\" ...\")\n",
    "        return uniq\n",
    "\n",
    "    print(f\"[LOCAL IMPORT] não encontrei '{package_dir_name}/__init__.py' em `/kaggle/input/*`.\")\n",
    "    return added\n",
    "\n",
    "\n",
    "OFFLINE_BUNDLE = _find_offline_bundle()\n",
    "if not INSTALL_WHEELS:\n",
    "    print(\"[OFFLINE INSTALL] FORGERYSEG_INSTALL_WHEELS=0; pulando instalação de wheels.\")\n",
    "elif OFFLINE_BUNDLE is None:\n",
    "    print(\"[OFFLINE INSTALL] nenhum bundle com `wheels/` encontrado em `/kaggle/input`.\")\n",
    "else:\n",
    "    wheel_dir = OFFLINE_BUNDLE / \"wheels\"\n",
    "    whls = sorted(str(p) for p in wheel_dir.glob(\"*.whl\"))\n",
    "    print(\"[OFFLINE INSTALL] bundle:\", OFFLINE_BUNDLE)\n",
    "    print(\"[OFFLINE INSTALL] wheels:\", len(whls))\n",
    "    if not whls:\n",
    "        print(\"[OFFLINE INSTALL] aviso: diretório `wheels/` existe mas não há `.whl`.\")\n",
    "    else:\n",
    "        cmd = [\n",
    "            sys.executable,\n",
    "            \"-m\",\n",
    "            \"pip\",\n",
    "            \"install\",\n",
    "            \"--no-index\",\n",
    "            \"--find-links\",\n",
    "            str(wheel_dir),\n",
    "            \"--no-deps\",\n",
    "            *whls,\n",
    "        ]\n",
    "        print(\"[OFFLINE INSTALL] executando:\", \" \".join(cmd[:9]), \"...\", f\"(+{len(whls)} wheels)\")\n",
    "        try:\n",
    "            subprocess.check_call(cmd)\n",
    "            print(\"[OFFLINE INSTALL] OK.\")\n",
    "        except Exception:\n",
    "            print(\"[OFFLINE INSTALL] falhou; seguindo sem wheels. Verifique compatibilidade das wheels.\")\n",
    "            traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6169a6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 2c: Import do projeto (src/forgeryseg)\n",
    "\n",
    "def _maybe_add_src_to_syspath(src_root: Path) -> bool:\n",
    "    if (src_root / \"forgeryseg\" / \"__init__.py\").exists() and str(src_root) not in sys.path:\n",
    "        sys.path.insert(0, str(src_root))\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "try:\n",
    "    import forgeryseg  # type: ignore\n",
    "except Exception:\n",
    "    _maybe_add_src_to_syspath(Path(\"src\").resolve())\n",
    "    if is_kaggle():\n",
    "        add_local_package_to_syspath(\"forgeryseg\")\n",
    "    import forgeryseg  # type: ignore\n",
    "\n",
    "FORGERYSEG_FILE = Path(forgeryseg.__file__).resolve()\n",
    "print(\"forgeryseg:\", FORGERYSEG_FILE)\n",
    "\n",
    "PROJECT_ROOT: Path | None = None\n",
    "try:\n",
    "    if FORGERYSEG_FILE.parent.name == \"forgeryseg\" and FORGERYSEG_FILE.parent.parent.name == \"src\":\n",
    "        PROJECT_ROOT = FORGERYSEG_FILE.parents[2]\n",
    "except Exception:\n",
    "    PROJECT_ROOT = None\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset  # noqa: E402\n",
    "\n",
    "from forgeryseg.augment import get_train_augment, get_val_augment  # noqa: E402\n",
    "from forgeryseg.dataset import PatchDataset, build_train_index  # noqa: E402\n",
    "from forgeryseg.losses import BCETverskyLoss  # noqa: E402\n",
    "from forgeryseg.models import builders, dinov2  # noqa: E402\n",
    "from forgeryseg.models.classifier import build_classifier, compute_pos_weight  # noqa: E402\n",
    "from forgeryseg.offline import configure_cache_dirs  # noqa: E402\n",
    "from forgeryseg.train import train_one_epoch, validate  # noqa: E402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95744cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 2d: Cache dirs (offline weights)\n",
    "#\n",
    "# Para usar pesos pré-treinados no Kaggle com internet OFF, anexe um Dataset contendo caches e aponte aqui.\n",
    "# Exemplo de estrutura sugerida:\n",
    "# - <CACHE_ROOT>/torch  (TORCH_HOME)\n",
    "# - <CACHE_ROOT>/hf     (HF_HOME)\n",
    "CACHE_ROOT = os.environ.get(\"FORGERYSEG_CACHE_ROOT\", \"\")\n",
    "if CACHE_ROOT:\n",
    "    configure_cache_dirs(CACHE_ROOT)\n",
    "    print(\"[CACHE] FORGERYSEG_CACHE_ROOT:\", CACHE_ROOT)\n",
    "else:\n",
    "    print(\"[CACHE] FORGERYSEG_CACHE_ROOT vazio (seguindo sem caches).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07bf44f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 3: Dataset root + contagens\n",
    "\n",
    "\n",
    "def find_dataset_root() -> Path:\n",
    "    def _looks_like_root(p: Path) -> bool:\n",
    "        return (p / \"train_images\").exists() and (p / \"test_images\").exists()\n",
    "\n",
    "    if is_kaggle():\n",
    "        base = Path(\"/kaggle/input/recodai-luc-scientific-image-forgery-detection\")\n",
    "        if _looks_like_root(base):\n",
    "            return base\n",
    "        kaggle_input = Path(\"/kaggle/input\")\n",
    "        if kaggle_input.exists():\n",
    "            for ds in sorted(kaggle_input.glob(\"*\")):\n",
    "                if _looks_like_root(ds):\n",
    "                    return ds\n",
    "\n",
    "    local_candidates = [\n",
    "        Path(\"data/recodai\").resolve(),\n",
    "        Path(\"data\").resolve(),\n",
    "    ]\n",
    "    for cand in local_candidates:\n",
    "        if _looks_like_root(cand):\n",
    "            return cand\n",
    "\n",
    "    raise FileNotFoundError(\"Dataset não encontrado. No Kaggle: anexe o dataset da competição.\")\n",
    "\n",
    "\n",
    "DATA_ROOT = find_dataset_root()\n",
    "train_samples = build_train_index(DATA_ROOT, strict=False)\n",
    "train_labels = np.array([0 if s.is_authentic else 1 for s in train_samples], dtype=np.int64)\n",
    "\n",
    "print(\"DATA_ROOT:\", DATA_ROOT)\n",
    "print(\"train samples:\", len(train_samples), \"auth:\", int((train_labels == 0).sum()), \"forged:\", int((train_labels == 1).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989cf8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 4: Config de treino (liga/desliga)\n",
    "def _has_any_ckpt(dir_name: str, pattern: str) -> bool:\n",
    "    # Procura primeiro em /kaggle/input (datasets anexados), depois em outputs/ local.\n",
    "    if is_kaggle():\n",
    "        ki = Path(\"/kaggle/input\")\n",
    "        if ki.exists():\n",
    "            for ds in sorted(ki.glob(\"*\")):\n",
    "                for base in (ds, ds / \"recodai_bundle\"):\n",
    "                    cand = base / \"outputs\" / dir_name\n",
    "                    if cand.exists():\n",
    "                        if any(cand.glob(pattern)):\n",
    "                            return True\n",
    "    local = (Path(\"/kaggle/working\") if is_kaggle() else Path(\".\").resolve()) / \"outputs\" / dir_name\n",
    "    return local.exists() and any(local.glob(pattern))\n",
    "\n",
    "\n",
    "HAS_SEG_CKPT = _has_any_ckpt(\"models_seg\", \"*/*/best.pt\")\n",
    "HAS_CLS_CKPT = _has_any_ckpt(\"models_cls\", \"fold_*/best.pt\")\n",
    "\n",
    "# Utils\n",
    "def _env_bool(name: str, default: bool) -> bool:\n",
    "    v = os.environ.get(name, \"\")\n",
    "    if v == \"\":\n",
    "        return bool(default)\n",
    "    return str(v).strip().lower() in {\"1\", \"true\", \"yes\", \"y\", \"on\"}\n",
    "\n",
    "\n",
    "ALLOW_DOWNLOAD = _env_bool(\"FORGERYSEG_ALLOW_DOWNLOAD\", default=not is_kaggle())\n",
    "# No Kaggle, a internet é OFF por padrão. Permita downloads apenas se o usuário pedir explicitamente.\n",
    "OFFLINE_NO_DOWNLOAD = bool(is_kaggle() and not ALLOW_DOWNLOAD)\n",
    "if OFFLINE_NO_DOWNLOAD:\n",
    "    os.environ.setdefault(\"HF_HUB_OFFLINE\", \"1\")\n",
    "    os.environ.setdefault(\"TRANSFORMERS_OFFLINE\", \"1\")\n",
    "    print(\"[OFFLINE] downloads disabled (Kaggle offline).\")\n",
    "\n",
    "\n",
    "N_FOLDS = int(os.environ.get(\"FORGERYSEG_N_FOLDS\", \"5\"))\n",
    "FOLD = int(os.environ.get(\"FORGERYSEG_FOLD\", \"0\"))\n",
    "\n",
    "FAST_TRAIN = _env_bool(\"FORGERYSEG_FAST_TRAIN\", default=bool(is_kaggle() and not HAS_SEG_CKPT))\n",
    "\n",
    "print(\"FAST_TRAIN:\", FAST_TRAIN)\n",
    "print(\"HAS_SEG_CKPT:\", HAS_SEG_CKPT)\n",
    "print(\"HAS_CLS_CKPT:\", HAS_CLS_CKPT)\n",
    "\n",
    "# DINO-only: pipeline simples e 100% offline (sem timm / sem downloads).\n",
    "DINO_ONLY = _env_bool(\"FORGERYSEG_DINO_ONLY\", default=bool(is_kaggle()))\n",
    "\n",
    "# Em notebook de submissão Kaggle, por padrão TREINAMOS.\n",
    "RUN_TRAIN_CLS = _env_bool(\"FORGERYSEG_RUN_TRAIN_CLS\", default=not DINO_ONLY)\n",
    "RUN_TRAIN_SEG = _env_bool(\"FORGERYSEG_RUN_TRAIN_SEG\", default=not DINO_ONLY)\n",
    "RUN_TRAIN_DINO = _env_bool(\"FORGERYSEG_RUN_TRAIN_DINO\", default=bool(DINO_ONLY))\n",
    "\n",
    "print(\"DINO_ONLY:\", DINO_ONLY)\n",
    "print(\"RUN_TRAIN_CLS:\", RUN_TRAIN_CLS)\n",
    "print(\"RUN_TRAIN_SEG:\", RUN_TRAIN_SEG)\n",
    "print(\"RUN_TRAIN_DINO:\", RUN_TRAIN_DINO)\n",
    "print(\"N_FOLDS:\", N_FOLDS)\n",
    "print(\"FOLD:\", FOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a1a82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 2 — Célula 5: Split (folds)\n",
    "try:\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "    folds = np.zeros(len(train_samples), dtype=np.int64)\n",
    "    for fold_id, (_, val_idx) in enumerate(skf.split(np.zeros(len(train_samples)), train_labels)):\n",
    "        folds[val_idx] = int(fold_id)\n",
    "except Exception:\n",
    "    print(\"[ERRO] scikit-learn falhou (StratifiedKFold). Usando split simples.\")\n",
    "    traceback.print_exc()\n",
    "    folds = np.arange(len(train_samples), dtype=np.int64) % int(N_FOLDS)\n",
    "\n",
    "train_idx = np.where(folds != int(FOLD))[0]\n",
    "val_idx = np.where(folds == int(FOLD))[0]\n",
    "print(f\"fold={FOLD}: train={len(train_idx)} val={len(val_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e3d86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 2 — Célula 6: Treino do classificador (opcional)\n",
    "try:\n",
    "    import torchvision.transforms as T\n",
    "except Exception:\n",
    "    print(\"[ERRO] torchvision falhou no import.\")\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except Exception:\n",
    "    print(\"[WARN] tqdm indisponível; usando loop simples.\")\n",
    "\n",
    "    def tqdm(x, **kwargs):  # type: ignore\n",
    "        return x\n",
    "\n",
    "\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "CLS_MODEL_NAME = \"tf_efficientnet_b4_ns\"\n",
    "CLS_BACKEND = os.environ.get(\"FORGERYSEG_CLS_BACKEND\", \"timm\").strip().lower()\n",
    "CLS_HF_MODEL_ID = os.environ.get(\"FORGERYSEG_CLS_HF_MODEL_ID\", \"metaresearch/dinov2\")\n",
    "CLS_FREEZE_ENCODER = _env_bool(\"FORGERYSEG_CLS_FREEZE_ENCODER\", default=True)\n",
    "CLS_LOCAL_FILES_ONLY = _env_bool(\"FORGERYSEG_CLS_LOCAL_FILES_ONLY\", default=OFFLINE_NO_DOWNLOAD)\n",
    "CLS_CLASSIFIER_HIDDEN = int(os.environ.get(\"FORGERYSEG_CLS_HIDDEN\", \"0\"))\n",
    "CLS_CLASSIFIER_DROPOUT = float(os.environ.get(\"FORGERYSEG_CLS_DROPOUT\", \"0.1\"))\n",
    "CLS_USE_CLS_TOKEN = _env_bool(\"FORGERYSEG_CLS_USE_CLS_TOKEN\", default=True)\n",
    "_cls_default_size = \"392\" if CLS_BACKEND in {\"dinov2\", \"hf\"} else \"384\"\n",
    "CLS_IMAGE_SIZE = int(os.environ.get(\"FORGERYSEG_CLS_IMAGE_SIZE\", _cls_default_size))\n",
    "CLS_BATCH_SIZE = 32\n",
    "CLS_EPOCHS = int(os.environ.get(\"FORGERYSEG_CLS_EPOCHS\", \"15\"))\n",
    "CLS_PATIENCE = 3\n",
    "CLS_LR = 3e-4\n",
    "CLS_WEIGHT_DECAY = 1e-2\n",
    "# Preferir recall (evitar falsos negativos): só pule a segmentação quando tiver alta confiança de autenticidade.\n",
    "CLS_SKIP_THRESHOLD = float(os.environ.get(\"FORGERYSEG_CLS_SKIP_THRESHOLD\", \"0.30\"))\n",
    "# Scheduler (PDF sugere ReduceLROnPlateau ou cosine; usamos ReduceLROnPlateau por padrão).\n",
    "CLS_USE_SCHEDULER = _env_bool(\"FORGERYSEG_CLS_USE_SCHEDULER\", default=True)\n",
    "CLS_LR_SCHED_PATIENCE = int(os.environ.get(\"FORGERYSEG_CLS_LR_SCHED_PATIENCE\", \"2\"))\n",
    "CLS_LR_SCHED_FACTOR = float(os.environ.get(\"FORGERYSEG_CLS_LR_SCHED_FACTOR\", \"0.5\"))\n",
    "# Pesos pré-treinados ajudam; em Kaggle offline use cache local (falha se faltar).\n",
    "CLS_PRETRAINED = _env_bool(\"FORGERYSEG_CLS_PRETRAINED\", default=True)\n",
    "\n",
    "\n",
    "def build_transform(train: bool) -> T.Compose:\n",
    "    aug = []\n",
    "    if train:\n",
    "        aug += [T.RandomHorizontalFlip(p=0.5), T.RandomVerticalFlip(p=0.5)]\n",
    "    aug += [\n",
    "        T.Resize((CLS_IMAGE_SIZE, CLS_IMAGE_SIZE)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "    ]\n",
    "    return T.Compose(aug)\n",
    "\n",
    "\n",
    "class ClsDataset(Dataset):\n",
    "    def __init__(self, samples, transform: T.Compose):\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        s = self.samples[int(idx)]\n",
    "        from PIL import Image\n",
    "\n",
    "        img = Image.open(s.image_path).convert(\"RGB\")\n",
    "        x = self.transform(img)\n",
    "        y = torch.tensor([0.0 if s.is_authentic else 1.0], dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "if RUN_TRAIN_CLS and not DINO_ONLY:\n",
    "    ds_cls_train = ClsDataset([train_samples[i] for i in train_idx.tolist()], build_transform(train=True))\n",
    "    ds_cls_val = ClsDataset([train_samples[i] for i in val_idx.tolist()], build_transform(train=False))\n",
    "\n",
    "    num_workers = NUM_WORKERS\n",
    "    dl_cls_train = DataLoader(ds_cls_train, batch_size=CLS_BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=(DEVICE == \"cuda\"), drop_last=True)\n",
    "    dl_cls_val = DataLoader(ds_cls_val, batch_size=CLS_BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=(DEVICE == \"cuda\"), drop_last=False)\n",
    "\n",
    "    cls_kwargs = {}\n",
    "    if CLS_BACKEND in {\"dinov2\", \"hf\"}:\n",
    "        cls_kwargs = {\n",
    "            \"hf_model_id\": CLS_HF_MODEL_ID,\n",
    "            \"local_files_only\": CLS_LOCAL_FILES_ONLY,\n",
    "            \"freeze_encoder\": CLS_FREEZE_ENCODER,\n",
    "            \"classifier_hidden\": CLS_CLASSIFIER_HIDDEN,\n",
    "            \"classifier_dropout\": CLS_CLASSIFIER_DROPOUT,\n",
    "            \"use_cls_token\": CLS_USE_CLS_TOKEN,\n",
    "        }\n",
    "    cls_model = build_classifier(\n",
    "        model_name=CLS_MODEL_NAME,\n",
    "        pretrained=CLS_PRETRAINED,\n",
    "        num_classes=1,\n",
    "        backend=CLS_BACKEND,\n",
    "        **cls_kwargs,\n",
    "    ).to(DEVICE)\n",
    "    pos_weight = torch.tensor(compute_pos_weight(train_labels[train_idx]), dtype=torch.float32, device=DEVICE)\n",
    "    cls_criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    cls_optimizer = torch.optim.AdamW(cls_model.parameters(), lr=CLS_LR, weight_decay=CLS_WEIGHT_DECAY)\n",
    "    cls_scheduler = None\n",
    "    if CLS_USE_SCHEDULER:\n",
    "        cls_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            cls_optimizer,\n",
    "            mode=\"min\",\n",
    "            patience=int(CLS_LR_SCHED_PATIENCE),\n",
    "            factor=float(CLS_LR_SCHED_FACTOR),\n",
    "        )\n",
    "    cls_scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE == \"cuda\"))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def cls_eval() -> dict:\n",
    "        cls_model.eval()\n",
    "        losses = []\n",
    "        logits_all = []\n",
    "        y_all = []\n",
    "        for x, yb in tqdm(dl_cls_val, desc=\"cls val\", leave=False):\n",
    "            x = x.to(DEVICE, non_blocking=True)\n",
    "            yb = yb.to(DEVICE, non_blocking=True)\n",
    "            logits = cls_model(x).view(-1, 1)\n",
    "            loss = cls_criterion(logits, yb)\n",
    "            losses.append(float(loss.item()))\n",
    "            logits_all.append(logits.detach().cpu().numpy())\n",
    "            y_all.append(yb.detach().cpu().numpy())\n",
    "        logits_np = np.concatenate(logits_all, axis=0).reshape(-1)\n",
    "        y_np = np.concatenate(y_all, axis=0).reshape(-1)\n",
    "        probs = 1.0 / (1.0 + np.exp(-logits_np))\n",
    "        acc = float(((probs >= 0.5).astype(np.int64) == y_np.astype(np.int64)).mean())\n",
    "        out = {\"loss\": float(np.mean(losses)) if losses else float(\"nan\"), \"acc@0.5\": acc}\n",
    "        try:\n",
    "            from sklearn.metrics import roc_auc_score\n",
    "\n",
    "            out[\"auc\"] = float(roc_auc_score(y_np, probs))\n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "        return out\n",
    "\n",
    "    def cls_train_one_epoch() -> float:\n",
    "        cls_model.train()\n",
    "        losses = []\n",
    "        for x, yb in tqdm(dl_cls_train, desc=\"cls train\", leave=False):\n",
    "            x = x.to(DEVICE, non_blocking=True)\n",
    "            yb = yb.to(DEVICE, non_blocking=True)\n",
    "            cls_optimizer.zero_grad(set_to_none=True)\n",
    "            with torch.cuda.amp.autocast(enabled=(DEVICE == \"cuda\")):\n",
    "                logits = cls_model(x).view(-1, 1)\n",
    "                loss = cls_criterion(logits, yb)\n",
    "            cls_scaler.scale(loss).backward()\n",
    "            cls_scaler.step(cls_optimizer)\n",
    "            cls_scaler.update()\n",
    "            losses.append(float(loss.item()))\n",
    "        return float(np.mean(losses)) if losses else float(\"nan\")\n",
    "\n",
    "    def output_root() -> Path:\n",
    "        return Path(\"/kaggle/working\") if is_kaggle() else Path(\".\").resolve()\n",
    "\n",
    "    cls_save_dir = output_root() / \"outputs\" / \"models_cls\" / f\"fold_{int(FOLD)}\"\n",
    "    cls_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    cls_best_path = cls_save_dir / \"best.pt\"\n",
    "\n",
    "    best_score = -1.0\n",
    "    best_epoch = 0\n",
    "    for epoch in range(1, int(CLS_EPOCHS) + 1):\n",
    "        tr_loss = cls_train_one_epoch()\n",
    "        val = cls_eval()\n",
    "        if cls_scheduler is not None:\n",
    "            cls_scheduler.step(float(val[\"loss\"]))\n",
    "        score = float(val.get(\"auc\", -val[\"loss\"]))\n",
    "        print(f\"[CLS] epoch {epoch:02d}/{CLS_EPOCHS} | train_loss={tr_loss:.4f} | val={val}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_epoch = int(epoch)\n",
    "            ckpt_config = {\n",
    "                \"backend\": CLS_BACKEND,\n",
    "                \"model_name\": CLS_MODEL_NAME,\n",
    "                \"image_size\": int(CLS_IMAGE_SIZE),\n",
    "                \"pretrained\": bool(CLS_PRETRAINED),\n",
    "                \"fold\": int(FOLD),\n",
    "                \"seed\": int(SEED),\n",
    "            }\n",
    "            if CLS_BACKEND in {\"dinov2\", \"hf\"}:\n",
    "                ckpt_config.update(\n",
    "                    {\n",
    "                        \"hf_model_id\": CLS_HF_MODEL_ID,\n",
    "                        \"local_files_only\": CLS_LOCAL_FILES_ONLY,\n",
    "                        \"freeze_encoder\": CLS_FREEZE_ENCODER,\n",
    "                        \"classifier_hidden\": CLS_CLASSIFIER_HIDDEN,\n",
    "                        \"classifier_dropout\": CLS_CLASSIFIER_DROPOUT,\n",
    "                        \"use_cls_token\": CLS_USE_CLS_TOKEN,\n",
    "                    }\n",
    "                )\n",
    "            ckpt = {\n",
    "                \"model_state\": cls_model.state_dict(),\n",
    "                \"config\": ckpt_config,\n",
    "                \"score\": float(best_score),\n",
    "            }\n",
    "            torch.save(ckpt, cls_best_path)\n",
    "            print(\"[CLS] saved best ->\", cls_best_path)\n",
    "        if CLS_PATIENCE and best_epoch and (int(epoch) - int(best_epoch) >= int(CLS_PATIENCE)):\n",
    "            print(f\"[CLS] early stopping: sem melhora por {CLS_PATIENCE} épocas (best_epoch={best_epoch}).\")\n",
    "            break\n",
    "\n",
    "    print(\"[CLS] done. best score:\", best_score)\n",
    "else:\n",
    "    if DINO_ONLY:\n",
    "        print(\"[CLS] DINO_ONLY=True (pulando treino do classificador).\")\n",
    "    else:\n",
    "        print(\"[CLS] RUN_TRAIN_CLS=False (pulando).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035119af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 3 — Célula 7: Treino de segmentação (opcional)\n",
    "SEG_PATCH_SIZE = int(os.environ.get(\"FORGERYSEG_SEG_PATCH_SIZE\", \"512\"))\n",
    "SEG_COPY_MOVE_PROB = 0.20\n",
    "SEG_BATCH_SIZE = int(os.environ.get(\"FORGERYSEG_SEG_BATCH_SIZE\", \"4\"))\n",
    "SEG_EPOCHS = int(os.environ.get(\"FORGERYSEG_SEG_EPOCHS\", \"40\"))\n",
    "SEG_LR = 1e-3\n",
    "SEG_WEIGHT_DECAY = 1e-2\n",
    "SEG_PATIENCE = 3\n",
    "# Scheduler (PDF sugere ReduceLROnPlateau ou cosine; usamos ReduceLROnPlateau por padrão).\n",
    "SEG_USE_SCHEDULER = _env_bool(\"FORGERYSEG_SEG_USE_SCHEDULER\", default=True)\n",
    "SEG_LR_SCHED_PATIENCE = int(os.environ.get(\"FORGERYSEG_SEG_LR_SCHED_PATIENCE\", \"2\"))\n",
    "SEG_LR_SCHED_FACTOR = float(os.environ.get(\"FORGERYSEG_SEG_LR_SCHED_FACTOR\", \"0.5\"))\n",
    "# Pesos pré-treinados: preferível (offline via cache); falha se faltar.\n",
    "_seg_weights_env = os.environ.get(\"FORGERYSEG_SEG_ENCODER_WEIGHTS\", \"imagenet\")\n",
    "if str(_seg_weights_env).strip().lower() in {\"\", \"none\", \"null\", \"false\", \"0\"}:\n",
    "    SEG_ENCODER_WEIGHTS = None\n",
    "else:\n",
    "    SEG_ENCODER_WEIGHTS = str(_seg_weights_env)\n",
    "\n",
    "# Para performance máxima, treine mais de uma arquitetura e faça ensemble na inferência.\n",
    "# Preset inspirado no PDF \"Pipeline Completo...\" (Unet++ + DeepLabV3+ + SegFormer).\n",
    "SEG_TRAIN_SPECS = [\n",
    "    {\n",
    "        \"model_id\": \"unetpp_effnet_b7\",\n",
    "        \"arch\": \"unetplusplus\",\n",
    "        \"encoder_name\": \"efficientnet-b7\",\n",
    "    },\n",
    "    {\n",
    "        \"model_id\": \"deeplabv3p_tu_resnest101e\",\n",
    "        \"arch\": \"deeplabv3plus\",\n",
    "        \"encoder_name\": \"tu-resnest101e\",\n",
    "    },\n",
    "    {\n",
    "        \"model_id\": \"segformer_mit_b3\",\n",
    "        \"arch\": \"segformer\",\n",
    "        \"encoder_name\": \"mit_b3\",\n",
    "    },\n",
    "]\n",
    "\n",
    "USE_DINOV2 = _env_bool(\"FORGERYSEG_USE_DINOV2\", default=False)\n",
    "if USE_DINOV2:\n",
    "    SEG_TRAIN_SPECS.append(\n",
    "        {\n",
    "            \"model_id\": \"dinov2_base_light\",\n",
    "            \"backend\": \"dinov2\",\n",
    "            \"arch\": \"dinov2\",\n",
    "            \"hf_model_id\": os.environ.get(\"FORGERYSEG_SEG_HF_MODEL_ID\", \"metaresearch/dinov2\"),\n",
    "            \"freeze_encoder\": _env_bool(\"FORGERYSEG_SEG_FREEZE_ENCODER\", default=True),\n",
    "            \"decoder_channels\": [256, 128, 64],\n",
    "            \"decoder_dropout\": float(os.environ.get(\"FORGERYSEG_SEG_DECODER_DROPOUT\", \"0.0\")),\n",
    "            \"local_files_only\": OFFLINE_NO_DOWNLOAD,\n",
    "        }\n",
    "    )\n",
    "\n",
    "if FAST_TRAIN:\n",
    "    print(\"[SEG] FAST_TRAIN=True -> preset rápido (1 modelo / poucas épocas).\")\n",
    "    SEG_EPOCHS = min(int(SEG_EPOCHS), 2)\n",
    "    if OFFLINE_NO_DOWNLOAD:\n",
    "        SEG_TRAIN_SPECS = [\n",
    "            {\"model_id\": \"unet_resnet34\", \"arch\": \"unet\", \"encoder_name\": \"resnet34\", \"encoder_weights\": None},\n",
    "        ]\n",
    "    else:\n",
    "        SEG_TRAIN_SPECS = [\n",
    "            {\"model_id\": \"unet_tu_convnext_small\", \"arch\": \"unet\", \"encoder_name\": \"tu-convnext_small\"},\n",
    "        ]\n",
    "\n",
    "if RUN_TRAIN_SEG and not DINO_ONLY:\n",
    "    train_aug = get_train_augment(patch_size=SEG_PATCH_SIZE, copy_move_prob=SEG_COPY_MOVE_PROB)\n",
    "    val_aug = get_val_augment()\n",
    "\n",
    "    ds_seg_train = PatchDataset([train_samples[i] for i in train_idx.tolist()], patch_size=SEG_PATCH_SIZE, train=True, augment=train_aug, positive_prob=0.7, seed=SEED)\n",
    "    ds_seg_val = PatchDataset([train_samples[i] for i in val_idx.tolist()], patch_size=SEG_PATCH_SIZE, train=False, augment=val_aug, seed=SEED)\n",
    "\n",
    "    num_workers = NUM_WORKERS\n",
    "    dl_seg_train = DataLoader(ds_seg_train, batch_size=SEG_BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=(DEVICE == \"cuda\"), drop_last=True)\n",
    "    dl_seg_val = DataLoader(ds_seg_val, batch_size=SEG_BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=(DEVICE == \"cuda\"), drop_last=False)\n",
    "\n",
    "    def output_root() -> Path:\n",
    "        return Path(\"/kaggle/working\") if is_kaggle() else Path(\".\").resolve()\n",
    "\n",
    "    use_amp = (DEVICE == \"cuda\")\n",
    "\n",
    "    def build_seg_model(spec: dict, encoder_weights: str | None) -> nn.Module:\n",
    "        backend = str(spec.get(\"backend\", \"smp\")).lower()\n",
    "        if backend == \"smp\":\n",
    "            arch = str(spec.get(\"arch\", \"unet\")).lower()\n",
    "            encoder_name = str(spec.get(\"encoder_name\", \"efficientnet-b4\"))\n",
    "            if arch == \"unet\":\n",
    "                return builders.build_unet(\n",
    "                    encoder_name=encoder_name,\n",
    "                    encoder_weights=encoder_weights,\n",
    "                    classes=1,\n",
    "                    strict_weights=True,\n",
    "                )\n",
    "            if arch in {\"unetplusplus\", \"unetpp\"}:\n",
    "                return builders.build_unetplusplus(\n",
    "                    encoder_name=encoder_name,\n",
    "                    encoder_weights=encoder_weights,\n",
    "                    classes=1,\n",
    "                    strict_weights=True,\n",
    "                )\n",
    "            if arch in {\"deeplabv3plus\", \"deeplabv3+\", \"deeplabv3p\"}:\n",
    "                return builders.build_deeplabv3plus(\n",
    "                    encoder_name=encoder_name,\n",
    "                    encoder_weights=encoder_weights,\n",
    "                    classes=1,\n",
    "                    strict_weights=True,\n",
    "                )\n",
    "            if arch in {\"segformer\", \"mit\"}:\n",
    "                return builders.build_segformer(\n",
    "                    encoder_name=encoder_name,\n",
    "                    encoder_weights=encoder_weights,\n",
    "                    classes=1,\n",
    "                    strict_weights=True,\n",
    "                )\n",
    "            raise ValueError(f\"SEG arch inválida: {arch!r}\")\n",
    "\n",
    "        if backend in {\"dinov2\", \"hf\"}:\n",
    "            model_id = str(spec.get(\"hf_model_id\", \"metaresearch/dinov2\"))\n",
    "            return dinov2.build_dinov2_segmenter(\n",
    "                model_id=model_id,\n",
    "                decoder_channels=spec.get(\"decoder_channels\", (256, 128, 64)),\n",
    "                decoder_dropout=float(spec.get(\"decoder_dropout\", 0.0)),\n",
    "                pretrained=True,\n",
    "                freeze_encoder=bool(spec.get(\"freeze_encoder\", True)),\n",
    "                local_files_only=bool(spec.get(\"local_files_only\", OFFLINE_NO_DOWNLOAD)),\n",
    "            )\n",
    "\n",
    "        raise ValueError(f\"SEG backend inválido: {backend!r}\")\n",
    "\n",
    "    available_encoders = set(builders.available_encoders())\n",
    "\n",
    "    for spec in SEG_TRAIN_SPECS:\n",
    "        model_id = str(spec[\"model_id\"])\n",
    "        backend = str(spec.get(\"backend\", \"smp\")).lower()\n",
    "        arch = str(spec.get(\"arch\", \"unetplusplus\"))\n",
    "        encoder_name = str(spec.get(\"encoder_name\", spec.get(\"hf_model_id\", \"efficientnet-b4\")))\n",
    "        encoder_weights: str | None = spec.get(\"encoder_weights\", SEG_ENCODER_WEIGHTS)\n",
    "\n",
    "        if backend == \"smp\" and available_encoders and encoder_name not in available_encoders:\n",
    "            raise ValueError(f\"[SEG] encoder {encoder_name!r} não listado em SMP.\")\n",
    "\n",
    "        seg_model = build_seg_model(spec, encoder_weights).to(DEVICE)\n",
    "\n",
    "        seg_criterion = BCETverskyLoss(alpha=0.7, beta=0.3, tversky_weight=1.0)\n",
    "        seg_optimizer = torch.optim.AdamW(seg_model.parameters(), lr=SEG_LR, weight_decay=SEG_WEIGHT_DECAY)\n",
    "        seg_scheduler = None\n",
    "        if SEG_USE_SCHEDULER:\n",
    "            seg_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                seg_optimizer,\n",
    "                mode=\"min\",\n",
    "                patience=int(SEG_LR_SCHED_PATIENCE),\n",
    "                factor=float(SEG_LR_SCHED_FACTOR),\n",
    "            )\n",
    "\n",
    "        seg_save_dir = output_root() / \"outputs\" / \"models_seg\" / model_id / f\"fold_{int(FOLD)}\"\n",
    "        seg_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        seg_best_path = seg_save_dir / \"best.pt\"\n",
    "\n",
    "        best_dice = -1.0\n",
    "        best_epoch = 0\n",
    "        for epoch in range(1, int(SEG_EPOCHS) + 1):\n",
    "            tr = train_one_epoch(seg_model, dl_seg_train, seg_criterion, seg_optimizer, DEVICE, use_amp=use_amp, progress=True, desc=f\"seg train ({model_id})\")\n",
    "            val_stats, val_dice = validate(seg_model, dl_seg_val, seg_criterion, DEVICE, progress=True, desc=f\"seg val ({model_id})\")\n",
    "            if seg_scheduler is not None:\n",
    "                seg_scheduler.step(float(val_stats.loss))\n",
    "            print(f\"[SEG {model_id}] epoch {epoch:02d}/{SEG_EPOCHS} | train_loss={tr.loss:.4f} | val_loss={val_stats.loss:.4f} | dice@0.5={val_dice:.4f}\")\n",
    "            if float(val_dice) > best_dice:\n",
    "                best_dice = float(val_dice)\n",
    "                best_epoch = int(epoch)\n",
    "                ckpt_config = {\n",
    "                    \"backend\": backend,\n",
    "                    \"arch\": arch,\n",
    "                    \"encoder_name\": encoder_name,\n",
    "                    \"encoder_weights\": encoder_weights,\n",
    "                    \"classes\": 1,\n",
    "                    \"model_id\": model_id,\n",
    "                    \"patch_size\": int(SEG_PATCH_SIZE),\n",
    "                    \"fold\": int(FOLD),\n",
    "                    \"seed\": int(SEED),\n",
    "                }\n",
    "                if backend in {\"dinov2\", \"hf\"}:\n",
    "                    ckpt_config.update(\n",
    "                        {\n",
    "                            \"hf_model_id\": spec.get(\"hf_model_id\", encoder_name),\n",
    "                            \"freeze_encoder\": bool(spec.get(\"freeze_encoder\", True)),\n",
    "                            \"decoder_channels\": spec.get(\"decoder_channels\", (256, 128, 64)),\n",
    "                            \"decoder_dropout\": float(spec.get(\"decoder_dropout\", 0.0)),\n",
    "                            \"local_files_only\": bool(spec.get(\"local_files_only\", OFFLINE_NO_DOWNLOAD)),\n",
    "                        }\n",
    "                    )\n",
    "                ckpt = {\n",
    "                    \"model_state\": seg_model.state_dict(),\n",
    "                    \"config\": ckpt_config,\n",
    "                    \"score\": float(best_dice),\n",
    "                }\n",
    "                torch.save(ckpt, seg_best_path)\n",
    "                print(\"[SEG] saved best ->\", seg_best_path)\n",
    "            if SEG_PATIENCE and best_epoch and (int(epoch) - int(best_epoch) >= int(SEG_PATIENCE)):\n",
    "                print(f\"[SEG {model_id}] early stopping: sem melhora por {SEG_PATIENCE} épocas (best_epoch={best_epoch}).\")\n",
    "                break\n",
    "\n",
    "        print(f\"[SEG {model_id}] done. best dice:\", best_dice)\n",
    "else:\n",
    "    if DINO_ONLY:\n",
    "        print(\"[SEG] DINO_ONLY=True (pulando treino SMP/SegFormer).\")\n",
    "    else:\n",
    "        print(\"[SEG] RUN_TRAIN_SEG=False (pulando).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28ebcd5",
   "metadata": {},
   "source": [
    "## Fase 3b — DINOv2 (offline) + head leve + TTA + pós-processamento\n",
    "\n",
    "Pipeline simples e robusto para Kaggle offline:\n",
    "- Encoder DINOv2 (congelado, pesos locais)\n",
    "- Head conv leve (3 camadas)\n",
    "- TTA + pós-processamento adaptativo\n",
    "\n",
    "Para ativar: `FORGERYSEG_DINO_ONLY=1` (default no Kaggle)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96487b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DINO_ONLY:\n",
    "    try:\n",
    "        import cv2\n",
    "    except Exception:\n",
    "        print(\"[ERRO] OpenCV (cv2) não disponível. Instale ou inclua no bundle.\")\n",
    "        raise\n",
    "\n",
    "    def _parse_version_tuple(ver: str) -> tuple[int, ...]:\n",
    "        parts = []\n",
    "        for chunk in str(ver).replace(\"+\", \".\").split(\".\"):\n",
    "            try:\n",
    "                parts.append(int(chunk))\n",
    "            except Exception:\n",
    "                break\n",
    "        return tuple(parts)\n",
    "\n",
    "    def _ensure_hf_hub_compat() -> None:\n",
    "        try:\n",
    "            from importlib import metadata as importlib_metadata\n",
    "        except Exception:\n",
    "            import importlib_metadata  # type: ignore\n",
    "\n",
    "        try:\n",
    "            hub_ver = importlib_metadata.version(\"huggingface-hub\")\n",
    "        except Exception:\n",
    "            hub_ver = None\n",
    "\n",
    "        def _is_ok(v: str | None) -> bool:\n",
    "            if not v:\n",
    "                return False\n",
    "            vt = _parse_version_tuple(v)\n",
    "            return vt >= (0, 34, 0) and vt < (1, 0, 0)\n",
    "\n",
    "        if _is_ok(hub_ver):\n",
    "            return\n",
    "\n",
    "        print(f\"[DINO] huggingface-hub incompatível (versão atual={hub_ver}). Tentando instalar wheel offline (<1.0).\")\n",
    "        if OFFLINE_BUNDLE is None:\n",
    "            raise RuntimeError(\"[DINO] bundle offline não encontrado; adicione wheels de huggingface-hub 0.34.x.\")\n",
    "\n",
    "        wheel_dir = OFFLINE_BUNDLE / \"wheels\"\n",
    "        if not wheel_dir.exists():\n",
    "            raise RuntimeError(f\"[DINO] diretório de wheels não encontrado: {wheel_dir}\")\n",
    "\n",
    "        hub_wheels = sorted(wheel_dir.glob(\"huggingface_hub-*.whl\"))\n",
    "        if not hub_wheels:\n",
    "            raise RuntimeError(\"[DINO] wheel de huggingface-hub não encontrada. Inclua huggingface-hub==0.34.* no bundle.\")\n",
    "\n",
    "        # escolher a wheel mais alta <1.0\n",
    "        def _wheel_version(p: Path) -> tuple[int, ...]:\n",
    "            name = p.name.replace(\"huggingface_hub-\", \"\")\n",
    "            ver = name.split(\"-\")[0]\n",
    "            return _parse_version_tuple(ver)\n",
    "\n",
    "        candidates = [(p, _wheel_version(p)) for p in hub_wheels]\n",
    "        candidates = [c for c in candidates if c[1] >= (0, 34, 0) and c[1] < (1, 0, 0)]\n",
    "        if not candidates:\n",
    "            raise RuntimeError(\"[DINO] nenhuma wheel compatível de huggingface-hub (<1.0) encontrada no bundle.\")\n",
    "\n",
    "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        wheel_path = candidates[0][0]\n",
    "        cmd = [\n",
    "            sys.executable,\n",
    "            \"-m\",\n",
    "            \"pip\",\n",
    "            \"install\",\n",
    "            \"--no-index\",\n",
    "            \"--find-links\",\n",
    "            str(wheel_dir),\n",
    "            \"--no-deps\",\n",
    "            str(wheel_path),\n",
    "        ]\n",
    "        print(\"[DINO] instalando:\", \" \".join(cmd))\n",
    "        subprocess.check_call(cmd)\n",
    "\n",
    "        try:\n",
    "            hub_ver = importlib_metadata.version(\"huggingface-hub\")\n",
    "        except Exception:\n",
    "            hub_ver = None\n",
    "        if not _is_ok(hub_ver):\n",
    "            raise RuntimeError(f\"[DINO] huggingface-hub ainda incompatível após instalação (versão={hub_ver}).\")\n",
    "        print(\"[DINO] huggingface-hub OK:\", hub_ver)\n",
    "\n",
    "    _ensure_hf_hub_compat()\n",
    "\n",
    "    try:\n",
    "        from transformers import AutoImageProcessor, AutoModel\n",
    "    except Exception:\n",
    "        print(\"[ERRO] transformers não disponível. Inclua no bundle offline.\")\n",
    "        raise\n",
    "\n",
    "    DINO_PATH = os.environ.get(\"FORGERYSEG_DINO_PATH\", \"/kaggle/input/dinov2/pytorch/base/1\")\n",
    "    DINO_IMAGE_SIZE = int(os.environ.get(\"FORGERYSEG_DINO_IMAGE_SIZE\", \"512\"))\n",
    "    DINO_BATCH_SIZE = int(os.environ.get(\"FORGERYSEG_DINO_BATCH_SIZE\", \"4\"))\n",
    "    DINO_EPOCHS = int(os.environ.get(\"FORGERYSEG_DINO_EPOCHS\", \"5\"))\n",
    "    DINO_LR = float(os.environ.get(\"FORGERYSEG_DINO_LR\", \"3e-4\"))\n",
    "    DINO_WEIGHT_DECAY = float(os.environ.get(\"FORGERYSEG_DINO_WEIGHT_DECAY\", \"1e-2\"))\n",
    "    DINO_LOCAL_FILES_ONLY = _env_bool(\"FORGERYSEG_DINO_LOCAL_ONLY\", default=True)\n",
    "    DINO_DECODER_DROPOUT = float(os.environ.get(\"FORGERYSEG_DINO_DECODER_DROPOUT\", \"0.0\"))\n",
    "    DINO_SAVE_DIR = (Path(\"/kaggle/working\") if is_kaggle() else Path(\".\").resolve()) / \"outputs\" / \"models_dino\"\n",
    "    DINO_SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    DINO_CKPT_PATH = DINO_SAVE_DIR / \"best.pt\"\n",
    "\n",
    "    # Pós-processamento (adaptativo)\n",
    "    DINO_THR_FACTOR = float(os.environ.get(\"FORGERYSEG_DINO_THR_FACTOR\", \"0.3\"))\n",
    "    DINO_MIN_AREA = int(os.environ.get(\"FORGERYSEG_DINO_MIN_AREA\", \"30\"))\n",
    "    DINO_MIN_AREA_PERCENT = float(os.environ.get(\"FORGERYSEG_DINO_MIN_AREA_PERCENT\", \"0.0005\"))\n",
    "    DINO_MIN_CONFIDENCE = float(os.environ.get(\"FORGERYSEG_DINO_MIN_CONFIDENCE\", \"0.33\"))\n",
    "    DINO_MORPH_CLOSE_K = int(os.environ.get(\"FORGERYSEG_DINO_CLOSE_K\", \"5\"))\n",
    "    DINO_MORPH_OPEN_K = int(os.environ.get(\"FORGERYSEG_DINO_OPEN_K\", \"3\"))\n",
    "    DINO_MORPH_ITERS = int(os.environ.get(\"FORGERYSEG_DINO_MORPH_ITERS\", \"1\"))\n",
    "    DINO_USE_TTA = _env_bool(\"FORGERYSEG_DINO_TTA\", default=True)\n",
    "\n",
    "    print(\"DINO_PATH:\", DINO_PATH)\n",
    "    print(\"DINO_IMAGE_SIZE:\", DINO_IMAGE_SIZE)\n",
    "    print(\"DINO_BATCH_SIZE:\", DINO_BATCH_SIZE)\n",
    "    print(\"DINO_EPOCHS:\", DINO_EPOCHS)\n",
    "    print(\"DINO_THR_FACTOR:\", DINO_THR_FACTOR)\n",
    "    print(\"DINO_MIN_AREA:\", DINO_MIN_AREA, \"DINO_MIN_AREA_PERCENT:\", DINO_MIN_AREA_PERCENT)\n",
    "    print(\"DINO_MIN_CONFIDENCE:\", DINO_MIN_CONFIDENCE)\n",
    "    print(\"DINO_USE_TTA:\", DINO_USE_TTA)\n",
    "\n",
    "    if str(DINO_PATH).startswith(\"/\") and not Path(DINO_PATH).exists():\n",
    "        raise FileNotFoundError(f\"[DINO] caminho não encontrado: {DINO_PATH}\")\n",
    "\n",
    "    class DinoSeg(nn.Module):\n",
    "        def __init__(self, dino_path: str, out_ch: int = 1):\n",
    "            super().__init__()\n",
    "            self.processor = AutoImageProcessor.from_pretrained(\n",
    "                dino_path,\n",
    "                local_files_only=DINO_LOCAL_FILES_ONLY,\n",
    "            )\n",
    "            self.encoder = AutoModel.from_pretrained(\n",
    "                dino_path,\n",
    "                local_files_only=DINO_LOCAL_FILES_ONLY,\n",
    "            )\n",
    "            for p in self.encoder.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "            hidden_size = int(getattr(self.encoder.config, \"hidden_size\", 768))\n",
    "            self.head = nn.Sequential(\n",
    "                nn.Conv2d(hidden_size, 256, 3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout2d(p=float(DINO_DECODER_DROPOUT)),\n",
    "                nn.Conv2d(256, 64, 3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(64, out_ch, 1),\n",
    "            )\n",
    "\n",
    "        @torch.no_grad()\n",
    "        def forward_features(self, x: torch.Tensor) -> torch.Tensor:\n",
    "            # x: [B, C, H, W] float32 em [0,1]\n",
    "            imgs = (x * 255.0).clamp(0, 255).to(torch.uint8)\n",
    "            imgs = imgs.permute(0, 2, 3, 1).cpu().numpy()\n",
    "            inputs = self.processor(\n",
    "                images=list(imgs),\n",
    "                return_tensors=\"pt\",\n",
    "                do_resize=False,\n",
    "                do_center_crop=False,\n",
    "            ).to(x.device)\n",
    "            feats = self.encoder(**inputs).last_hidden_state  # B, N, C\n",
    "            feats = feats[:, 1:, :]\n",
    "            b, n, c = feats.shape\n",
    "            s = int(np.sqrt(n))\n",
    "            fmap = feats.permute(0, 2, 1).reshape(b, c, s, s)\n",
    "            return fmap\n",
    "\n",
    "        def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "            fmap = self.forward_features(x)\n",
    "            logits = self.head(\n",
    "                torch.nn.functional.interpolate(\n",
    "                    fmap,\n",
    "                    size=(x.shape[2], x.shape[3]),\n",
    "                    mode=\"bilinear\",\n",
    "                    align_corners=False,\n",
    "                )\n",
    "            )\n",
    "            return logits\n",
    "\n",
    "    def _load_union_mask(mask_path: Path | None, out_size: int) -> np.ndarray:\n",
    "        if mask_path is None:\n",
    "            return np.zeros((out_size, out_size), dtype=np.uint8)\n",
    "        masks = np.load(mask_path)\n",
    "        if masks.ndim == 2:\n",
    "            union = masks\n",
    "        else:\n",
    "            union = masks.max(axis=0)\n",
    "        union = (union > 0).astype(np.uint8)\n",
    "        if union.shape != (out_size, out_size):\n",
    "            union = cv2.resize(union, (out_size, out_size), interpolation=cv2.INTER_NEAREST)\n",
    "        return union\n",
    "\n",
    "    class DinoSegDataset(Dataset):\n",
    "        def __init__(self, samples, image_size: int, train: bool):\n",
    "            self.samples = samples\n",
    "            self.image_size = int(image_size)\n",
    "            self.train = bool(train)\n",
    "\n",
    "        def __len__(self) -> int:\n",
    "            return len(self.samples)\n",
    "\n",
    "        def __getitem__(self, idx: int):\n",
    "            s = self.samples[int(idx)]\n",
    "            img = np.array(Image.open(s.image_path).convert(\"RGB\"))\n",
    "            img = cv2.resize(img, (self.image_size, self.image_size), interpolation=cv2.INTER_AREA)\n",
    "            mask = _load_union_mask(s.mask_path, self.image_size)\n",
    "\n",
    "            if self.train:\n",
    "                if np.random.rand() < 0.5:\n",
    "                    img = np.ascontiguousarray(img[:, ::-1])\n",
    "                    mask = np.ascontiguousarray(mask[:, ::-1])\n",
    "                if np.random.rand() < 0.5:\n",
    "                    img = np.ascontiguousarray(img[::-1, :])\n",
    "                    mask = np.ascontiguousarray(mask[::-1, :])\n",
    "                # rotações 90°\n",
    "                if np.random.rand() < 0.25:\n",
    "                    img = np.ascontiguousarray(np.rot90(img, k=1))\n",
    "                    mask = np.ascontiguousarray(np.rot90(mask, k=1))\n",
    "\n",
    "            x = torch.from_numpy(img).permute(2, 0, 1).float() / 255.0\n",
    "            y = torch.from_numpy(mask).unsqueeze(0).float()\n",
    "            return x, y\n",
    "\n",
    "    def _dice_from_logits(logits: torch.Tensor, targets: torch.Tensor, thr: float = 0.5, eps: float = 1e-6) -> float:\n",
    "        probs = torch.sigmoid(logits)\n",
    "        preds = (probs > thr).float()\n",
    "        inter = (preds * targets).sum(dim=(2, 3))\n",
    "        union = preds.sum(dim=(2, 3)) + targets.sum(dim=(2, 3))\n",
    "        dice = (2.0 * inter + eps) / (union + eps)\n",
    "        return float(dice.mean().item())\n",
    "\n",
    "    def _adaptive_threshold_value(prob: np.ndarray, factor: float = 0.3, eps: float = 1e-6) -> float:\n",
    "        mean = float(np.mean(prob))\n",
    "        std = float(np.std(prob))\n",
    "        thr = mean + float(factor) * std\n",
    "        thr = max(float(eps), min(1.0 - float(eps), thr))\n",
    "        return float(thr)\n",
    "\n",
    "    def _remove_small_components(mask: np.ndarray, min_area: int) -> np.ndarray:\n",
    "        if int(min_area) <= 0:\n",
    "            return mask\n",
    "        num, labels, stats, _ = cv2.connectedComponentsWithStats(mask.astype(np.uint8), connectivity=8)\n",
    "        if num <= 1:\n",
    "            return mask\n",
    "        out = np.zeros_like(mask, dtype=np.uint8)\n",
    "        for idx in range(1, num):\n",
    "            area = stats[idx, cv2.CC_STAT_AREA]\n",
    "            if int(area) >= int(min_area):\n",
    "                out[labels == idx] = 1\n",
    "        return out\n",
    "\n",
    "    def _postprocess_prob(prob: np.ndarray) -> np.ndarray:\n",
    "        thr = _adaptive_threshold_value(prob, factor=DINO_THR_FACTOR)\n",
    "        mask = (prob >= thr).astype(np.uint8)\n",
    "\n",
    "        if DINO_MORPH_CLOSE_K > 0:\n",
    "            kernel = np.ones((DINO_MORPH_CLOSE_K, DINO_MORPH_CLOSE_K), np.uint8)\n",
    "            mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=int(DINO_MORPH_ITERS))\n",
    "        if DINO_MORPH_OPEN_K > 0:\n",
    "            kernel = np.ones((DINO_MORPH_OPEN_K, DINO_MORPH_OPEN_K), np.uint8)\n",
    "            mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=int(DINO_MORPH_ITERS))\n",
    "\n",
    "        min_area = int(DINO_MIN_AREA)\n",
    "        if float(DINO_MIN_AREA_PERCENT) > 0:\n",
    "            min_area = max(min_area, int(float(DINO_MIN_AREA_PERCENT) * float(mask.size)))\n",
    "        mask = _remove_small_components(mask, min_area=min_area)\n",
    "\n",
    "        if int(mask.sum()) <= 0:\n",
    "            return mask\n",
    "\n",
    "        if float(DINO_MIN_CONFIDENCE) > 0:\n",
    "            conf = float(prob[mask > 0].mean())\n",
    "            if conf < float(DINO_MIN_CONFIDENCE):\n",
    "                return np.zeros_like(mask, dtype=np.uint8)\n",
    "        return mask\n",
    "\n",
    "    dino_model: DinoSeg | None = None\n",
    "    if RUN_TRAIN_DINO:\n",
    "        ds_dino_train = DinoSegDataset([train_samples[i] for i in train_idx.tolist()], DINO_IMAGE_SIZE, train=True)\n",
    "        ds_dino_val = DinoSegDataset([train_samples[i] for i in val_idx.tolist()], DINO_IMAGE_SIZE, train=False)\n",
    "        dl_dino_train = DataLoader(ds_dino_train, batch_size=DINO_BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=(DEVICE == \"cuda\"), drop_last=True)\n",
    "        dl_dino_val = DataLoader(ds_dino_val, batch_size=DINO_BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=(DEVICE == \"cuda\"), drop_last=False)\n",
    "\n",
    "        dino_model = DinoSeg(DINO_PATH).to(DEVICE)\n",
    "        dino_optimizer = torch.optim.AdamW(dino_model.head.parameters(), lr=DINO_LR, weight_decay=DINO_WEIGHT_DECAY)\n",
    "        dino_loss = nn.BCEWithLogitsLoss()\n",
    "        dino_scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE == \"cuda\"))\n",
    "\n",
    "        best_dice = -1.0\n",
    "        best_epoch = 0\n",
    "        for epoch in range(1, int(DINO_EPOCHS) + 1):\n",
    "            dino_model.train()\n",
    "            tr_losses = []\n",
    "            for xb, yb in tqdm(dl_dino_train, desc=\"dino train\", leave=False):\n",
    "                xb = xb.to(DEVICE, non_blocking=True)\n",
    "                yb = yb.to(DEVICE, non_blocking=True)\n",
    "                dino_optimizer.zero_grad(set_to_none=True)\n",
    "                with torch.cuda.amp.autocast(enabled=(DEVICE == \"cuda\")):\n",
    "                    logits = dino_model(xb)\n",
    "                    loss = dino_loss(logits, yb)\n",
    "                dino_scaler.scale(loss).backward()\n",
    "                dino_scaler.step(dino_optimizer)\n",
    "                dino_scaler.update()\n",
    "                tr_losses.append(float(loss.item()))\n",
    "\n",
    "            dino_model.eval()\n",
    "            val_dices = []\n",
    "            with torch.no_grad():\n",
    "                for xb, yb in tqdm(dl_dino_val, desc=\"dino val\", leave=False):\n",
    "                    xb = xb.to(DEVICE, non_blocking=True)\n",
    "                    yb = yb.to(DEVICE, non_blocking=True)\n",
    "                    logits = dino_model(xb)\n",
    "                    val_dices.append(_dice_from_logits(logits, yb))\n",
    "            mean_dice = float(np.mean(val_dices)) if val_dices else float(\"nan\")\n",
    "            print(f\"[DINO] epoch {epoch:02d}/{DINO_EPOCHS} | train_loss={np.mean(tr_losses):.4f} | dice@0.5={mean_dice:.4f}\")\n",
    "            if float(mean_dice) > best_dice:\n",
    "                best_dice = float(mean_dice)\n",
    "                best_epoch = int(epoch)\n",
    "                ckpt = {\n",
    "                    \"head_state\": dino_model.head.state_dict(),\n",
    "                    \"config\": {\n",
    "                        \"dino_path\": str(DINO_PATH),\n",
    "                        \"image_size\": int(DINO_IMAGE_SIZE),\n",
    "                        \"thr_factor\": float(DINO_THR_FACTOR),\n",
    "                        \"min_area\": int(DINO_MIN_AREA),\n",
    "                        \"min_area_percent\": float(DINO_MIN_AREA_PERCENT),\n",
    "                        \"min_confidence\": float(DINO_MIN_CONFIDENCE),\n",
    "                    },\n",
    "                    \"score\": float(best_dice),\n",
    "                }\n",
    "                torch.save(ckpt, DINO_CKPT_PATH)\n",
    "                print(\"[DINO] saved best ->\", DINO_CKPT_PATH)\n",
    "            if best_epoch and (int(epoch) - int(best_epoch) >= 3):\n",
    "                print(\"[DINO] early stopping: sem melhora por 3 épocas.\")\n",
    "                break\n",
    "\n",
    "        print(\"[DINO] done. best dice:\", best_dice)\n",
    "    else:\n",
    "        print(\"[DINO] RUN_TRAIN_DINO=False (pulando treino).\")\n",
    "\n",
    "    if dino_model is None:\n",
    "        if not DINO_CKPT_PATH.exists():\n",
    "            raise FileNotFoundError(f\"[DINO] checkpoint não encontrado: {DINO_CKPT_PATH}\")\n",
    "        dino_model = DinoSeg(DINO_PATH).to(DEVICE)\n",
    "        ckpt = torch.load(DINO_CKPT_PATH, map_location=DEVICE)\n",
    "        dino_model.head.load_state_dict(ckpt[\"head_state\"])\n",
    "        dino_model.eval()\n",
    "        print(\"[DINO] carregado checkpoint ->\", DINO_CKPT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dfc96e",
   "metadata": {},
   "source": [
    "## Fase 4 — Geração de `submission.csv` (roteiro oficial)\n",
    "\n",
    "A competição pede **segmentação** de regiões de copy-move e usa uma variante do **F1-score**,\n",
    "portanto o foco é equilibrar precisão e recall. A métrica oficial usa **RLE (Run-Length Encoding)**.\n",
    "\n",
    "Abaixo está o **roteiro completo** para montar o notebook de submissão:\n",
    "\n",
    "### 1) Importar bibliotecas e ler dados\n",
    "- Define os caminhos de treino e teste no Kaggle.\n",
    "- Lista as imagens de teste para gerar o CSV.\n",
    "\n",
    "### 2) Funções de codificação RLE\n",
    "- Usa RLE para converter máscaras binárias em string.\n",
    "\n",
    "### 3) Lógica de predição (baseline)\n",
    "- Baseline simples: assume todas as imagens como `authentic`.\n",
    "- Opcional: gerar máscara via modelo e converter para RLE.\n",
    "\n",
    "### 4) Gerar e salvar o arquivo de submissão\n",
    "- Salva `submission.csv` em `/kaggle/working/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaf4805",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Fase 4 — Célula 8: Imports + leitura de dados (roteiro oficial)\n",
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# No Kaggle, o dataset costuma ficar aqui; se não existir, usa o DATA_ROOT detectado.\n",
    "DATA_DIR = Path(\"/kaggle/input/recodai-luc-scientific-image-forgery-detection\")\n",
    "if not DATA_DIR.exists():\n",
    "    DATA_DIR = DATA_ROOT\n",
    "\n",
    "TRAIN_DIR = DATA_DIR / \"train_images\"\n",
    "TEST_DIR = DATA_DIR / \"test_images\"\n",
    "TRAIN_MASKS = DATA_DIR / \"train_masks\"  # se houver\n",
    "\n",
    "VALID_EXTS = {\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\"}\n",
    "test_images = sorted([p for p in TEST_DIR.iterdir() if p.suffix.lower() in VALID_EXTS])\n",
    "test_by_id = {p.stem: p for p in test_images}\n",
    "\n",
    "sample_submission_path = DATA_DIR / \"sample_submission.csv\"\n",
    "sample_submission = None\n",
    "case_ids = [p.stem for p in test_images]\n",
    "if sample_submission_path.exists():\n",
    "    sample_submission = pd.read_csv(sample_submission_path)\n",
    "    if \"case_id\" in sample_submission.columns:\n",
    "        case_ids = sample_submission[\"case_id\"].tolist()\n",
    "\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"TEST_DIR:\", TEST_DIR)\n",
    "print(\"#test images:\", len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cbc860",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Fase 4 — Célula 9: Funções RLE (roteiro oficial)\n",
    "# A métrica oficial usa JSON para a lista de pares [start, length, ...]\n",
    "# e suporta múltiplas instâncias separadas por ';'.\n",
    "def _rle_encode_single(mask: np.ndarray, fg_val: int = 1) -> list[int]:\n",
    "    # Kaggle oficial usa ordem coluna-major (Fortran).\n",
    "    dots = np.where(mask.flatten(order=\"F\") == fg_val)[0]\n",
    "    run_lengths: list[int] = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        b = int(b)\n",
    "        if b > prev + 1:\n",
    "            run_lengths.extend([b + 1, 0])  # start 1-based\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "\n",
    "def rle_encode(masks: list[np.ndarray] | np.ndarray, fg_val: int = 1) -> str:\n",
    "    if isinstance(masks, np.ndarray):\n",
    "        masks = [masks]\n",
    "    parts: list[str] = []\n",
    "    for m in masks:\n",
    "        runs = _rle_encode_single(m, fg_val=fg_val)\n",
    "        if runs:\n",
    "            parts.append(json.dumps(runs))\n",
    "    if not parts:\n",
    "        return \"authentic\"\n",
    "    return \";\".join(parts)\n",
    "\n",
    "\n",
    "def encode_submission(mask_union: np.ndarray) -> str:\n",
    "    if int(mask_union.sum()) <= 0:\n",
    "        return \"authentic\"\n",
    "    return rle_encode(mask_union.astype(np.uint8))\n",
    "\n",
    "\n",
    "def rle_decode(annotation: str, shape: tuple[int, int]) -> list[np.ndarray]:\n",
    "    text = annotation.strip()\n",
    "    if text == \"\" or text.lower() == \"authentic\":\n",
    "        return []\n",
    "    masks: list[np.ndarray] = []\n",
    "    for part in text.split(\";\"):\n",
    "        part = part.strip()\n",
    "        if not part:\n",
    "            continue\n",
    "        runs = json.loads(part)\n",
    "        mask = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "        for start, length in zip(runs[0::2], runs[1::2]):\n",
    "            if int(length) <= 0:\n",
    "                continue\n",
    "            start_index = int(start) - 1  # 1-based -> 0-based\n",
    "            end_index = start_index + int(length)\n",
    "            mask[start_index:end_index] = 1\n",
    "        masks.append(mask.reshape(shape, order=\"F\"))\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fb4f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 4 — Célula 10: Baseline simples (tudo authentic)\n",
    "if sample_submission is not None:\n",
    "    submissions = sample_submission.copy()\n",
    "    submissions[\"annotation\"] = \"authentic\"\n",
    "else:\n",
    "    submissions = pd.DataFrame(\n",
    "        {\n",
    "            \"case_id\": case_ids,\n",
    "            \"annotation\": [\"authentic\"] * len(case_ids),\n",
    "        }\n",
    "    )\n",
    "\n",
    "submissions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a91d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 4 — Célula 11: Exemplo de loop com modelo (opcional)\n",
    "# Ative com FORGERYSEG_USE_MODEL_SUBMISSION=1 e defina `model`.\n",
    "USE_MODEL_SUBMISSION = _env_bool(\"FORGERYSEG_USE_MODEL_SUBMISSION\", default=False)\n",
    "THRESHOLD = float(os.environ.get(\"FORGERYSEG_SUBMISSION_THRESHOLD\", \"0.5\"))\n",
    "\n",
    "submissions_from_model = None\n",
    "if USE_MODEL_SUBMISSION:\n",
    "    if \"model\" not in globals():\n",
    "        raise RuntimeError(\"Defina a variável `model` antes de ativar FORGERYSEG_USE_MODEL_SUBMISSION=1.\")\n",
    "\n",
    "    USE_TTA = _env_bool(\"FORGERYSEG_TTA\", default=True)\n",
    "    TTA_MODES = (\"none\", \"hflip\", \"vflip\", \"rot90\", \"rot180\", \"rot270\")\n",
    "\n",
    "    def _apply_tta(image: np.ndarray, mode: str) -> np.ndarray:\n",
    "        if mode == \"none\":\n",
    "            return image\n",
    "        if mode == \"hflip\":\n",
    "            return np.ascontiguousarray(image[:, ::-1])\n",
    "        if mode == \"vflip\":\n",
    "            return np.ascontiguousarray(image[::-1, :])\n",
    "        if mode == \"rot90\":\n",
    "            return np.ascontiguousarray(np.rot90(image, k=1))\n",
    "        if mode == \"rot180\":\n",
    "            return np.ascontiguousarray(np.rot90(image, k=2))\n",
    "        if mode == \"rot270\":\n",
    "            return np.ascontiguousarray(np.rot90(image, k=3))\n",
    "        raise ValueError(f\"TTA mode inválido: {mode}\")\n",
    "\n",
    "    def _undo_tta(mask: np.ndarray, mode: str) -> np.ndarray:\n",
    "        if mode == \"none\":\n",
    "            return mask\n",
    "        if mode == \"hflip\":\n",
    "            return np.ascontiguousarray(mask[:, ::-1])\n",
    "        if mode == \"vflip\":\n",
    "            return np.ascontiguousarray(mask[::-1, :])\n",
    "        if mode == \"rot90\":\n",
    "            return np.ascontiguousarray(np.rot90(mask, k=3))\n",
    "        if mode == \"rot180\":\n",
    "            return np.ascontiguousarray(np.rot90(mask, k=2))\n",
    "        if mode == \"rot270\":\n",
    "            return np.ascontiguousarray(np.rot90(mask, k=1))\n",
    "        raise ValueError(f\"TTA mode inválido: {mode}\")\n",
    "\n",
    "    def _default_predict_fn(image: np.ndarray) -> np.ndarray:\n",
    "        if hasattr(model, \"predict\"):\n",
    "            pred = model.predict(image[None])[0]\n",
    "        else:\n",
    "            from forgeryseg.inference import predict_image\n",
    "\n",
    "            pred = predict_image(model, image, DEVICE)\n",
    "        pred = np.asarray(pred)\n",
    "        if pred.ndim > 2:\n",
    "            pred = np.squeeze(pred)\n",
    "        if pred.ndim != 2:\n",
    "            raise ValueError(f\"Predição esperada HxW, obtido shape={pred.shape}\")\n",
    "        return pred.astype(np.float32)\n",
    "\n",
    "    def _tta_predict(image: np.ndarray) -> np.ndarray:\n",
    "        if not USE_TTA:\n",
    "            return _default_predict_fn(image)\n",
    "        preds = []\n",
    "        for mode in TTA_MODES:\n",
    "            img_t = _apply_tta(image, mode)\n",
    "            pred_t = _default_predict_fn(img_t)\n",
    "            pred = _undo_tta(pred_t, mode)\n",
    "            preds.append(pred)\n",
    "        return np.mean(preds, axis=0)\n",
    "\n",
    "    annotations = []\n",
    "    for case_id in case_ids:\n",
    "        key = str(case_id)\n",
    "        if key not in test_by_id:\n",
    "            raise FileNotFoundError(f\"Não encontrei imagem para case_id={case_id!r}\")\n",
    "        img_path = test_by_id[key]\n",
    "        # carregue e processe a imagem\n",
    "        img = np.array(Image.open(img_path)) / 255.0\n",
    "        # modelo deve gerar um mapa de probabilidade ou máscara\n",
    "        pred_prob = _tta_predict(img)\n",
    "        binary_mask = (pred_prob > THRESHOLD).astype(np.uint8)\n",
    "        annotations.append(encode_submission(binary_mask))\n",
    "\n",
    "    submissions_from_model = pd.DataFrame(\n",
    "        {\n",
    "            \"case_id\": case_ids,\n",
    "            \"annotation\": annotations,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    submissions_from_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dd79d0",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Fase 4 — Célula 11b: Submissão DINO-only (offline)\n",
    "submissions_from_dino = None\n",
    "if DINO_ONLY:\n",
    "    if dino_model is None:\n",
    "        raise RuntimeError(\"[DINO] modelo não carregado.\")\n",
    "\n",
    "    dino_model.eval()\n",
    "\n",
    "    TTA_MODES = (\"none\", \"hflip\", \"vflip\", \"rot90\", \"rot180\", \"rot270\")\n",
    "\n",
    "    def _apply_tta(img: np.ndarray, mode: str) -> np.ndarray:\n",
    "        if mode == \"none\":\n",
    "            return img\n",
    "        if mode == \"hflip\":\n",
    "            return np.ascontiguousarray(img[:, ::-1])\n",
    "        if mode == \"vflip\":\n",
    "            return np.ascontiguousarray(img[::-1, :])\n",
    "        if mode == \"rot90\":\n",
    "            return np.ascontiguousarray(np.rot90(img, k=1))\n",
    "        if mode == \"rot180\":\n",
    "            return np.ascontiguousarray(np.rot90(img, k=2))\n",
    "        if mode == \"rot270\":\n",
    "            return np.ascontiguousarray(np.rot90(img, k=3))\n",
    "        raise ValueError(f\"TTA mode inválido: {mode}\")\n",
    "\n",
    "    def _undo_tta(mask: np.ndarray, mode: str) -> np.ndarray:\n",
    "        if mode == \"none\":\n",
    "            return mask\n",
    "        if mode == \"hflip\":\n",
    "            return np.ascontiguousarray(mask[:, ::-1])\n",
    "        if mode == \"vflip\":\n",
    "            return np.ascontiguousarray(mask[::-1, :])\n",
    "        if mode == \"rot90\":\n",
    "            return np.ascontiguousarray(np.rot90(mask, k=3))\n",
    "        if mode == \"rot180\":\n",
    "            return np.ascontiguousarray(np.rot90(mask, k=2))\n",
    "        if mode == \"rot270\":\n",
    "            return np.ascontiguousarray(np.rot90(mask, k=1))\n",
    "        raise ValueError(f\"TTA mode inválido: {mode}\")\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _dino_predict_prob(img_rgb: np.ndarray) -> np.ndarray:\n",
    "        orig_h, orig_w = img_rgb.shape[:2]\n",
    "        img_rs = cv2.resize(img_rgb, (DINO_IMAGE_SIZE, DINO_IMAGE_SIZE), interpolation=cv2.INTER_AREA)\n",
    "        x = torch.from_numpy(img_rs).permute(2, 0, 1).float().unsqueeze(0) / 255.0\n",
    "        x = x.to(DEVICE)\n",
    "        logits = dino_model(x)\n",
    "        prob = torch.sigmoid(logits)[0, 0].detach().cpu().numpy().astype(np.float32)\n",
    "        if prob.shape != (orig_h, orig_w):\n",
    "            prob = cv2.resize(prob, (orig_w, orig_h), interpolation=cv2.INTER_LINEAR)\n",
    "        return prob\n",
    "\n",
    "    def _dino_tta_predict(img_rgb: np.ndarray) -> np.ndarray:\n",
    "        if not DINO_USE_TTA:\n",
    "            return _dino_predict_prob(img_rgb)\n",
    "        preds = []\n",
    "        for mode in TTA_MODES:\n",
    "            img_t = _apply_tta(img_rgb, mode)\n",
    "            prob_t = _dino_predict_prob(img_t)\n",
    "            prob = _undo_tta(prob_t, mode)\n",
    "            preds.append(prob)\n",
    "        return np.mean(preds, axis=0).astype(np.float32)\n",
    "\n",
    "    annotations = []\n",
    "    for case_id in case_ids:\n",
    "        key = str(case_id)\n",
    "        if key not in test_by_id:\n",
    "            raise FileNotFoundError(f\"[DINO] imagem não encontrada para case_id={case_id!r}\")\n",
    "        img_path = test_by_id[key]\n",
    "        img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        prob = _dino_tta_predict(img)\n",
    "        mask = _postprocess_prob(prob)\n",
    "        annotations.append(encode_submission(mask))\n",
    "\n",
    "    submissions_from_dino = pd.DataFrame(\n",
    "        {\n",
    "            \"case_id\": case_ids,\n",
    "            \"annotation\": annotations,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    submissions_from_dino.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea423ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 4 — Célula 12: Salvar submission.csv (roteiro oficial)\n",
    "def output_root() -> Path:\n",
    "    return Path(\"/kaggle/working\") if is_kaggle() else Path(\".\").resolve()\n",
    "\n",
    "\n",
    "def _write_submission_csv(submissions_to_save: pd.DataFrame) -> Path:\n",
    "    submission_path = output_root() / \"submission.csv\"\n",
    "    pd.DataFrame(submissions_to_save).to_csv(submission_path, index=False)\n",
    "    return submission_path\n",
    "\n",
    "\n",
    "RUN_SUBMISSION_SIMPLE = _env_bool(\"FORGERYSEG_RUN_SUBMISSION_SIMPLE\", default=False)\n",
    "print(\"RUN_SUBMISSION_SIMPLE:\", RUN_SUBMISSION_SIMPLE)\n",
    "\n",
    "if RUN_SUBMISSION_SIMPLE:\n",
    "    if DINO_ONLY and submissions_from_dino is not None:\n",
    "        submissions_to_save = submissions_from_dino\n",
    "    else:\n",
    "        submissions_to_save = submissions_from_model if USE_MODEL_SUBMISSION else submissions\n",
    "    submission_path = _write_submission_csv(submissions_to_save)\n",
    "    print(\"Wrote:\", submission_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba45366",
   "metadata": {},
   "source": [
    "## Fase 4b — Submissão via `submit_ensemble.py` (opcional)\n",
    "\n",
    "- Usa os checkpoints em `outputs/models_seg/...`.\n",
    "- Respeita o `configs/infer_ensemble.json` (inclui gate do classificador e pesos do ensemble).\n",
    "\n",
    "Para desligar/ligar: `FORGERYSEG_RUN_SUBMISSION_SCRIPT=0|1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae832e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 4b — Célula 13: Gerar submission.csv via script (opcional)\n",
    "RUN_SUBMISSION_SCRIPT = _env_bool(\"FORGERYSEG_RUN_SUBMISSION_SCRIPT\", default=bool(is_kaggle() and not DINO_ONLY))\n",
    "print(\"RUN_SUBMISSION_SCRIPT:\", RUN_SUBMISSION_SCRIPT)\n",
    "\n",
    "\n",
    "def _find_submit_ensemble_script() -> Path:\n",
    "    candidates: list[Path] = []\n",
    "    if PROJECT_ROOT is not None:\n",
    "        candidates.append(PROJECT_ROOT / \"scripts\" / \"submit_ensemble.py\")\n",
    "    candidates.append(Path(\"scripts/submit_ensemble.py\").resolve())\n",
    "\n",
    "    if is_kaggle():\n",
    "        ki = Path(\"/kaggle/input\")\n",
    "        if ki.exists():\n",
    "            for ds in sorted(ki.glob(\"*\")):\n",
    "                for base in (ds, ds / \"recodai_bundle\"):\n",
    "                    p = base / \"scripts\" / \"submit_ensemble.py\"\n",
    "                    if p.exists():\n",
    "                        candidates.append(p)\n",
    "\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(\n",
    "        \"Não encontrei `scripts/submit_ensemble.py`.\\n\"\n",
    "        \"- Solução (Kaggle): anexe o dataset do repositório (bundle) contendo `scripts/`.\\n\"\n",
    "        \"- Solução (local): rode a partir do root do repo (onde existe `scripts/`).\"\n",
    "    )\n",
    "\n",
    "\n",
    "def _find_infer_cfg_path() -> Path | None:\n",
    "    candidates: list[Path] = []\n",
    "    if PROJECT_ROOT is not None:\n",
    "        candidates.append(PROJECT_ROOT / \"configs\" / \"infer_ensemble.json\")\n",
    "    candidates.append(Path(\"configs/infer_ensemble.json\").resolve())\n",
    "\n",
    "    if is_kaggle():\n",
    "        ki = Path(\"/kaggle/input\")\n",
    "        if ki.exists():\n",
    "            for ds in sorted(ki.glob(\"*\")):\n",
    "                for base in (ds, ds / \"recodai_bundle\"):\n",
    "                    p = base / \"configs\" / \"infer_ensemble.json\"\n",
    "                    if p.exists():\n",
    "                        candidates.append(p)\n",
    "\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "\n",
    "def _find_models_dir_with_ckpt() -> Path | None:\n",
    "    candidates: list[Path] = []\n",
    "    if PROJECT_ROOT is not None:\n",
    "        candidates.append(PROJECT_ROOT / \"outputs\" / \"models_seg\")\n",
    "    candidates.append(Path(\"outputs/models_seg\").resolve())\n",
    "\n",
    "    if is_kaggle():\n",
    "        ki = Path(\"/kaggle/input\")\n",
    "        if ki.exists():\n",
    "            for ds in sorted(ki.glob(\"*\")):\n",
    "                for base in (ds, ds / \"recodai_bundle\"):\n",
    "                    cand = base / \"outputs\" / \"models_seg\"\n",
    "                    if cand.exists():\n",
    "                        candidates.append(cand)\n",
    "\n",
    "    for cand in candidates:\n",
    "        if any(cand.glob(\"*/*/best.pt\")):\n",
    "            return cand\n",
    "        if any(cand.glob(\"*/best.pt\")):\n",
    "            return cand\n",
    "        if any(cand.glob(\"**/best.pt\")):\n",
    "            return cand\n",
    "        if any(cand.glob(\"*/*/last.pt\")):\n",
    "            return cand\n",
    "        if any(cand.glob(\"*/last.pt\")):\n",
    "            return cand\n",
    "        if any(cand.glob(\"**/last.pt\")):\n",
    "            return cand\n",
    "    return None\n",
    "\n",
    "\n",
    "if RUN_SUBMISSION_SCRIPT:\n",
    "    submit_script = _find_submit_ensemble_script()\n",
    "    infer_cfg_path = _find_infer_cfg_path()\n",
    "\n",
    "    submission_path = output_root() / \"submission.csv\"\n",
    "    models_dir = _find_models_dir_with_ckpt()\n",
    "    if models_dir is None:\n",
    "        raise RuntimeError(\"[SUBMISSION] nenhum checkpoint encontrado em outputs/models_seg.\")\n",
    "\n",
    "    cmd = [\n",
    "        sys.executable,\n",
    "        str(submit_script),\n",
    "        \"--data-root\",\n",
    "        str(DATA_ROOT),\n",
    "        \"--out-csv\",\n",
    "        str(submission_path),\n",
    "    ]\n",
    "    cmd += [\"--models-dir\", str(models_dir)]\n",
    "    if infer_cfg_path is not None:\n",
    "        cmd += [\"--config\", str(infer_cfg_path)]\n",
    "\n",
    "    print(\"[SUBMISSION] script:\", submit_script)\n",
    "    if infer_cfg_path is not None:\n",
    "        print(\"[SUBMISSION] cfg:\", infer_cfg_path)\n",
    "    print(\"[SUBMISSION] running:\", \" \".join(cmd))\n",
    "    subprocess.check_call(cmd)\n",
    "    print(\"[SUBMISSION] wrote:\", submission_path)\n",
    "else:\n",
    "    print(\"[SUBMISSION] RUN_SUBMISSION_SCRIPT=False (pulando).\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent",
   "main_language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
