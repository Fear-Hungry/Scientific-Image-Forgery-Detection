{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "deb5af58",
   "metadata": {},
   "source": [
    "# Pipeline único — Fases 1→4 (Kaggle / Offline)\n",
    "\n",
    "Este notebook junta tudo em um só lugar:\n",
    "\n",
    "1) **Setup offline + checagens**\n",
    "2) **Treino do classificador** (authentic vs forged) *(opcional)*\n",
    "3) **Treino do segmentador** (máscara de duplicação) *(opcional)*\n",
    "4) **Inferência + submissão** (`submission.csv`)\n",
    "\n",
    "## Regras / Decisões\n",
    "- Notebook-only (não importa `src/forgeryseg/`).\n",
    "- Compatível com Kaggle **internet OFF** (instala wheels locais se existirem).\n",
    "- Não esconde erros: exceções e tracebacks aparecem explicitamente.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8702340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 1: Sanidade Kaggle (lembrete)\n",
    "print(\"Kaggle submission constraints (lembrete):\")\n",
    "print(\"- Submissions via Notebook\")\n",
    "print(\"- Runtime <= 4h (CPU/GPU)\")\n",
    "print(\"- Internet: OFF no submit\")\n",
    "print(\"- Output: /kaggle/working/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3c490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 2: Imports + ambiente\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import traceback\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "warnings.simplefilter(\"default\")\n",
    "os.environ.setdefault(\"NO_ALBUMENTATIONS_UPDATE\", \"1\")\n",
    "\n",
    "\n",
    "def is_kaggle() -> bool:\n",
    "    return bool(os.environ.get(\"KAGGLE_URL_BASE\")) or Path(\"/kaggle\").exists()\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(\"python:\", sys.version.split()[0])\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "print(\"device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b16948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 2b: Instalação offline (wheels) — NÃO resolve deps (evita puxar nvidia-cuda-*)\n",
    "#\n",
    "# Estruturas suportadas:\n",
    "# - `/kaggle/input/<dataset>/wheels/*.whl`\n",
    "# - `/kaggle/input/<dataset>/recodai_bundle/wheels/*.whl`\n",
    "#\n",
    "# Observação: instalamos com `--no-deps` para não tentar instalar dependências do torch offline.\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def _find_offline_bundle() -> Path | None:\n",
    "    if not is_kaggle():\n",
    "        return None\n",
    "    kaggle_input = Path(\"/kaggle/input\")\n",
    "    if not kaggle_input.exists():\n",
    "        return None\n",
    "\n",
    "    candidates: list[Path] = []\n",
    "    for ds in sorted(kaggle_input.glob(\"*\")):\n",
    "        for base in (ds, ds / \"recodai_bundle\"):\n",
    "            if (base / \"wheels\").exists():\n",
    "                candidates.append(base)\n",
    "\n",
    "    if not candidates:\n",
    "        return None\n",
    "    if len(candidates) > 1:\n",
    "        print(\"[OFFLINE INSTALL] múltiplos bundles com wheels encontrados; usando o primeiro:\")\n",
    "        for c in candidates:\n",
    "            print(\" -\", c)\n",
    "    return candidates[0]\n",
    "\n",
    "\n",
    "OFFLINE_BUNDLE = _find_offline_bundle()\n",
    "if OFFLINE_BUNDLE is None:\n",
    "    print(\"[OFFLINE INSTALL] nenhum bundle com `wheels/` encontrado em `/kaggle/input`.\")\n",
    "else:\n",
    "    wheel_dir = OFFLINE_BUNDLE / \"wheels\"\n",
    "    whls = sorted(str(p) for p in wheel_dir.glob(\"*.whl\"))\n",
    "    print(\"[OFFLINE INSTALL] bundle:\", OFFLINE_BUNDLE)\n",
    "    print(\"[OFFLINE INSTALL] wheels:\", len(whls))\n",
    "    if not whls:\n",
    "        print(\"[OFFLINE INSTALL] aviso: diretório `wheels/` existe mas não há `.whl`.\")\n",
    "    else:\n",
    "        cmd = [\n",
    "            sys.executable,\n",
    "            \"-m\",\n",
    "            \"pip\",\n",
    "            \"install\",\n",
    "            \"--no-index\",\n",
    "            \"--find-links\",\n",
    "            str(wheel_dir),\n",
    "            \"--no-deps\",\n",
    "            *whls,\n",
    "        ]\n",
    "        print(\"[OFFLINE INSTALL] executando:\", \" \".join(cmd[:9]), \"...\", f\"(+{len(whls)} wheels)\")\n",
    "        subprocess.check_call(cmd)\n",
    "        print(\"[OFFLINE INSTALL] OK.\")\n",
    "\n",
    "\n",
    "def _is_competition_dataset_dir(path: Path) -> bool:\n",
    "    return (path / \"train_images\").exists() or (path / \"test_images\").exists() or (path / \"train_masks\").exists()\n",
    "\n",
    "\n",
    "def _candidate_python_roots(base: Path) -> list[Path]:\n",
    "    roots = [\n",
    "        base,\n",
    "        base / \"src\",\n",
    "        base / \"vendor\",\n",
    "        base / \"third_party\",\n",
    "        base / \"recodai_bundle\",\n",
    "        base / \"recodai_bundle\" / \"src\",\n",
    "        base / \"recodai_bundle\" / \"vendor\",\n",
    "        base / \"recodai_bundle\" / \"third_party\",\n",
    "    ]\n",
    "    return [r for r in roots if r.exists()]\n",
    "\n",
    "\n",
    "def add_local_package_to_syspath(package_dir_name: str) -> list[Path]:\n",
    "    \"\"\"\n",
    "    Procura por `package_dir_name/__init__.py` em `/kaggle/input/*` (exceto o dataset da competição)\n",
    "    e adiciona o root correspondente ao `sys.path`.\n",
    "    \"\"\"\n",
    "    added: list[Path] = []\n",
    "    if not is_kaggle():\n",
    "        return added\n",
    "\n",
    "    kaggle_input = Path(\"/kaggle/input\")\n",
    "    if not kaggle_input.exists():\n",
    "        return added\n",
    "\n",
    "    for ds in sorted(kaggle_input.glob(\"*\")):\n",
    "        if _is_competition_dataset_dir(ds):\n",
    "            continue\n",
    "        for root in _candidate_python_roots(ds):\n",
    "            pkg = root / package_dir_name\n",
    "            if (pkg / \"__init__.py\").exists():\n",
    "                if str(root) not in sys.path:\n",
    "                    sys.path.insert(0, str(root))\n",
    "                    added.append(root)\n",
    "                continue\n",
    "            try:\n",
    "                for child in sorted(p for p in root.glob(\"*\") if p.is_dir()):\n",
    "                    pkg2 = child / package_dir_name\n",
    "                    if (pkg2 / \"__init__.py\").exists():\n",
    "                        if str(child) not in sys.path:\n",
    "                            sys.path.insert(0, str(child))\n",
    "                            added.append(child)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    if added:\n",
    "        uniq = []\n",
    "        for p in added:\n",
    "            if p not in uniq:\n",
    "                uniq.append(p)\n",
    "        print(f\"[LOCAL IMPORT] adicionado ao sys.path para '{package_dir_name}':\")\n",
    "        for p in uniq[:10]:\n",
    "            print(\" -\", p)\n",
    "        if len(uniq) > 10:\n",
    "            print(\" ...\")\n",
    "        return uniq\n",
    "\n",
    "    print(f\"[LOCAL IMPORT] não encontrei '{package_dir_name}/__init__.py' em `/kaggle/input/*` (fora do dataset da competição).\")\n",
    "    return added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ae1834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 3: Checagem de dependências (não esconde erro)\n",
    "\n",
    "\n",
    "def _try_import(module_name: str) -> None:\n",
    "    try:\n",
    "        mod = __import__(module_name)\n",
    "        ver = getattr(mod, \"__version__\", None)\n",
    "        print(f\"[OK] import {module_name}\" + (f\" ({ver})\" if ver else \"\"))\n",
    "    except Exception:\n",
    "        print(f\"[ERRO] falha ao importar: {module_name}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "\n",
    "for pkg in [\n",
    "    \"numpy\",\n",
    "    \"torch\",\n",
    "    \"torchvision\",\n",
    "    \"albumentations\",\n",
    "    \"cv2\",\n",
    "    \"timm\",\n",
    "    \"segmentation_models_pytorch\",\n",
    "    \"scipy\",\n",
    "    \"sklearn\",\n",
    "]:\n",
    "    _try_import(pkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeaed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 4: Dataset root (Kaggle/local)\n",
    "\n",
    "\n",
    "def find_dataset_root() -> Path:\n",
    "    if is_kaggle():\n",
    "        base = Path(\"/kaggle/input/recodai-luc-scientific-image-forgery-detection\")\n",
    "        if base.exists():\n",
    "            return base\n",
    "        kaggle_input = Path(\"/kaggle/input\")\n",
    "        if kaggle_input.exists():\n",
    "            for ds in sorted(kaggle_input.glob(\"*\")):\n",
    "                if (ds / \"train_images\").exists() and (ds / \"test_images\").exists():\n",
    "                    return ds\n",
    "\n",
    "    base = Path(\"data\").resolve()\n",
    "    if (base / \"train_images\").exists() and (base / \"test_images\").exists():\n",
    "        return base\n",
    "\n",
    "    raise FileNotFoundError(\n",
    "        \"Dataset não encontrado.\\n\"\n",
    "        \"- No Kaggle: anexe o dataset da competição (Add data).\\n\"\n",
    "        \"- Local: espere `data/train_images` e `data/train_masks`.\"\n",
    "    )\n",
    "\n",
    "\n",
    "DATA_ROOT = find_dataset_root()\n",
    "TRAIN_IMAGES = DATA_ROOT / \"train_images\"\n",
    "TRAIN_MASKS = DATA_ROOT / \"train_masks\"\n",
    "TEST_IMAGES = DATA_ROOT / \"test_images\"\n",
    "\n",
    "num_auth = len(list((TRAIN_IMAGES / \"authentic\").glob(\"*.png\")))\n",
    "num_forged = len(list((TRAIN_IMAGES / \"forged\").glob(\"*.png\")))\n",
    "num_masks = len(list(TRAIN_MASKS.glob(\"*.npy\")))\n",
    "num_test = len(list(TEST_IMAGES.glob(\"*.png\")))\n",
    "\n",
    "print(\"DATA_ROOT:\", DATA_ROOT)\n",
    "print(\"train/authentic:\", num_auth)\n",
    "print(\"train/forged:\", num_forged)\n",
    "print(\"train_masks:\", num_masks)\n",
    "print(\"test_images:\", num_test)\n",
    "if num_auth == 0 and num_forged == 0:\n",
    "    raise FileNotFoundError(\n",
    "        \"Nenhuma imagem encontrada em `train_images/authentic` e `train_images/forged`.\\n\"\n",
    "        f\"DATA_ROOT={DATA_ROOT}\\n\"\n",
    "        \"No Kaggle, isso normalmente significa que o dataset da competição não foi anexado.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5c30e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 5: Config global (liga/desliga)\n",
    "RUN_TRAIN_CLS = False  # mude para True se quiser treinar classificador aqui\n",
    "RUN_TRAIN_SEG = False  # mude para True se quiser treinar segmentação aqui\n",
    "RUN_SUBMISSION = True  # deixe True no submit\n",
    "\n",
    "N_FOLDS = 5\n",
    "FOLD = 0  # qual fold usar para validar/treinar (quando não for ensemble)\n",
    "\n",
    "print(\"RUN_TRAIN_CLS:\", RUN_TRAIN_CLS)\n",
    "print(\"RUN_TRAIN_SEG:\", RUN_TRAIN_SEG)\n",
    "print(\"RUN_SUBMISSION:\", RUN_SUBMISSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb0263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 2 — Célula 6: Classificador (index + split)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class ClsSample:\n",
    "    case_id: str\n",
    "    image_path: Path\n",
    "    label: int  # 0 authentic, 1 forged\n",
    "\n",
    "\n",
    "def build_cls_index(train_images_dir: Path) -> list[ClsSample]:\n",
    "    samples: list[ClsSample] = []\n",
    "    for label_name, y in [(\"authentic\", 0), (\"forged\", 1)]:\n",
    "        for img_path in sorted((train_images_dir / label_name).glob(\"*.png\")):\n",
    "            samples.append(ClsSample(case_id=img_path.stem, image_path=img_path, label=int(y)))\n",
    "    if not samples:\n",
    "        raise FileNotFoundError(f\"Nenhuma imagem encontrada em: {train_images_dir}\")\n",
    "    return samples\n",
    "\n",
    "\n",
    "cls_samples = build_cls_index(TRAIN_IMAGES)\n",
    "cls_y = np.array([s.label for s in cls_samples], dtype=np.int64)\n",
    "print(\"cls samples:\", len(cls_samples), \"auth:\", int((cls_y == 0).sum()), \"forged:\", int((cls_y == 1).sum()))\n",
    "\n",
    "try:\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "    cls_folds = np.zeros(len(cls_samples), dtype=np.int64)\n",
    "    for fold_id, (_, val_idx) in enumerate(skf.split(np.zeros(len(cls_samples)), cls_y)):\n",
    "        cls_folds[val_idx] = int(fold_id)\n",
    "except Exception:\n",
    "    print(\"[ERRO] scikit-learn falhou (StratifiedKFold). Usando split simples.\")\n",
    "    traceback.print_exc()\n",
    "    cls_folds = np.arange(len(cls_samples), dtype=np.int64) % int(N_FOLDS)\n",
    "\n",
    "cls_train_idx = np.where(cls_folds != int(FOLD))[0]\n",
    "cls_val_idx = np.where(cls_folds == int(FOLD))[0]\n",
    "print(f\"cls fold={FOLD}: train={len(cls_train_idx)} val={len(cls_val_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c326d021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 2 — Célula 7: Classificador (dataset/dataloader + modelo + treino)\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "try:\n",
    "    import torchvision.transforms as T\n",
    "except Exception:\n",
    "    print(\"[ERRO] torchvision falhou no import.\")\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except Exception:\n",
    "    print(\"[WARN] tqdm indisponível; usando loop simples.\")\n",
    "\n",
    "    def tqdm(x, **kwargs):  # type: ignore\n",
    "        return x\n",
    "\n",
    "\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "CLS_IMAGE_SIZE = 384\n",
    "CLS_BATCH_SIZE = 32\n",
    "CLS_EPOCHS = 10\n",
    "CLS_LR = 3e-4\n",
    "CLS_WEIGHT_DECAY = 1e-2\n",
    "CLS_MODEL_NAME = \"tf_efficientnet_b4_ns\"\n",
    "\n",
    "\n",
    "def build_transform(train: bool) -> T.Compose:\n",
    "    aug = []\n",
    "    if train:\n",
    "        aug += [T.RandomHorizontalFlip(p=0.5), T.RandomVerticalFlip(p=0.5)]\n",
    "    aug += [\n",
    "        T.Resize((CLS_IMAGE_SIZE, CLS_IMAGE_SIZE)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "    ]\n",
    "    return T.Compose(aug)\n",
    "\n",
    "\n",
    "class ClsDataset(Dataset):\n",
    "    def __init__(self, samples: list[ClsSample], transform: T.Compose):\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        s = self.samples[int(idx)]\n",
    "        img = Image.open(s.image_path).convert(\"RGB\")\n",
    "        x = self.transform(img)\n",
    "        y = torch.tensor([float(s.label)], dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "cls_ds_train = ClsDataset([cls_samples[i] for i in cls_train_idx.tolist()], build_transform(train=True))\n",
    "cls_ds_val = ClsDataset([cls_samples[i] for i in cls_val_idx.tolist()], build_transform(train=False))\n",
    "\n",
    "# Nota: fora de notebook (ex.: rodando .py), multiprocess pode quebrar; aqui preferimos 0 fora do Kaggle.\n",
    "CLS_NUM_WORKERS = 2 if is_kaggle() else 0\n",
    "\n",
    "cls_dl_train = DataLoader(\n",
    "    cls_ds_train,\n",
    "    batch_size=CLS_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=CLS_NUM_WORKERS,\n",
    "    pin_memory=(DEVICE == \"cuda\"),\n",
    "    drop_last=True,\n",
    ")\n",
    "cls_dl_val = DataLoader(\n",
    "    cls_ds_val,\n",
    "    batch_size=CLS_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=CLS_NUM_WORKERS,\n",
    "    pin_memory=(DEVICE == \"cuda\"),\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "try:\n",
    "    import timm\n",
    "except Exception:\n",
    "    timm = None\n",
    "    print(\"[WARN] timm indisponível; usando fallback torchvision.\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "\n",
    "def build_cls_model(model_name: str) -> nn.Module:\n",
    "    if timm is not None:\n",
    "        return timm.create_model(model_name, pretrained=False, num_classes=1)\n",
    "    from torchvision.models import resnet50\n",
    "\n",
    "    m = resnet50(weights=None)\n",
    "    m.fc = nn.Linear(m.fc.in_features, 1)\n",
    "    return m\n",
    "\n",
    "\n",
    "def _compute_pos_weight(labels: np.ndarray) -> torch.Tensor:\n",
    "    pos = float((labels == 1).sum())\n",
    "    neg = float((labels == 0).sum())\n",
    "    if pos <= 0:\n",
    "        return torch.tensor(1.0)\n",
    "    return torch.tensor(neg / max(pos, 1.0), dtype=torch.float32)\n",
    "\n",
    "\n",
    "cls_model = build_cls_model(CLS_MODEL_NAME).to(DEVICE)\n",
    "cls_pos_weight = _compute_pos_weight(cls_y[cls_train_idx]).to(DEVICE)\n",
    "cls_criterion = nn.BCEWithLogitsLoss(pos_weight=cls_pos_weight)\n",
    "cls_optimizer = torch.optim.AdamW(cls_model.parameters(), lr=CLS_LR, weight_decay=CLS_WEIGHT_DECAY)\n",
    "cls_scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE == \"cuda\"))\n",
    "\n",
    "\n",
    "def output_root() -> Path:\n",
    "    if is_kaggle():\n",
    "        return Path(\"/kaggle/working\")\n",
    "    return Path(\".\").resolve()\n",
    "\n",
    "\n",
    "CLS_SAVE_DIR = output_root() / \"outputs\" / \"models_cls\" / f\"fold_{int(FOLD)}\"\n",
    "CLS_SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CLS_BEST_PATH = CLS_SAVE_DIR / \"best.pt\"\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def cls_evaluate(model: nn.Module, loader: DataLoader) -> dict:\n",
    "    model.eval()\n",
    "    losses: list[float] = []\n",
    "    all_logits: list[np.ndarray] = []\n",
    "    all_targets: list[np.ndarray] = []\n",
    "    for x, yb in tqdm(loader, desc=\"cls val\", leave=False):\n",
    "        x = x.to(DEVICE, non_blocking=True)\n",
    "        yb = yb.to(DEVICE, non_blocking=True)\n",
    "        logits = model(x).view(-1, 1)\n",
    "        loss = cls_criterion(logits, yb)\n",
    "        losses.append(float(loss.item()))\n",
    "        all_logits.append(logits.detach().cpu().numpy())\n",
    "        all_targets.append(yb.detach().cpu().numpy())\n",
    "\n",
    "    logits_np = np.concatenate(all_logits, axis=0).reshape(-1)\n",
    "    targets_np = np.concatenate(all_targets, axis=0).reshape(-1)\n",
    "    probs = 1.0 / (1.0 + np.exp(-logits_np))\n",
    "    pred = (probs >= 0.5).astype(np.int64)\n",
    "    acc = float((pred == targets_np.astype(np.int64)).mean())\n",
    "\n",
    "    out = {\"loss\": float(np.mean(losses)) if losses else float(\"nan\"), \"acc@0.5\": acc}\n",
    "    try:\n",
    "        from sklearn.metrics import roc_auc_score\n",
    "\n",
    "        out[\"auc\"] = float(roc_auc_score(targets_np, probs))\n",
    "    except Exception:\n",
    "        print(\"[WARN] falha ao calcular AUC (roc_auc_score).\")\n",
    "        traceback.print_exc()\n",
    "    return out\n",
    "\n",
    "\n",
    "def cls_train_one_epoch(model: nn.Module, loader: DataLoader) -> float:\n",
    "    model.train()\n",
    "    losses: list[float] = []\n",
    "    for x, yb in tqdm(loader, desc=\"cls train\", leave=False):\n",
    "        x = x.to(DEVICE, non_blocking=True)\n",
    "        yb = yb.to(DEVICE, non_blocking=True)\n",
    "        cls_optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(DEVICE == \"cuda\")):\n",
    "            logits = model(x).view(-1, 1)\n",
    "            loss = cls_criterion(logits, yb)\n",
    "        cls_scaler.scale(loss).backward()\n",
    "        cls_scaler.step(cls_optimizer)\n",
    "        cls_scaler.update()\n",
    "        losses.append(float(loss.item()))\n",
    "    return float(np.mean(losses)) if losses else float(\"nan\")\n",
    "\n",
    "\n",
    "if RUN_TRAIN_CLS:\n",
    "    best_score = -1.0\n",
    "    for epoch in range(1, int(CLS_EPOCHS) + 1):\n",
    "        train_loss = cls_train_one_epoch(cls_model, cls_dl_train)\n",
    "        val = cls_evaluate(cls_model, cls_dl_val)\n",
    "        score = float(val.get(\"auc\", -val[\"loss\"]))\n",
    "        print(\n",
    "            f\"[CLS] epoch {epoch:02d}/{CLS_EPOCHS} | train_loss={train_loss:.4f} | \"\n",
    "            f\"val_loss={val['loss']:.4f} | acc@0.5={val['acc@0.5']:.4f} | \"\n",
    "            + (f\"auc={val.get('auc', float('nan')):.4f}\" if \"auc\" in val else \"\")\n",
    "        )\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            ckpt = {\n",
    "                \"model_state\": cls_model.state_dict(),\n",
    "                \"config\": {\n",
    "                    \"backend\": \"timm\" if timm is not None else \"torchvision\",\n",
    "                    \"model_name\": CLS_MODEL_NAME,\n",
    "                    \"image_size\": int(CLS_IMAGE_SIZE),\n",
    "                    \"fold\": int(FOLD),\n",
    "                    \"seed\": int(SEED),\n",
    "                },\n",
    "                \"score\": float(best_score),\n",
    "            }\n",
    "            torch.save(ckpt, CLS_BEST_PATH)\n",
    "            print(\"[CLS] saved best ->\", CLS_BEST_PATH)\n",
    "    print(\"[CLS] done. best score:\", best_score)\n",
    "else:\n",
    "    print(\"[CLS] treino desativado (RUN_TRAIN_CLS=False).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5c85eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 3 — Célula 8: Segmentação (index + split)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class SegSample:\n",
    "    case_id: str\n",
    "    image_path: Path\n",
    "    mask_path: Path | None\n",
    "    label: int  # 0 authentic, 1 forged\n",
    "\n",
    "\n",
    "def build_seg_index(train_images_dir: Path, train_masks_dir: Path) -> list[SegSample]:\n",
    "    samples: list[SegSample] = []\n",
    "    for label_name, y in [(\"authentic\", 0), (\"forged\", 1)]:\n",
    "        for img_path in sorted((train_images_dir / label_name).glob(\"*.png\")):\n",
    "            case_id = img_path.stem\n",
    "            mask_path = train_masks_dir / f\"{case_id}.npy\" if label_name == \"forged\" else None\n",
    "            samples.append(SegSample(case_id=case_id, image_path=img_path, mask_path=mask_path, label=int(y)))\n",
    "    if not samples:\n",
    "        raise FileNotFoundError(f\"Nenhuma imagem encontrada em: {train_images_dir}\")\n",
    "    return samples\n",
    "\n",
    "\n",
    "seg_samples = build_seg_index(TRAIN_IMAGES, TRAIN_MASKS)\n",
    "seg_y = np.array([s.label for s in seg_samples], dtype=np.int64)\n",
    "\n",
    "try:\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "    seg_folds = np.zeros(len(seg_samples), dtype=np.int64)\n",
    "    for fold_id, (_, val_idx) in enumerate(skf.split(np.zeros(len(seg_samples)), seg_y)):\n",
    "        seg_folds[val_idx] = int(fold_id)\n",
    "except Exception:\n",
    "    print(\"[ERRO] scikit-learn falhou (StratifiedKFold). Usando split simples.\")\n",
    "    traceback.print_exc()\n",
    "    seg_folds = np.arange(len(seg_samples), dtype=np.int64) % int(N_FOLDS)\n",
    "\n",
    "seg_train_idx = np.where(seg_folds != int(FOLD))[0]\n",
    "seg_val_idx = np.where(seg_folds == int(FOLD))[0]\n",
    "print(\"seg samples:\", len(seg_samples), \"fold:\", FOLD, \"train:\", len(seg_train_idx), \"val:\", len(seg_val_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb27e462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 3 — Célula 9: Segmentação (dataset patch + modelo + treino)\n",
    "SEG_PATCH_SIZE = 512\n",
    "SEG_BATCH_SIZE = 8\n",
    "SEG_EPOCHS = 15\n",
    "SEG_LR = 1e-3\n",
    "SEG_WEIGHT_DECAY = 1e-2\n",
    "\n",
    "\n",
    "def load_image_rgb(path: Path) -> np.ndarray:\n",
    "    return np.asarray(Image.open(path).convert(\"RGB\"))\n",
    "\n",
    "\n",
    "def load_mask_binary(path: Path | None, shape_hw: tuple[int, int]) -> np.ndarray:\n",
    "    if path is None or not path.exists():\n",
    "        return np.zeros(shape_hw, dtype=np.uint8)\n",
    "\n",
    "    arr = np.load(path)\n",
    "    arr = np.asarray(arr)\n",
    "    if arr.ndim == 2:\n",
    "        m = arr\n",
    "    elif arr.ndim == 3:\n",
    "        if arr.shape[0] < 64 and arr.shape[1:] == shape_hw:\n",
    "            m = arr.max(axis=0)\n",
    "        elif arr.shape[:2] == shape_hw:\n",
    "            m = arr.max(axis=2)\n",
    "        else:\n",
    "            m = arr.max(axis=0)\n",
    "    else:\n",
    "        raise ValueError(f\"mask array com shape inesperado: {arr.shape}\")\n",
    "    return (np.asarray(m) > 0).astype(np.uint8)\n",
    "\n",
    "\n",
    "def _pad_to_min(image: np.ndarray, mask: np.ndarray, min_h: int, min_w: int) -> tuple[np.ndarray, np.ndarray]:\n",
    "    h, w = image.shape[:2]\n",
    "    pad_h = max(int(min_h) - int(h), 0)\n",
    "    pad_w = max(int(min_w) - int(w), 0)\n",
    "    if pad_h == 0 and pad_w == 0:\n",
    "        return image, mask\n",
    "    image_p = np.pad(image, ((0, pad_h), (0, pad_w), (0, 0)), mode=\"constant\", constant_values=0)\n",
    "    mask_p = np.pad(mask, ((0, pad_h), (0, pad_w)), mode=\"constant\", constant_values=0)\n",
    "    return image_p, mask_p\n",
    "\n",
    "\n",
    "def _random_crop(image: np.ndarray, mask: np.ndarray, size: int) -> tuple[np.ndarray, np.ndarray]:\n",
    "    image, mask = _pad_to_min(image, mask, size, size)\n",
    "    h, w = image.shape[:2]\n",
    "    y0 = random.randint(0, h - size)\n",
    "    x0 = random.randint(0, w - size)\n",
    "    return image[y0 : y0 + size, x0 : x0 + size], mask[y0 : y0 + size, x0 : x0 + size]\n",
    "\n",
    "\n",
    "def _augment_seg(image: np.ndarray, mask: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
    "    if random.random() < 0.5:\n",
    "        image = np.ascontiguousarray(image[:, ::-1])\n",
    "        mask = np.ascontiguousarray(mask[:, ::-1])\n",
    "    if random.random() < 0.5:\n",
    "        image = np.ascontiguousarray(image[::-1, :])\n",
    "        mask = np.ascontiguousarray(mask[::-1, :])\n",
    "    if random.random() < 0.20:\n",
    "        k = random.randint(0, 3)\n",
    "        if k:\n",
    "            image = np.ascontiguousarray(np.rot90(image, k))\n",
    "            mask = np.ascontiguousarray(np.rot90(mask, k))\n",
    "    return image, mask\n",
    "\n",
    "\n",
    "def normalize_image(image: np.ndarray, mean=IMAGENET_MEAN, std=IMAGENET_STD) -> np.ndarray:\n",
    "    x = image.astype(np.float32)\n",
    "    if x.max() > 1.0:\n",
    "        x /= 255.0\n",
    "    mean = np.array(mean, dtype=np.float32)\n",
    "    std = np.array(std, dtype=np.float32)\n",
    "    return (x - mean) / std\n",
    "\n",
    "\n",
    "class SegPatchDataset(Dataset):\n",
    "    def __init__(self, samples: list[SegSample], train: bool):\n",
    "        self.samples = samples\n",
    "        self.train = bool(train)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        s = self.samples[int(idx)]\n",
    "        image = load_image_rgb(s.image_path)\n",
    "        h, w = image.shape[:2]\n",
    "        mask = load_mask_binary(s.mask_path, shape_hw=(h, w))\n",
    "        image, mask = _random_crop(image, mask, int(SEG_PATCH_SIZE))\n",
    "        if self.train:\n",
    "            image, mask = _augment_seg(image, mask)\n",
    "        image = normalize_image(image)\n",
    "        x = torch.from_numpy(image).permute(2, 0, 1).float()\n",
    "        y = torch.from_numpy(mask[None, :, :]).float()\n",
    "        return x, y\n",
    "\n",
    "\n",
    "seg_ds_train = SegPatchDataset([seg_samples[i] for i in seg_train_idx.tolist()], train=True)\n",
    "seg_ds_val = SegPatchDataset([seg_samples[i] for i in seg_val_idx.tolist()], train=False)\n",
    "\n",
    "SEG_NUM_WORKERS = 2 if is_kaggle() else 0\n",
    "seg_dl_train = DataLoader(\n",
    "    seg_ds_train,\n",
    "    batch_size=SEG_BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=SEG_NUM_WORKERS,\n",
    "    pin_memory=(DEVICE == \"cuda\"),\n",
    "    drop_last=True,\n",
    ")\n",
    "seg_dl_val = DataLoader(\n",
    "    seg_ds_val,\n",
    "    batch_size=SEG_BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=SEG_NUM_WORKERS,\n",
    "    pin_memory=(DEVICE == \"cuda\"),\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "try:\n",
    "    import segmentation_models_pytorch as smp\n",
    "except Exception:\n",
    "    smp = None\n",
    "    print(\"[WARN] segmentation_models_pytorch indisponível.\")\n",
    "    traceback.print_exc()\n",
    "\n",
    "\n",
    "def _tv_deeplabv3_resnet50() -> nn.Module:\n",
    "    from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "\n",
    "    try:\n",
    "        base = deeplabv3_resnet50(weights=None, weights_backbone=None)\n",
    "    except TypeError:\n",
    "        base = deeplabv3_resnet50(pretrained=False)\n",
    "\n",
    "    head = base.classifier[-1]\n",
    "    base.classifier[-1] = nn.Conv2d(head.in_channels, 1, kernel_size=1)\n",
    "\n",
    "    class _Wrap(nn.Module):\n",
    "        def __init__(self, m: nn.Module):\n",
    "            super().__init__()\n",
    "            self.m = m\n",
    "\n",
    "        def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "            out = self.m(x)\n",
    "            if isinstance(out, dict):\n",
    "                out = out[\"out\"]\n",
    "            return out\n",
    "\n",
    "    return _Wrap(base)\n",
    "\n",
    "\n",
    "def build_seg_model() -> tuple[nn.Module, dict]:\n",
    "    if smp is not None:\n",
    "        m = smp.UnetPlusPlus(encoder_name=\"efficientnet-b4\", encoder_weights=None, classes=1, activation=None)\n",
    "        cfg = {\"backend\": \"smp\", \"arch\": \"UnetPlusPlus\", \"encoder_name\": \"efficientnet-b4\", \"classes\": 1}\n",
    "        return m, cfg\n",
    "    m = _tv_deeplabv3_resnet50()\n",
    "    cfg = {\"backend\": \"torchvision\", \"arch\": \"deeplabv3_resnet50\", \"classes\": 1}\n",
    "    return m, cfg\n",
    "\n",
    "\n",
    "seg_model, seg_model_cfg = build_seg_model()\n",
    "seg_model = seg_model.to(DEVICE)\n",
    "print(\"seg model cfg:\", seg_model_cfg)\n",
    "\n",
    "\n",
    "def dice_loss_with_logits(logits: torch.Tensor, targets: torch.Tensor, eps: float = 1e-6) -> torch.Tensor:\n",
    "    probs = torch.sigmoid(logits)\n",
    "    probs = probs.view(probs.size(0), -1)\n",
    "    targets = targets.view(targets.size(0), -1)\n",
    "    inter = (probs * targets).sum(dim=1)\n",
    "    den = probs.sum(dim=1) + targets.sum(dim=1)\n",
    "    dice = (2.0 * inter + eps) / (den + eps)\n",
    "    return 1.0 - dice.mean()\n",
    "\n",
    "\n",
    "def bce_dice_loss(logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "    bce = torch.nn.functional.binary_cross_entropy_with_logits(logits, targets)\n",
    "    d = dice_loss_with_logits(logits, targets)\n",
    "    return bce + d\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def dice_score_from_logits(logits: torch.Tensor, targets: torch.Tensor, threshold: float = 0.5, eps: float = 1e-6) -> float:\n",
    "    probs = torch.sigmoid(logits)\n",
    "    pred = (probs >= float(threshold)).float()\n",
    "    inter = (pred * targets).sum().item()\n",
    "    den = pred.sum().item() + targets.sum().item()\n",
    "    return float((2.0 * inter + eps) / (den + eps))\n",
    "\n",
    "\n",
    "seg_optimizer = torch.optim.AdamW(seg_model.parameters(), lr=SEG_LR, weight_decay=SEG_WEIGHT_DECAY)\n",
    "seg_scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE == \"cuda\"))\n",
    "\n",
    "SEG_MODEL_ID = \"unetpp_effb4\" if seg_model_cfg.get(\"backend\") == \"smp\" else \"deeplabv3_r50\"\n",
    "SEG_SAVE_DIR = output_root() / \"outputs\" / \"models_seg\" / SEG_MODEL_ID / f\"fold_{int(FOLD)}\"\n",
    "SEG_SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "SEG_BEST_PATH = SEG_SAVE_DIR / \"best.pt\"\n",
    "\n",
    "\n",
    "def seg_train_one_epoch(model: nn.Module, loader: DataLoader) -> float:\n",
    "    model.train()\n",
    "    losses: list[float] = []\n",
    "    for x, yb in tqdm(loader, desc=\"seg train\", leave=False):\n",
    "        x = x.to(DEVICE, non_blocking=True)\n",
    "        yb = yb.to(DEVICE, non_blocking=True)\n",
    "        seg_optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.cuda.amp.autocast(enabled=(DEVICE == \"cuda\")):\n",
    "            logits = model(x)\n",
    "            loss = bce_dice_loss(logits, yb)\n",
    "        seg_scaler.scale(loss).backward()\n",
    "        seg_scaler.step(seg_optimizer)\n",
    "        seg_scaler.update()\n",
    "        losses.append(float(loss.item()))\n",
    "    return float(np.mean(losses)) if losses else float(\"nan\")\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def seg_evaluate(model: nn.Module, loader: DataLoader) -> dict:\n",
    "    model.eval()\n",
    "    losses: list[float] = []\n",
    "    dices: list[float] = []\n",
    "    for x, yb in tqdm(loader, desc=\"seg val\", leave=False):\n",
    "        x = x.to(DEVICE, non_blocking=True)\n",
    "        yb = yb.to(DEVICE, non_blocking=True)\n",
    "        logits = model(x)\n",
    "        losses.append(float(bce_dice_loss(logits, yb).item()))\n",
    "        dices.append(dice_score_from_logits(logits, yb, threshold=0.5))\n",
    "    return {\"loss\": float(np.mean(losses)) if losses else float(\"nan\"), \"dice@0.5\": float(np.mean(dices)) if dices else 0.0}\n",
    "\n",
    "\n",
    "if RUN_TRAIN_SEG:\n",
    "    best_dice = -1.0\n",
    "    for epoch in range(1, int(SEG_EPOCHS) + 1):\n",
    "        tr = seg_train_one_epoch(seg_model, seg_dl_train)\n",
    "        val = seg_evaluate(seg_model, seg_dl_val)\n",
    "        print(f\"[SEG] epoch {epoch:02d}/{SEG_EPOCHS} | train_loss={tr:.4f} | val_loss={val['loss']:.4f} | dice@0.5={val['dice@0.5']:.4f}\")\n",
    "        if float(val[\"dice@0.5\"]) > best_dice:\n",
    "            best_dice = float(val[\"dice@0.5\"])\n",
    "            ckpt = {\n",
    "                \"model_state\": seg_model.state_dict(),\n",
    "                \"config\": {**seg_model_cfg, \"model_id\": SEG_MODEL_ID, \"patch_size\": int(SEG_PATCH_SIZE), \"fold\": int(FOLD), \"seed\": int(SEED)},\n",
    "                \"score\": float(best_dice),\n",
    "            }\n",
    "            torch.save(ckpt, SEG_BEST_PATH)\n",
    "            print(\"[SEG] saved best ->\", SEG_BEST_PATH)\n",
    "    print(\"[SEG] done. best dice:\", best_dice)\n",
    "else:\n",
    "    print(\"[SEG] treino desativado (RUN_TRAIN_SEG=False).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fac81d1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Fase 4 — Célula 10: Inferência (load checkpoints + submission)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TestSample:\n",
    "    case_id: str\n",
    "    image_path: Path\n",
    "\n",
    "\n",
    "def build_test_index(test_images_dir: Path) -> list[TestSample]:\n",
    "    paths = sorted(test_images_dir.glob(\"*.png\"))\n",
    "    if not paths:\n",
    "        raise FileNotFoundError(f\"Nenhuma imagem encontrada em {test_images_dir}\")\n",
    "    return [TestSample(case_id=p.stem, image_path=p) for p in paths]\n",
    "\n",
    "\n",
    "test_samples = build_test_index(TEST_IMAGES)\n",
    "print(\"test samples:\", len(test_samples))\n",
    "\n",
    "\n",
    "def _find_models_dir(dir_name: str) -> Path | None:\n",
    "    # Preferência: Kaggle Dataset anexado contendo outputs/\n",
    "    if is_kaggle():\n",
    "        ki = Path(\"/kaggle/input\")\n",
    "        if ki.exists():\n",
    "            candidates = []\n",
    "            for ds in sorted(ki.glob(\"*\")):\n",
    "                for base in (ds, ds / \"recodai_bundle\"):\n",
    "                    cand = base / \"outputs\" / dir_name\n",
    "                    if cand.exists():\n",
    "                        candidates.append(cand)\n",
    "            if candidates:\n",
    "                if len(candidates) > 1:\n",
    "                    print(f\"[CKPT] múltiplos candidatos para outputs/{dir_name}; usando o primeiro:\")\n",
    "                    for c in candidates:\n",
    "                        print(\" -\", c)\n",
    "                return candidates[0]\n",
    "\n",
    "    local = output_root() / \"outputs\" / dir_name\n",
    "    if local.exists():\n",
    "        return local\n",
    "    return None\n",
    "\n",
    "\n",
    "MODELS_SEG_DIR = _find_models_dir(\"models_seg\")\n",
    "MODELS_CLS_DIR = _find_models_dir(\"models_cls\")\n",
    "print(\"MODELS_SEG_DIR:\", MODELS_SEG_DIR)\n",
    "print(\"MODELS_CLS_DIR:\", MODELS_CLS_DIR)\n",
    "\n",
    "\n",
    "def _load_checkpoint(path: Path) -> tuple[dict, dict]:\n",
    "    ckpt = torch.load(path, map_location=\"cpu\")\n",
    "    if isinstance(ckpt, dict) and \"model_state\" in ckpt:\n",
    "        return ckpt[\"model_state\"], ckpt.get(\"config\", {})\n",
    "    return ckpt, {}\n",
    "\n",
    "\n",
    "def build_seg_from_config(cfg: dict) -> nn.Module:\n",
    "    backend = str(cfg.get(\"backend\", \"torchvision\"))\n",
    "    arch = str(cfg.get(\"arch\", cfg.get(\"model_id\", \"deeplabv3_resnet50\")))\n",
    "\n",
    "    if backend == \"smp\":\n",
    "        try:\n",
    "            import segmentation_models_pytorch as smp  # type: ignore\n",
    "        except Exception:\n",
    "            print(\"[ERRO] checkpoint pede SMP, mas segmentation_models_pytorch não está disponível.\")\n",
    "            traceback.print_exc()\n",
    "            raise\n",
    "\n",
    "        encoder_name = str(cfg.get(\"encoder_name\", \"efficientnet-b4\"))\n",
    "        classes = int(cfg.get(\"classes\", 1))\n",
    "\n",
    "        if arch.lower() in {\"unetplusplus\", \"unetpp\"}:\n",
    "            return smp.UnetPlusPlus(encoder_name=encoder_name, encoder_weights=None, classes=classes, activation=None)\n",
    "        if arch.lower() == \"unet\":\n",
    "            return smp.Unet(encoder_name=encoder_name, encoder_weights=None, classes=classes, activation=None)\n",
    "        if arch.lower() in {\"deeplabv3plus\", \"deeplabv3+\"}:\n",
    "            return smp.DeepLabV3Plus(encoder_name=encoder_name, encoder_weights=None, classes=classes, activation=None)\n",
    "        raise ValueError(f\"Arquitetura SMP desconhecida no cfg: {arch!r}\")\n",
    "\n",
    "    return _tv_deeplabv3_resnet50()\n",
    "\n",
    "\n",
    "def build_cls_from_config(cfg: dict) -> tuple[nn.Module, int]:\n",
    "    backend = str(cfg.get(\"backend\", \"torchvision\"))\n",
    "    model_name = str(cfg.get(\"model_name\", \"resnet50\"))\n",
    "    image_size = int(cfg.get(\"image_size\", CLS_IMAGE_SIZE))\n",
    "\n",
    "    if backend == \"timm\":\n",
    "        if timm is None:\n",
    "            raise RuntimeError(\"checkpoint pede timm, mas timm é None\")\n",
    "        return timm.create_model(model_name, pretrained=False, num_classes=1), image_size\n",
    "\n",
    "    from torchvision.models import resnet50\n",
    "\n",
    "    m = resnet50(weights=None)\n",
    "    m.fc = nn.Linear(m.fc.in_features, 1)\n",
    "    return m, image_size\n",
    "\n",
    "\n",
    "SEG_MODELS: list[nn.Module] = []\n",
    "if MODELS_SEG_DIR is None:\n",
    "    print(\"[ERRO] MODELS_SEG_DIR não encontrado. Treine e salve em outputs/models_seg/... ou anexe dataset com isso.\")\n",
    "else:\n",
    "    seg_ckpts = sorted(MODELS_SEG_DIR.glob(\"*/*/best.pt\"))\n",
    "    print(\"seg checkpoints encontrados:\", len(seg_ckpts))\n",
    "    for p in seg_ckpts:\n",
    "        try:\n",
    "            state, cfg = _load_checkpoint(p)\n",
    "            m = build_seg_from_config(cfg)\n",
    "            m.load_state_dict(state)\n",
    "            m.to(DEVICE)\n",
    "            m.eval()\n",
    "            SEG_MODELS.append(m)\n",
    "        except Exception:\n",
    "            print(\"[ERRO] falha ao carregar seg checkpoint:\", p)\n",
    "            traceback.print_exc()\n",
    "\n",
    "if not SEG_MODELS:\n",
    "    raise RuntimeError(\"Nenhum modelo de segmentação foi carregado. Veja os erros acima.\")\n",
    "\n",
    "\n",
    "CLS_MODELS: list[nn.Module] = []\n",
    "CLS_INFER_IMAGE_SIZE = CLS_IMAGE_SIZE\n",
    "CLS_SKIP_THRESHOLD = 0.30\n",
    "\n",
    "if MODELS_CLS_DIR is not None:\n",
    "    cls_ckpts = sorted(MODELS_CLS_DIR.glob(\"fold_*/best.pt\"))\n",
    "    print(\"cls checkpoints encontrados:\", len(cls_ckpts))\n",
    "    for p in cls_ckpts:\n",
    "        try:\n",
    "            state, cfg = _load_checkpoint(p)\n",
    "            m, image_size = build_cls_from_config(cfg)\n",
    "            CLS_INFER_IMAGE_SIZE = int(image_size)\n",
    "            m.load_state_dict(state)\n",
    "            m.to(DEVICE)\n",
    "            m.eval()\n",
    "            CLS_MODELS.append(m)\n",
    "        except Exception:\n",
    "            print(\"[ERRO] falha ao carregar cls checkpoint:\", p)\n",
    "            traceback.print_exc()\n",
    "\n",
    "print(\"loaded cls models:\", len(CLS_MODELS), \"CLS_INFER_IMAGE_SIZE:\", CLS_INFER_IMAGE_SIZE)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_prob_forged(image: np.ndarray) -> float:\n",
    "    if not CLS_MODELS:\n",
    "        raise RuntimeError(\"CLS_MODELS vazio\")\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    img = normalize_image(image)\n",
    "    x = torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0).to(DEVICE)\n",
    "    if CLS_INFER_IMAGE_SIZE and x.shape[-2:] != (CLS_INFER_IMAGE_SIZE, CLS_INFER_IMAGE_SIZE):\n",
    "        x = F.interpolate(x, size=(CLS_INFER_IMAGE_SIZE, CLS_INFER_IMAGE_SIZE), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "    probs: list[float] = []\n",
    "    for m in CLS_MODELS:\n",
    "        logits = m(x).view(-1)\n",
    "        probs.append(float(torch.sigmoid(logits)[0].item()))\n",
    "    return float(np.mean(probs))\n",
    "\n",
    "\n",
    "try:\n",
    "    from scipy.ndimage import label as _cc_label\n",
    "except Exception:\n",
    "    _cc_label = None\n",
    "\n",
    "try:\n",
    "    import cv2\n",
    "except Exception:\n",
    "    cv2 = None\n",
    "\n",
    "\n",
    "def extract_components(mask: np.ndarray, min_area: int = 0) -> list[np.ndarray]:\n",
    "    mask = (np.asarray(mask) > 0).astype(np.uint8)\n",
    "    if mask.ndim != 2:\n",
    "        raise ValueError(f\"Expected 2D mask, got shape {mask.shape}\")\n",
    "    if mask.max() == 0:\n",
    "        return []\n",
    "\n",
    "    instances: list[np.ndarray] = []\n",
    "    if _cc_label is not None:\n",
    "        labeled, num = _cc_label(mask > 0)\n",
    "        for idx in range(1, int(num) + 1):\n",
    "            comp = (labeled == idx)\n",
    "            if min_area and int(comp.sum()) < int(min_area):\n",
    "                continue\n",
    "            instances.append(comp.astype(np.uint8))\n",
    "        return instances\n",
    "\n",
    "    if cv2 is None:\n",
    "        raise ImportError(\"connected components requires scipy or opencv-python\")\n",
    "\n",
    "    num_labels, labels = cv2.connectedComponents(mask, connectivity=4)\n",
    "    for idx in range(1, int(num_labels)):\n",
    "        comp = (labels == idx)\n",
    "        if min_area and int(comp.sum()) < int(min_area):\n",
    "            continue\n",
    "        instances.append(comp.astype(np.uint8))\n",
    "    return instances\n",
    "\n",
    "\n",
    "AUTHENTIC_LABEL = \"authentic\"\n",
    "\n",
    "\n",
    "def rle_encode(mask: np.ndarray) -> list[int]:\n",
    "    mask = (np.asarray(mask) > 0).astype(np.uint8)\n",
    "    if mask.max() == 0:\n",
    "        return []\n",
    "    pixels = mask.flatten(order=\"F\")\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    changes = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    changes[1::2] -= changes[::2]\n",
    "    return changes.tolist()\n",
    "\n",
    "\n",
    "def encode_instances(instances: list[np.ndarray]) -> str:\n",
    "    if not instances:\n",
    "        return AUTHENTIC_LABEL\n",
    "    parts = [json.dumps(rle_encode(m)) for m in instances]\n",
    "    return \";\".join(parts)\n",
    "\n",
    "\n",
    "def _tile_coords(length: int, tile_size: int, overlap: int) -> list[tuple[int, int]]:\n",
    "    stride = int(tile_size) - int(overlap)\n",
    "    if stride <= 0:\n",
    "        raise ValueError(\"tile_size must be larger than overlap\")\n",
    "    if length <= tile_size:\n",
    "        return [(0, tile_size)]\n",
    "    coords = list(range(0, length - tile_size + 1, stride))\n",
    "    if coords[-1] != length - tile_size:\n",
    "        coords.append(length - tile_size)\n",
    "    return [(int(start), int(start + tile_size)) for start in coords]\n",
    "\n",
    "\n",
    "def _pad_image(image: np.ndarray, target_h: int, target_w: int) -> tuple[np.ndarray, tuple[int, int]]:\n",
    "    h, w = image.shape[:2]\n",
    "    pad_h = max(target_h - h, 0)\n",
    "    pad_w = max(target_w - w, 0)\n",
    "    if pad_h == 0 and pad_w == 0:\n",
    "        return image, (0, 0)\n",
    "    padded = np.pad(image, ((0, pad_h), (0, pad_w), (0, 0)), mode=\"constant\")\n",
    "    return padded, (pad_h, pad_w)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def _predict_tensor(model: nn.Module, tensor: torch.Tensor, device: str) -> torch.Tensor:\n",
    "    tensor = tensor.to(device)\n",
    "    logits = model(tensor)\n",
    "    return torch.sigmoid(logits)\n",
    "\n",
    "\n",
    "def predict_image(\n",
    "    model: nn.Module,\n",
    "    image: np.ndarray,\n",
    "    device: str,\n",
    "    tile_size: int = 0,\n",
    "    overlap: int = 0,\n",
    "    max_size: int = 0,\n",
    ") -> np.ndarray:\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    orig_h, orig_w = image.shape[:2]\n",
    "\n",
    "    if tile_size and int(tile_size) > 0:\n",
    "        padded, _ = _pad_image(image, int(tile_size), int(tile_size))\n",
    "        pad_h, pad_w = padded.shape[0], padded.shape[1]\n",
    "        pred_sum = np.zeros((pad_h, pad_w), dtype=np.float32)\n",
    "        pred_count = np.zeros((pad_h, pad_w), dtype=np.float32)\n",
    "\n",
    "        ys = _tile_coords(padded.shape[0], int(tile_size), int(overlap))\n",
    "        xs = _tile_coords(padded.shape[1], int(tile_size), int(overlap))\n",
    "        for y0, y1 in ys:\n",
    "            for x0, x1 in xs:\n",
    "                tile = padded[y0:y1, x0:x1]\n",
    "                tile_norm = normalize_image(tile)\n",
    "                tile_tensor = torch.from_numpy(tile_norm).permute(2, 0, 1).unsqueeze(0)\n",
    "                probs = _predict_tensor(model, tile_tensor, device)\n",
    "                prob_tile = probs.squeeze(0).squeeze(0).cpu().numpy()\n",
    "                pred_sum[y0:y1, x0:x1] += prob_tile\n",
    "                pred_count[y0:y1, x0:x1] += 1.0\n",
    "\n",
    "        pred = pred_sum / np.maximum(pred_count, 1.0)\n",
    "        return pred[:orig_h, :orig_w]\n",
    "\n",
    "    image_norm = normalize_image(image)\n",
    "    tensor = torch.from_numpy(image_norm).permute(2, 0, 1).unsqueeze(0)\n",
    "    if max_size and max(orig_h, orig_w) > int(max_size):\n",
    "        scale = int(max_size) / float(max(orig_h, orig_w))\n",
    "        new_h = int(round(orig_h * scale))\n",
    "        new_w = int(round(orig_w * scale))\n",
    "        tensor = F.interpolate(tensor, size=(new_h, new_w), mode=\"bilinear\", align_corners=False)\n",
    "\n",
    "    probs = _predict_tensor(model, tensor, device)\n",
    "    if probs.shape[-2:] != (orig_h, orig_w):\n",
    "        probs = F.interpolate(probs, size=(orig_h, orig_w), mode=\"bilinear\", align_corners=False)\n",
    "    return probs.squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "\n",
    "def binarize(mask: np.ndarray, threshold: float = 0.5) -> np.ndarray:\n",
    "    return (np.asarray(mask) >= float(threshold)).astype(np.uint8)\n",
    "\n",
    "\n",
    "def postprocess_binary_mask(mask: np.ndarray, max_hole_area: int = 64, morph_kernel: int = 0) -> np.ndarray:\n",
    "    m = (np.asarray(mask) > 0).astype(np.uint8)\n",
    "    if m.max() == 0 or cv2 is None:\n",
    "        return m\n",
    "    try:\n",
    "        if max_hole_area > 0:\n",
    "            inv = (1 - m).astype(np.uint8)\n",
    "            n, labels, stats, _ = cv2.connectedComponentsWithStats(inv, connectivity=4)\n",
    "            for i in range(1, int(n)):\n",
    "                area = int(stats[i, cv2.CC_STAT_AREA])\n",
    "                if area <= int(max_hole_area):\n",
    "                    m[labels == i] = 1\n",
    "        if morph_kernel and int(morph_kernel) > 1:\n",
    "            k = int(morph_kernel)\n",
    "            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (k, k))\n",
    "            m = cv2.morphologyEx(m, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
    "    except Exception:\n",
    "        print(\"[PP] erro no pós-processamento; seguindo sem. Erro abaixo:\")\n",
    "        traceback.print_exc()\n",
    "    return (m > 0).astype(np.uint8)\n",
    "\n",
    "\n",
    "TILE_SIZE = 1024\n",
    "OVERLAP = 128\n",
    "MAX_SIZE = 0\n",
    "THRESHOLD = 0.50\n",
    "MIN_AREA = 32\n",
    "USE_TTA = True\n",
    "TTA_MODES = (\"none\", \"hflip\", \"vflip\")\n",
    "PP_MAX_HOLE_AREA = 64\n",
    "PP_MORPH_KERNEL = 0\n",
    "\n",
    "\n",
    "def _apply_tta(image: np.ndarray, mode: str) -> np.ndarray:\n",
    "    if mode == \"none\":\n",
    "        return image\n",
    "    if mode == \"hflip\":\n",
    "        return np.ascontiguousarray(image[:, ::-1])\n",
    "    if mode == \"vflip\":\n",
    "        return np.ascontiguousarray(image[::-1, :])\n",
    "    raise ValueError(f\"tta mode inválido: {mode}\")\n",
    "\n",
    "\n",
    "def _undo_tta(mask: np.ndarray, mode: str) -> np.ndarray:\n",
    "    if mode == \"none\":\n",
    "        return mask\n",
    "    if mode == \"hflip\":\n",
    "        return np.ascontiguousarray(mask[:, ::-1])\n",
    "    if mode == \"vflip\":\n",
    "        return np.ascontiguousarray(mask[::-1, :])\n",
    "    raise ValueError(f\"tta mode inválido: {mode}\")\n",
    "\n",
    "\n",
    "def predict_seg_ensemble_prob(image: np.ndarray) -> np.ndarray:\n",
    "    probs_sum = None\n",
    "    count = 0\n",
    "    modes = TTA_MODES if USE_TTA else (\"none\",)\n",
    "    for mode in modes:\n",
    "        img_t = _apply_tta(image, mode)\n",
    "        ens = None\n",
    "        for m in SEG_MODELS:\n",
    "            p = predict_image(m, img_t, DEVICE, tile_size=TILE_SIZE, overlap=OVERLAP, max_size=MAX_SIZE)\n",
    "            ens = p if ens is None else (ens + p)\n",
    "        ens = ens / float(len(SEG_MODELS))\n",
    "        ens = _undo_tta(ens, mode)\n",
    "        probs_sum = ens if probs_sum is None else (probs_sum + ens)\n",
    "        count += 1\n",
    "    return probs_sum / float(max(count, 1))\n",
    "\n",
    "\n",
    "def predict_instances(image: np.ndarray) -> list[np.ndarray]:\n",
    "    prob = predict_seg_ensemble_prob(image)\n",
    "    bin_mask = binarize(prob, threshold=THRESHOLD)\n",
    "    bin_mask = postprocess_binary_mask(bin_mask, max_hole_area=int(PP_MAX_HOLE_AREA), morph_kernel=int(PP_MORPH_KERNEL))\n",
    "    return extract_components(bin_mask, min_area=int(MIN_AREA))\n",
    "\n",
    "\n",
    "SUBMISSION_PATH = Path(\"/kaggle/working/submission.csv\") if is_kaggle() else (output_root() / \"submission.csv\")\n",
    "if RUN_SUBMISSION:\n",
    "    SUBMISSION_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with SUBMISSION_PATH.open(\"w\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"case_id\", \"annotation\"])\n",
    "        writer.writeheader()\n",
    "        for s in tqdm(test_samples, desc=\"infer\"):\n",
    "            img = load_image_rgb(s.image_path)\n",
    "            if CLS_MODELS:\n",
    "                p_forged = predict_prob_forged(img)\n",
    "                if float(p_forged) < float(CLS_SKIP_THRESHOLD):\n",
    "                    writer.writerow({\"case_id\": s.case_id, \"annotation\": AUTHENTIC_LABEL})\n",
    "                    continue\n",
    "            inst = predict_instances(img)\n",
    "            writer.writerow({\"case_id\": s.case_id, \"annotation\": encode_instances(inst)})\n",
    "\n",
    "    print(\"wrote:\", SUBMISSION_PATH)\n",
    "else:\n",
    "    print(\"[SUBMISSION] RUN_SUBMISSION=False; não gerou CSV.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
