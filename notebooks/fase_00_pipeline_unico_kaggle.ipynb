{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8932f34",
   "metadata": {},
   "source": [
    "# Pipeline único — Fases 1→4 (Kaggle / Offline)\n",
    "\n",
    "Este notebook junta tudo em um só lugar:\n",
    "\n",
    "1) **Setup offline + checagens**\n",
    "2) **Treino do classificador** (authentic vs forged) *(opcional)*\n",
    "3) **Treino do segmentador** (máscara de duplicação) *(opcional)*\n",
    "4) **Inferência + submissão** (`submission.csv`)\n",
    "\n",
    "## Regras / Decisões\n",
    "- Importa código do projeto em `src/forgeryseg/` (modularizado).\n",
    "- Compatível com Kaggle **internet OFF** (instala wheels locais se existirem).\n",
    "- Não esconde erros: exceções e tracebacks aparecem.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd668557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 1: Sanidade Kaggle (lembrete)\n",
    "print(\"Kaggle submission constraints (lembrete):\")\n",
    "print(\"- Submissions via Notebook\")\n",
    "print(\"- Runtime <= 4h (CPU/GPU)\")\n",
    "print(\"- Internet: OFF no submit\")\n",
    "print(\"- Output: /kaggle/working/submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50729446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 2: Imports + ambiente\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import traceback\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "warnings.simplefilter(\"default\")\n",
    "os.environ.setdefault(\"NO_ALBUMENTATIONS_UPDATE\", \"1\")\n",
    "\n",
    "\n",
    "def is_kaggle() -> bool:\n",
    "    return bool(os.environ.get(\"KAGGLE_URL_BASE\")) or Path(\"/kaggle\").exists()\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if DEVICE == \"cuda\":\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "print(\"python:\", sys.version.split()[0])\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "print(\"device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1d9d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 2b: Instalação offline (wheels) — NÃO resolve deps\n",
    "#\n",
    "# Estruturas suportadas:\n",
    "# - `/kaggle/input/<dataset>/wheels/*.whl`\n",
    "# - `/kaggle/input/<dataset>/recodai_bundle/wheels/*.whl`\n",
    "#\n",
    "# Observação: instalamos com `--no-deps` para não tentar instalar dependências do torch offline.\n",
    "import subprocess\n",
    "\n",
    "\n",
    "def _find_offline_bundle() -> Path | None:\n",
    "    if not is_kaggle():\n",
    "        return None\n",
    "    kaggle_input = Path(\"/kaggle/input\")\n",
    "    if not kaggle_input.exists():\n",
    "        return None\n",
    "\n",
    "    candidates: list[Path] = []\n",
    "    for ds in sorted(kaggle_input.glob(\"*\")):\n",
    "        for base in (ds, ds / \"recodai_bundle\"):\n",
    "            if (base / \"wheels\").exists():\n",
    "                candidates.append(base)\n",
    "\n",
    "    if not candidates:\n",
    "        return None\n",
    "    if len(candidates) > 1:\n",
    "        print(\"[OFFLINE INSTALL] múltiplos bundles com wheels encontrados; usando o primeiro:\")\n",
    "        for c in candidates:\n",
    "            print(\" -\", c)\n",
    "    return candidates[0]\n",
    "\n",
    "\n",
    "def _is_competition_dataset_dir(path: Path) -> bool:\n",
    "    return (path / \"train_images\").exists() or (path / \"test_images\").exists() or (path / \"train_masks\").exists()\n",
    "\n",
    "\n",
    "def _candidate_python_roots(base: Path) -> list[Path]:\n",
    "    roots = [\n",
    "        base,\n",
    "        base / \"src\",\n",
    "        base / \"vendor\",\n",
    "        base / \"third_party\",\n",
    "        base / \"recodai_bundle\",\n",
    "        base / \"recodai_bundle\" / \"src\",\n",
    "        base / \"recodai_bundle\" / \"vendor\",\n",
    "        base / \"recodai_bundle\" / \"third_party\",\n",
    "    ]\n",
    "    return [r for r in roots if r.exists()]\n",
    "\n",
    "\n",
    "def add_local_package_to_syspath(package_dir_name: str) -> list[Path]:\n",
    "    \"\"\"\n",
    "    Procura por `package_dir_name/__init__.py` em `/kaggle/input/*` (exceto o dataset da competição)\n",
    "    e adiciona o root correspondente ao `sys.path`.\n",
    "    \"\"\"\n",
    "    added: list[Path] = []\n",
    "    if not is_kaggle():\n",
    "        return added\n",
    "\n",
    "    kaggle_input = Path(\"/kaggle/input\")\n",
    "    if not kaggle_input.exists():\n",
    "        return added\n",
    "\n",
    "    for ds in sorted(kaggle_input.glob(\"*\")):\n",
    "        if _is_competition_dataset_dir(ds):\n",
    "            continue\n",
    "        for root in _candidate_python_roots(ds):\n",
    "            pkg = root / package_dir_name\n",
    "            if (pkg / \"__init__.py\").exists():\n",
    "                if str(root) not in sys.path:\n",
    "                    sys.path.insert(0, str(root))\n",
    "                    added.append(root)\n",
    "                continue\n",
    "            try:\n",
    "                for child in sorted(p for p in root.glob(\"*\") if p.is_dir()):\n",
    "                    pkg2 = child / package_dir_name\n",
    "                    if (pkg2 / \"__init__.py\").exists():\n",
    "                        if str(child) not in sys.path:\n",
    "                            sys.path.insert(0, str(child))\n",
    "                            added.append(child)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    if added:\n",
    "        uniq = []\n",
    "        for p in added:\n",
    "            if p not in uniq:\n",
    "                uniq.append(p)\n",
    "        print(f\"[LOCAL IMPORT] adicionado ao sys.path para '{package_dir_name}':\")\n",
    "        for p in uniq[:10]:\n",
    "            print(\" -\", p)\n",
    "        if len(uniq) > 10:\n",
    "            print(\" ...\")\n",
    "        return uniq\n",
    "\n",
    "    print(f\"[LOCAL IMPORT] não encontrei '{package_dir_name}/__init__.py' em `/kaggle/input/*` (fora do dataset da competição).\")\n",
    "    return added\n",
    "\n",
    "\n",
    "OFFLINE_BUNDLE = _find_offline_bundle()\n",
    "if OFFLINE_BUNDLE is None:\n",
    "    print(\"[OFFLINE INSTALL] nenhum bundle com `wheels/` encontrado em `/kaggle/input`.\")\n",
    "else:\n",
    "    wheel_dir = OFFLINE_BUNDLE / \"wheels\"\n",
    "    whls = sorted(str(p) for p in wheel_dir.glob(\"*.whl\"))\n",
    "    print(\"[OFFLINE INSTALL] bundle:\", OFFLINE_BUNDLE)\n",
    "    print(\"[OFFLINE INSTALL] wheels:\", len(whls))\n",
    "    if not whls:\n",
    "        print(\"[OFFLINE INSTALL] aviso: diretório `wheels/` existe mas não há `.whl`.\")\n",
    "    else:\n",
    "        cmd = [\n",
    "            sys.executable,\n",
    "            \"-m\",\n",
    "            \"pip\",\n",
    "            \"install\",\n",
    "            \"--no-index\",\n",
    "            \"--find-links\",\n",
    "            str(wheel_dir),\n",
    "            \"--no-deps\",\n",
    "            *whls,\n",
    "        ]\n",
    "        print(\"[OFFLINE INSTALL] executando:\", \" \".join(cmd[:9]), \"...\", f\"(+{len(whls)} wheels)\")\n",
    "        subprocess.check_call(cmd)\n",
    "        print(\"[OFFLINE INSTALL] OK.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8669ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 2c: Import do projeto (src/forgeryseg)\n",
    "try:\n",
    "    import forgeryseg  # type: ignore\n",
    "except Exception:\n",
    "    local_src = Path(\"src\").resolve()\n",
    "    if (local_src / \"forgeryseg\" / \"__init__.py\").exists() and str(local_src) not in sys.path:\n",
    "        sys.path.insert(0, str(local_src))\n",
    "    if is_kaggle():\n",
    "        add_local_package_to_syspath(\"forgeryseg\")\n",
    "    import forgeryseg  # type: ignore\n",
    "\n",
    "print(\"forgeryseg:\", Path(forgeryseg.__file__).resolve())\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset  # noqa: E402\n",
    "\n",
    "from forgeryseg.augment import get_train_augment, get_val_augment  # noqa: E402\n",
    "from forgeryseg.checkpoints import build_classifier_from_config, build_segmentation_from_config, load_checkpoint  # noqa: E402\n",
    "from forgeryseg.constants import AUTHENTIC_LABEL  # noqa: E402\n",
    "from forgeryseg.dataset import PatchDataset, build_test_index, build_train_index, load_image  # noqa: E402\n",
    "from forgeryseg.inference import normalize_image, predict_image  # noqa: E402\n",
    "from forgeryseg.losses import BCETverskyLoss  # noqa: E402\n",
    "from forgeryseg.models import builders  # noqa: E402\n",
    "from forgeryseg.models.classifier import build_classifier, compute_pos_weight  # noqa: E402\n",
    "from forgeryseg.postprocess import binarize, extract_components  # noqa: E402\n",
    "from forgeryseg.rle import encode_instances  # noqa: E402\n",
    "from forgeryseg.train import train_one_epoch, validate  # noqa: E402"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3efba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 3: Dataset root + contagens\n",
    "\n",
    "\n",
    "def find_dataset_root() -> Path:\n",
    "    if is_kaggle():\n",
    "        base = Path(\"/kaggle/input/recodai-luc-scientific-image-forgery-detection\")\n",
    "        if base.exists():\n",
    "            return base\n",
    "        kaggle_input = Path(\"/kaggle/input\")\n",
    "        if kaggle_input.exists():\n",
    "            for ds in sorted(kaggle_input.glob(\"*\")):\n",
    "                if (ds / \"train_images\").exists() and (ds / \"test_images\").exists():\n",
    "                    return ds\n",
    "\n",
    "    base = Path(\"data\").resolve()\n",
    "    if (base / \"train_images\").exists() and (base / \"test_images\").exists():\n",
    "        return base\n",
    "\n",
    "    raise FileNotFoundError(\"Dataset não encontrado. No Kaggle: anexe o dataset da competição.\")\n",
    "\n",
    "\n",
    "DATA_ROOT = find_dataset_root()\n",
    "train_samples = build_train_index(DATA_ROOT, strict=False)\n",
    "train_labels = np.array([0 if s.is_authentic else 1 for s in train_samples], dtype=np.int64)\n",
    "test_samples = build_test_index(DATA_ROOT)\n",
    "\n",
    "print(\"DATA_ROOT:\", DATA_ROOT)\n",
    "print(\"train samples:\", len(train_samples), \"auth:\", int((train_labels == 0).sum()), \"forged:\", int((train_labels == 1).sum()))\n",
    "print(\"test samples:\", len(test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db91209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 1 — Célula 4: Config global (liga/desliga)\n",
    "RUN_TRAIN_CLS = False\n",
    "RUN_TRAIN_SEG = False\n",
    "RUN_SUBMISSION = True\n",
    "\n",
    "N_FOLDS = 5\n",
    "FOLD = 0\n",
    "\n",
    "print(\"RUN_TRAIN_CLS:\", RUN_TRAIN_CLS)\n",
    "print(\"RUN_TRAIN_SEG:\", RUN_TRAIN_SEG)\n",
    "print(\"RUN_SUBMISSION:\", RUN_SUBMISSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e6476f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 2 — Célula 5: Split (folds)\n",
    "try:\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "    folds = np.zeros(len(train_samples), dtype=np.int64)\n",
    "    for fold_id, (_, val_idx) in enumerate(skf.split(np.zeros(len(train_samples)), train_labels)):\n",
    "        folds[val_idx] = int(fold_id)\n",
    "except Exception:\n",
    "    print(\"[ERRO] scikit-learn falhou (StratifiedKFold). Usando split simples.\")\n",
    "    traceback.print_exc()\n",
    "    folds = np.arange(len(train_samples), dtype=np.int64) % int(N_FOLDS)\n",
    "\n",
    "train_idx = np.where(folds != int(FOLD))[0]\n",
    "val_idx = np.where(folds == int(FOLD))[0]\n",
    "print(f\"fold={FOLD}: train={len(train_idx)} val={len(val_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74c1b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 2 — Célula 6: Treino do classificador (opcional)\n",
    "try:\n",
    "    import torchvision.transforms as T\n",
    "except Exception:\n",
    "    print(\"[ERRO] torchvision falhou no import.\")\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except Exception:\n",
    "    print(\"[WARN] tqdm indisponível; usando loop simples.\")\n",
    "\n",
    "    def tqdm(x, **kwargs):  # type: ignore\n",
    "        return x\n",
    "\n",
    "\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "CLS_MODEL_NAME = \"tf_efficientnet_b4_ns\"\n",
    "CLS_IMAGE_SIZE = 384\n",
    "CLS_BATCH_SIZE = 32\n",
    "CLS_EPOCHS = 10\n",
    "CLS_LR = 3e-4\n",
    "CLS_WEIGHT_DECAY = 1e-2\n",
    "CLS_SKIP_THRESHOLD = 0.30\n",
    "\n",
    "\n",
    "def build_transform(train: bool) -> T.Compose:\n",
    "    aug = []\n",
    "    if train:\n",
    "        aug += [T.RandomHorizontalFlip(p=0.5), T.RandomVerticalFlip(p=0.5)]\n",
    "    aug += [\n",
    "        T.Resize((CLS_IMAGE_SIZE, CLS_IMAGE_SIZE)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(IMAGENET_MEAN, IMAGENET_STD),\n",
    "    ]\n",
    "    return T.Compose(aug)\n",
    "\n",
    "\n",
    "class ClsDataset(Dataset):\n",
    "    def __init__(self, samples, transform: T.Compose):\n",
    "        self.samples = samples\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        s = self.samples[int(idx)]\n",
    "        from PIL import Image\n",
    "\n",
    "        img = Image.open(s.image_path).convert(\"RGB\")\n",
    "        x = self.transform(img)\n",
    "        y = torch.tensor([0.0 if s.is_authentic else 1.0], dtype=torch.float32)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "if RUN_TRAIN_CLS:\n",
    "    ds_cls_train = ClsDataset([train_samples[i] for i in train_idx.tolist()], build_transform(train=True))\n",
    "    ds_cls_val = ClsDataset([train_samples[i] for i in val_idx.tolist()], build_transform(train=False))\n",
    "\n",
    "    num_workers = 2 if is_kaggle() else 0\n",
    "    dl_cls_train = DataLoader(ds_cls_train, batch_size=CLS_BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=(DEVICE == \"cuda\"), drop_last=True)\n",
    "    dl_cls_val = DataLoader(ds_cls_val, batch_size=CLS_BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=(DEVICE == \"cuda\"), drop_last=False)\n",
    "\n",
    "    cls_model = build_classifier(model_name=CLS_MODEL_NAME, pretrained=False, num_classes=1).to(DEVICE)\n",
    "    pos_weight = torch.tensor(compute_pos_weight(train_labels[train_idx]), dtype=torch.float32, device=DEVICE)\n",
    "    cls_criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    cls_optimizer = torch.optim.AdamW(cls_model.parameters(), lr=CLS_LR, weight_decay=CLS_WEIGHT_DECAY)\n",
    "    cls_scaler = torch.cuda.amp.GradScaler(enabled=(DEVICE == \"cuda\"))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def cls_eval() -> dict:\n",
    "        cls_model.eval()\n",
    "        losses = []\n",
    "        logits_all = []\n",
    "        y_all = []\n",
    "        for x, yb in tqdm(dl_cls_val, desc=\"cls val\", leave=False):\n",
    "            x = x.to(DEVICE, non_blocking=True)\n",
    "            yb = yb.to(DEVICE, non_blocking=True)\n",
    "            logits = cls_model(x).view(-1, 1)\n",
    "            loss = cls_criterion(logits, yb)\n",
    "            losses.append(float(loss.item()))\n",
    "            logits_all.append(logits.detach().cpu().numpy())\n",
    "            y_all.append(yb.detach().cpu().numpy())\n",
    "        logits_np = np.concatenate(logits_all, axis=0).reshape(-1)\n",
    "        y_np = np.concatenate(y_all, axis=0).reshape(-1)\n",
    "        probs = 1.0 / (1.0 + np.exp(-logits_np))\n",
    "        acc = float(((probs >= 0.5).astype(np.int64) == y_np.astype(np.int64)).mean())\n",
    "        out = {\"loss\": float(np.mean(losses)) if losses else float(\"nan\"), \"acc@0.5\": acc}\n",
    "        try:\n",
    "            from sklearn.metrics import roc_auc_score\n",
    "\n",
    "            out[\"auc\"] = float(roc_auc_score(y_np, probs))\n",
    "        except Exception:\n",
    "            traceback.print_exc()\n",
    "        return out\n",
    "\n",
    "    def cls_train_one_epoch() -> float:\n",
    "        cls_model.train()\n",
    "        losses = []\n",
    "        for x, yb in tqdm(dl_cls_train, desc=\"cls train\", leave=False):\n",
    "            x = x.to(DEVICE, non_blocking=True)\n",
    "            yb = yb.to(DEVICE, non_blocking=True)\n",
    "            cls_optimizer.zero_grad(set_to_none=True)\n",
    "            with torch.cuda.amp.autocast(enabled=(DEVICE == \"cuda\")):\n",
    "                logits = cls_model(x).view(-1, 1)\n",
    "                loss = cls_criterion(logits, yb)\n",
    "            cls_scaler.scale(loss).backward()\n",
    "            cls_scaler.step(cls_optimizer)\n",
    "            cls_scaler.update()\n",
    "            losses.append(float(loss.item()))\n",
    "        return float(np.mean(losses)) if losses else float(\"nan\")\n",
    "\n",
    "    def output_root() -> Path:\n",
    "        return Path(\"/kaggle/working\") if is_kaggle() else Path(\".\").resolve()\n",
    "\n",
    "    cls_save_dir = output_root() / \"outputs\" / \"models_cls\" / f\"fold_{int(FOLD)}\"\n",
    "    cls_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    cls_best_path = cls_save_dir / \"best.pt\"\n",
    "\n",
    "    best_score = -1.0\n",
    "    for epoch in range(1, int(CLS_EPOCHS) + 1):\n",
    "        tr_loss = cls_train_one_epoch()\n",
    "        val = cls_eval()\n",
    "        score = float(val.get(\"auc\", -val[\"loss\"]))\n",
    "        print(f\"[CLS] epoch {epoch:02d}/{CLS_EPOCHS} | train_loss={tr_loss:.4f} | val={val}\")\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            ckpt = {\n",
    "                \"model_state\": cls_model.state_dict(),\n",
    "                \"config\": {\"backend\": \"timm\", \"model_name\": CLS_MODEL_NAME, \"image_size\": int(CLS_IMAGE_SIZE), \"fold\": int(FOLD), \"seed\": int(SEED)},\n",
    "                \"score\": float(best_score),\n",
    "            }\n",
    "            torch.save(ckpt, cls_best_path)\n",
    "            print(\"[CLS] saved best ->\", cls_best_path)\n",
    "\n",
    "    print(\"[CLS] done. best score:\", best_score)\n",
    "else:\n",
    "    print(\"[CLS] RUN_TRAIN_CLS=False (pulando).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22086753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 3 — Célula 7: Treino de segmentação (opcional)\n",
    "SEG_MODEL_ID = \"unetpp_effb7\"\n",
    "SEG_ENCODER = \"efficientnet-b7\"\n",
    "SEG_PATCH_SIZE = 512\n",
    "SEG_BATCH_SIZE = 8\n",
    "SEG_EPOCHS = 15\n",
    "SEG_LR = 1e-3\n",
    "SEG_WEIGHT_DECAY = 1e-2\n",
    "\n",
    "if RUN_TRAIN_SEG:\n",
    "    train_aug = get_train_augment(patch_size=SEG_PATCH_SIZE, copy_move_prob=0.20)\n",
    "    val_aug = get_val_augment()\n",
    "\n",
    "    ds_seg_train = PatchDataset([train_samples[i] for i in train_idx.tolist()], patch_size=SEG_PATCH_SIZE, train=True, augment=train_aug, positive_prob=0.7, seed=SEED)\n",
    "    ds_seg_val = PatchDataset([train_samples[i] for i in val_idx.tolist()], patch_size=SEG_PATCH_SIZE, train=False, augment=val_aug, seed=SEED)\n",
    "\n",
    "    num_workers = 2 if is_kaggle() else 0\n",
    "    dl_seg_train = DataLoader(ds_seg_train, batch_size=SEG_BATCH_SIZE, shuffle=True, num_workers=num_workers, pin_memory=(DEVICE == \"cuda\"), drop_last=True)\n",
    "    dl_seg_val = DataLoader(ds_seg_val, batch_size=SEG_BATCH_SIZE, shuffle=False, num_workers=num_workers, pin_memory=(DEVICE == \"cuda\"), drop_last=False)\n",
    "\n",
    "    seg_model = builders.build_unetplusplus(encoder_name=SEG_ENCODER, encoder_weights=None, classes=1, strict_weights=True).to(DEVICE)\n",
    "    seg_criterion = BCETverskyLoss(alpha=0.7, beta=0.3, tversky_weight=1.0)\n",
    "    seg_optimizer = torch.optim.AdamW(seg_model.parameters(), lr=SEG_LR, weight_decay=SEG_WEIGHT_DECAY)\n",
    "\n",
    "    def output_root() -> Path:\n",
    "        return Path(\"/kaggle/working\") if is_kaggle() else Path(\".\").resolve()\n",
    "\n",
    "    seg_save_dir = output_root() / \"outputs\" / \"models_seg\" / SEG_MODEL_ID / f\"fold_{int(FOLD)}\"\n",
    "    seg_save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    seg_best_path = seg_save_dir / \"best.pt\"\n",
    "\n",
    "    use_amp = (DEVICE == \"cuda\")\n",
    "    best_dice = -1.0\n",
    "    for epoch in range(1, int(SEG_EPOCHS) + 1):\n",
    "        tr = train_one_epoch(seg_model, dl_seg_train, seg_criterion, seg_optimizer, DEVICE, use_amp=use_amp, progress=True, desc=\"seg train\")\n",
    "        val_stats, val_dice = validate(seg_model, dl_seg_val, seg_criterion, DEVICE, progress=True, desc=\"seg val\")\n",
    "        print(f\"[SEG] epoch {epoch:02d}/{SEG_EPOCHS} | train_loss={tr.loss:.4f} | val_loss={val_stats.loss:.4f} | dice@0.5={val_dice:.4f}\")\n",
    "        if float(val_dice) > best_dice:\n",
    "            best_dice = float(val_dice)\n",
    "            ckpt = {\n",
    "                \"model_state\": seg_model.state_dict(),\n",
    "                \"config\": {\"backend\": \"smp\", \"arch\": \"unetplusplus\", \"encoder_name\": SEG_ENCODER, \"encoder_weights\": None, \"classes\": 1, \"model_id\": SEG_MODEL_ID, \"patch_size\": int(SEG_PATCH_SIZE), \"fold\": int(FOLD), \"seed\": int(SEED)},\n",
    "                \"score\": float(best_dice),\n",
    "            }\n",
    "            torch.save(ckpt, seg_best_path)\n",
    "            print(\"[SEG] saved best ->\", seg_best_path)\n",
    "\n",
    "    print(\"[SEG] done. best dice:\", best_dice)\n",
    "else:\n",
    "    print(\"[SEG] RUN_TRAIN_SEG=False (pulando).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e405c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 4 — Célula 8: Carregar checkpoints (para inferência/submissão)\n",
    "\n",
    "\n",
    "def output_root() -> Path:\n",
    "    return Path(\"/kaggle/working\") if is_kaggle() else Path(\".\").resolve()\n",
    "\n",
    "\n",
    "def _find_models_dir(dir_name: str) -> Path | None:\n",
    "    if is_kaggle():\n",
    "        ki = Path(\"/kaggle/input\")\n",
    "        if ki.exists():\n",
    "            candidates = []\n",
    "            for ds in sorted(ki.glob(\"*\")):\n",
    "                for base in (ds, ds / \"recodai_bundle\"):\n",
    "                    cand = base / \"outputs\" / dir_name\n",
    "                    if cand.exists():\n",
    "                        candidates.append(cand)\n",
    "            if candidates:\n",
    "                if len(candidates) > 1:\n",
    "                    print(f\"[CKPT] múltiplos candidatos para outputs/{dir_name}; usando o primeiro:\")\n",
    "                    for c in candidates:\n",
    "                        print(\" -\", c)\n",
    "                return candidates[0]\n",
    "\n",
    "    local = output_root() / \"outputs\" / dir_name\n",
    "    if local.exists():\n",
    "        return local\n",
    "    return None\n",
    "\n",
    "\n",
    "MODELS_SEG_DIR = _find_models_dir(\"models_seg\")\n",
    "MODELS_CLS_DIR = _find_models_dir(\"models_cls\")\n",
    "print(\"MODELS_SEG_DIR:\", MODELS_SEG_DIR)\n",
    "print(\"MODELS_CLS_DIR:\", MODELS_CLS_DIR)\n",
    "\n",
    "SEG_MODELS: list[nn.Module] = []\n",
    "if MODELS_SEG_DIR is not None:\n",
    "    for ckpt_path in sorted(MODELS_SEG_DIR.glob(\"*/*/best.pt\")):\n",
    "        try:\n",
    "            state, cfg = load_checkpoint(ckpt_path)\n",
    "            m = build_segmentation_from_config(cfg)\n",
    "            m.load_state_dict(state)\n",
    "            m.to(DEVICE)\n",
    "            m.eval()\n",
    "            SEG_MODELS.append(m)\n",
    "        except Exception:\n",
    "            print(\"[ERRO] falha ao carregar seg:\", ckpt_path)\n",
    "            traceback.print_exc()\n",
    "\n",
    "CLS_MODELS: list[nn.Module] = []\n",
    "CLS_INFER_IMAGE_SIZE = CLS_IMAGE_SIZE\n",
    "if MODELS_CLS_DIR is not None:\n",
    "    for ckpt_path in sorted(MODELS_CLS_DIR.glob(\"fold_*/best.pt\")):\n",
    "        try:\n",
    "            state, cfg = load_checkpoint(ckpt_path)\n",
    "            m, image_size = build_classifier_from_config(cfg)\n",
    "            CLS_INFER_IMAGE_SIZE = int(image_size)\n",
    "            m.load_state_dict(state)\n",
    "            m.to(DEVICE)\n",
    "            m.eval()\n",
    "            CLS_MODELS.append(m)\n",
    "        except Exception:\n",
    "            print(\"[ERRO] falha ao carregar cls:\", ckpt_path)\n",
    "            traceback.print_exc()\n",
    "\n",
    "print(\"loaded seg models:\", len(SEG_MODELS))\n",
    "print(\"loaded cls models:\", len(CLS_MODELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dd0ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fase 4 — Célula 9: Inferência + submission\n",
    "TILE_SIZE = 1024\n",
    "OVERLAP = 128\n",
    "MAX_SIZE = 0\n",
    "THRESHOLD = 0.50\n",
    "MIN_AREA = 32\n",
    "USE_TTA = True\n",
    "TTA_MODES = (\"none\", \"hflip\", \"vflip\")\n",
    "\n",
    "\n",
    "def _apply_tta(image: np.ndarray, mode: str) -> np.ndarray:\n",
    "    if mode == \"none\":\n",
    "        return image\n",
    "    if mode == \"hflip\":\n",
    "        return np.ascontiguousarray(image[:, ::-1])\n",
    "    if mode == \"vflip\":\n",
    "        return np.ascontiguousarray(image[::-1, :])\n",
    "    raise ValueError(f\"tta mode inválido: {mode}\")\n",
    "\n",
    "\n",
    "def _undo_tta(mask: np.ndarray, mode: str) -> np.ndarray:\n",
    "    if mode == \"none\":\n",
    "        return mask\n",
    "    if mode == \"hflip\":\n",
    "        return np.ascontiguousarray(mask[:, ::-1])\n",
    "    if mode == \"vflip\":\n",
    "        return np.ascontiguousarray(mask[::-1, :])\n",
    "    raise ValueError(f\"tta mode inválido: {mode}\")\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_prob_forged(image: np.ndarray) -> float:\n",
    "    import torch.nn.functional as F\n",
    "\n",
    "    img = normalize_image(image)\n",
    "    x = torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0).to(DEVICE)\n",
    "    if CLS_INFER_IMAGE_SIZE and x.shape[-2:] != (CLS_INFER_IMAGE_SIZE, CLS_INFER_IMAGE_SIZE):\n",
    "        x = F.interpolate(x, size=(CLS_INFER_IMAGE_SIZE, CLS_INFER_IMAGE_SIZE), mode=\"bilinear\", align_corners=False)\n",
    "    probs: list[float] = []\n",
    "    for m in CLS_MODELS:\n",
    "        logits = m(x).view(-1)\n",
    "        probs.append(float(torch.sigmoid(logits)[0].item()))\n",
    "    return float(np.mean(probs)) if probs else 0.0\n",
    "\n",
    "\n",
    "def predict_seg_ensemble_prob(image: np.ndarray) -> np.ndarray:\n",
    "    if not SEG_MODELS:\n",
    "        msg = (\n",
    "            \"Nenhum modelo de segmentação carregado.\\n\"\n",
    "            f\"- MODELS_SEG_DIR={MODELS_SEG_DIR}\\n\"\n",
    "            \"- Esperado: `outputs/models_seg/<model_id>/fold_*/best.pt` (no Kaggle: /kaggle/working/outputs/...)\\n\"\n",
    "            \"- Soluções:\\n\"\n",
    "            \"  1) Rode treino aqui: defina `RUN_TRAIN_SEG=True` e execute as células de treino.\\n\"\n",
    "            \"  2) Anexe um Dataset com checkpoints em `outputs/models_seg/...` e rode novamente.\\n\"\n",
    "        )\n",
    "        raise RuntimeError(msg)\n",
    "    probs_sum: np.ndarray | None = None\n",
    "    count = 0\n",
    "    modes = TTA_MODES if USE_TTA else (\"none\",)\n",
    "    for mode in modes:\n",
    "        img_t = _apply_tta(image, mode)\n",
    "        ens: np.ndarray | None = None\n",
    "        for m in SEG_MODELS:\n",
    "            p = predict_image(m, img_t, DEVICE, tile_size=TILE_SIZE, overlap=OVERLAP, max_size=MAX_SIZE)\n",
    "            ens = p if ens is None else (ens + p)\n",
    "        assert ens is not None\n",
    "        ens = ens / float(len(SEG_MODELS))\n",
    "        ens = _undo_tta(ens, mode)\n",
    "        probs_sum = ens if probs_sum is None else (probs_sum + ens)\n",
    "        count += 1\n",
    "    assert probs_sum is not None\n",
    "    return probs_sum / float(max(count, 1))\n",
    "\n",
    "\n",
    "def predict_instances(image: np.ndarray) -> list[np.ndarray]:\n",
    "    prob = predict_seg_ensemble_prob(image)\n",
    "    bin_mask = binarize(prob, threshold=THRESHOLD)\n",
    "    return extract_components(bin_mask, min_area=int(MIN_AREA))\n",
    "\n",
    "\n",
    "if RUN_SUBMISSION:\n",
    "    if not SEG_MODELS:\n",
    "        raise RuntimeError(\n",
    "            \"RUN_SUBMISSION=True, mas nenhum modelo de segmentação foi carregado.\\n\"\n",
    "            f\"- MODELS_SEG_DIR={MODELS_SEG_DIR}\\n\"\n",
    "            \"Treine (RUN_TRAIN_SEG=True) ou anexe um Dataset com `outputs/models_seg/<model_id>/fold_*/best.pt`.\"\n",
    "        )\n",
    "    SUBMISSION_PATH = Path(\"/kaggle/working/submission.csv\") if is_kaggle() else (output_root() / \"submission.csv\")\n",
    "    SUBMISSION_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    with SUBMISSION_PATH.open(\"w\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"case_id\", \"annotation\"])\n",
    "        writer.writeheader()\n",
    "\n",
    "        for s in tqdm(test_samples, desc=\"infer\"):\n",
    "            img = load_image(s.image_path)\n",
    "            if CLS_MODELS:\n",
    "                p_forged = predict_prob_forged(img)\n",
    "                if float(p_forged) < float(CLS_SKIP_THRESHOLD):\n",
    "                    writer.writerow({\"case_id\": s.case_id, \"annotation\": AUTHENTIC_LABEL})\n",
    "                    continue\n",
    "            inst = predict_instances(img)\n",
    "            writer.writerow({\"case_id\": s.case_id, \"annotation\": encode_instances(inst)})\n",
    "\n",
    "    print(\"wrote:\", SUBMISSION_PATH)\n",
    "else:\n",
    "    print(\"[SUBMISSION] RUN_SUBMISSION=False; não gerou CSV.\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
