{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Recod.ai/LUC — Submission (Kaggle)\n",
        "\n",
        "Gera `submission.csv` no formato da competição a partir de 1+ configs em `configs/*.json`, com suporte a:\n",
        "\n",
        "- Segmentação (DINOv2) + pós-processamento + TTA (via config)\n",
        "- `fft_gate` (opcional) para revisar casos `authentic`\n",
        "- `dinov2_freq_fusion` (opcional) via `model_type`\n",
        "- Ensemble de múltiplas submissões (opcional)\n",
        "\n",
        "**No Kaggle**:\n",
        "1. Anexe o dataset da competição.\n",
        "2. (Opcional) Anexe um dataset com seus checkpoints em `outputs/models/*.pth`.\n",
        "3. (Recomendado) Anexe um dataset com este repo (pelo menos `src/` e `configs/`).\n",
        "4. Rode todas as células; o arquivo final fica em `/kaggle/working/submission.csv`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import dataclasses\n",
        "import json\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def _find_code_root() -> Path:\n",
        "    cwd = Path.cwd()\n",
        "    for p in [cwd, *cwd.parents]:\n",
        "        if (p / \"src\" / \"forgeryseg\").exists():\n",
        "            return p\n",
        "\n",
        "    kaggle_input = Path(\"/kaggle/input\")\n",
        "    if kaggle_input.exists():\n",
        "        for d in kaggle_input.iterdir():\n",
        "            if not d.is_dir():\n",
        "                continue\n",
        "            if (d / \"src\" / \"forgeryseg\").exists():\n",
        "                return d\n",
        "            try:\n",
        "                for child in d.iterdir():\n",
        "                    if child.is_dir() and (child / \"src\" / \"forgeryseg\").exists():\n",
        "                        return child\n",
        "            except PermissionError:\n",
        "                continue\n",
        "\n",
        "    raise FileNotFoundError(\n",
        "        \"Não encontrei o código (src/forgeryseg). \"\n",
        "        \"No Kaggle: anexe um Dataset contendo este repo (com pastas src/ e configs/).\"\n",
        "    )\n",
        "\n",
        "\n",
        "CODE_ROOT = _find_code_root()\n",
        "SRC = CODE_ROOT / \"src\"\n",
        "CONFIG_ROOT = CODE_ROOT / \"configs\"\n",
        "print(f\"code_root={CODE_ROOT}\")\n",
        "\n",
        "if str(SRC) not in sys.path:\n",
        "    sys.path.insert(0, str(SRC))\n",
        "\n",
        "from forgeryseg.checkpoint import load_flexible_state_dict\n",
        "from forgeryseg.dataset import list_cases\n",
        "from forgeryseg.ensemble import ensemble_annotations, rank_weights_by_score\n",
        "from forgeryseg.frequency import FFTParams, fft_tensor\n",
        "from forgeryseg.inference import default_tta, load_rgb, predict_prob_map\n",
        "from forgeryseg.models.dinov2_decoder import DinoV2EncoderSpec, DinoV2SegmentationModel\n",
        "from forgeryseg.models.dinov2_freq_fusion import DinoV2FreqFusionSegmentationModel, FreqFusionSpec\n",
        "from forgeryseg.models.fft_classifier import FFTClassifier\n",
        "from forgeryseg.postprocess import PostprocessParams, postprocess_prob\n",
        "from forgeryseg.rle import masks_to_annotation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Config (edite aqui)\n",
        "# -------------------------\n",
        "\n",
        "DATA_ROOT: Path | None = None  # None => auto-detect (Kaggle -> local)\n",
        "SPLIT = \"test\"  # \"test\" no Kaggle (train/supplemental só para debug)\n",
        "LIMIT = 0  # 0 = sem limite\n",
        "SKIP_MISSING_CONFIGS = True  # se faltar config/ckpt, pula ao invés de quebrar\n",
        "\n",
        "# 1+ configs para gerar submissões individuais\n",
        "CONFIG_PATHS = [\n",
        "    CONFIG_ROOT / \"dino_v3_518_r69_fft_gate.json\",\n",
        "    # CONFIG_ROOT / \"dino_v2_518_basev1.json\",\n",
        "    # CONFIG_ROOT / \"dino_v1_718_u52.json\",\n",
        "    # CONFIG_ROOT / \"dino_v3_518_r69_freq_fusion.json\",\n",
        "]\n",
        "\n",
        "# ensemble (opcional) se CONFIG_PATHS tiver 2+\n",
        "DO_ENSEMBLE = len(CONFIG_PATHS) > 1\n",
        "ENSEMBLE_METHOD = \"weighted\"  # weighted | majority | union | intersection\n",
        "ENSEMBLE_THRESHOLD = 0.5  # só para method=\"weighted\"\n",
        "\n",
        "# Se quiser pesos fixos, preencha WEIGHTS (mesmo tamanho de CONFIG_PATHS).\n",
        "# Caso contrário, se SCORES for fornecido, os pesos vêm de rank_weights_by_score(scores).\n",
        "WEIGHTS: list[float] | None = None\n",
        "SCORES: list[float] | None = None\n",
        "\n",
        "OUT_DIR = Path(\"/kaggle/working\") if Path(\"/kaggle/working\").exists() else Path(\"outputs\")\n",
        "FINAL_OUT = OUT_DIR / \"submission.csv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def _find_recodai_root() -> Path:\n",
        "    if DATA_ROOT is not None:\n",
        "        return Path(DATA_ROOT)\n",
        "\n",
        "    kaggle_input = Path(\"/kaggle/input\")\n",
        "    if kaggle_input.exists():\n",
        "        for d in kaggle_input.iterdir():\n",
        "            if not d.is_dir():\n",
        "                continue\n",
        "            if (d / \"recodai\" / \"sample_submission.csv\").exists():\n",
        "                return d / \"recodai\"\n",
        "            if (d / \"sample_submission.csv\").exists() and (d / \"test_images\").exists():\n",
        "                return d\n",
        "\n",
        "    local = Path(\"data/recodai\")\n",
        "    if local.exists():\n",
        "        return local\n",
        "    local2 = CODE_ROOT / \"data\" / \"recodai\"\n",
        "    if local2.exists():\n",
        "        return local2\n",
        "\n",
        "    raise FileNotFoundError(\n",
        "        \"Não encontrei o data root. Defina DATA_ROOT manualmente \"\n",
        "        \"(ex.: /kaggle/input/<dataset>/recodai ou data/recodai).\"\n",
        "    )\n",
        "\n",
        "\n",
        "def _resolve_maybe_in_kaggle_input(path: str | Path) -> Path:\n",
        "    p = Path(path)\n",
        "    if p.exists():\n",
        "        return p\n",
        "    if p.is_absolute():\n",
        "        return p\n",
        "    cand_local = CODE_ROOT / p\n",
        "    if cand_local.exists():\n",
        "        return cand_local\n",
        "\n",
        "    kaggle_input = Path(\"/kaggle/input\")\n",
        "    if kaggle_input.exists():\n",
        "        for d in kaggle_input.iterdir():\n",
        "            if not d.is_dir():\n",
        "                continue\n",
        "            cand = d / p\n",
        "            if cand.exists():\n",
        "                return cand\n",
        "    return p\n",
        "\n",
        "\n",
        "def _warn_state_dict(missing: list[str], unexpected: list[str]) -> None:\n",
        "    if missing:\n",
        "        print(f\"[warn] Missing keys ({len(missing)}): {missing[:5]}{'...' if len(missing) > 5 else ''}\")\n",
        "    if unexpected:\n",
        "        print(f\"[warn] Unexpected keys ({len(unexpected)}): {unexpected[:5]}{'...' if len(unexpected) > 5 else ''}\")\n",
        "\n",
        "\n",
        "def _load_segmentation_model(cfg: dict, *, device: torch.device) -> torch.nn.Module:\n",
        "    enc_cfg = cfg.get(\"encoder\", {})\n",
        "    encoder = DinoV2EncoderSpec(\n",
        "        model_name=enc_cfg.get(\"model_name\", \"vit_base_patch14_dinov2\"),\n",
        "        checkpoint_path=enc_cfg.get(\"checkpoint_path\"),\n",
        "    )\n",
        "\n",
        "    model_type = str(cfg.get(\"model_type\", \"dinov2\"))\n",
        "    if model_type == \"dinov2_freq_fusion\":\n",
        "        freq = FreqFusionSpec(**cfg.get(\"freq_fusion\", {}))\n",
        "        model = DinoV2FreqFusionSegmentationModel(\n",
        "            encoder,\n",
        "            decoder_hidden_channels=int(cfg.get(\"decoder_hidden_channels\", 256)),\n",
        "            decoder_dropout=float(cfg.get(\"decoder_dropout\", 0.0)),\n",
        "            freeze_encoder=bool(cfg.get(\"freeze_encoder\", True)),\n",
        "            freq=freq,\n",
        "        )\n",
        "    else:\n",
        "        model = DinoV2SegmentationModel(\n",
        "            encoder,\n",
        "            decoder_hidden_channels=int(cfg.get(\"decoder_hidden_channels\", 256)),\n",
        "            decoder_dropout=float(cfg.get(\"decoder_dropout\", 0.0)),\n",
        "            freeze_encoder=bool(cfg.get(\"freeze_encoder\", True)),\n",
        "        )\n",
        "\n",
        "    ckpt = cfg.get(\"checkpoint\")\n",
        "    if ckpt:\n",
        "        ckpt_path = _resolve_maybe_in_kaggle_input(ckpt)\n",
        "        if not ckpt_path.exists():\n",
        "            raise FileNotFoundError(f\"Checkpoint não encontrado: {ckpt} (tentado: {ckpt_path})\")\n",
        "        missing, unexpected = load_flexible_state_dict(model, ckpt_path)\n",
        "        _warn_state_dict(missing, unexpected)\n",
        "\n",
        "    return model.to(device).eval()\n",
        "\n",
        "\n",
        "def _load_fft_gate(cfg: dict, *, device: torch.device) -> tuple[FFTClassifier, FFTParams, float] | None:\n",
        "    fft_gate = cfg.get(\"fft_gate\")\n",
        "    if not isinstance(fft_gate, dict) or not fft_gate.get(\"enabled\", True):\n",
        "        return None\n",
        "\n",
        "    fft_ckpt = fft_gate.get(\"checkpoint\")\n",
        "    if not fft_ckpt:\n",
        "        raise ValueError(\"fft_gate.enabled is true but fft_gate.checkpoint is missing\")\n",
        "    fft_ckpt_path = _resolve_maybe_in_kaggle_input(fft_ckpt)\n",
        "    if not fft_ckpt_path.exists():\n",
        "        raise FileNotFoundError(f\"FFT checkpoint não encontrado: {fft_ckpt} (tentado: {fft_ckpt_path})\")\n",
        "\n",
        "    fft_params = FFTParams(**fft_gate.get(\"fft\", {}))\n",
        "    fft_threshold = float(fft_gate.get(\"threshold\", 0.5))\n",
        "    fft_model = FFTClassifier(\n",
        "        backbone=fft_gate.get(\"backbone\", \"resnet18\"),\n",
        "        in_chans=1,\n",
        "        dropout=float(fft_gate.get(\"dropout\", 0.0)),\n",
        "    )\n",
        "    missing, unexpected = load_flexible_state_dict(fft_model, fft_ckpt_path)\n",
        "    _warn_state_dict(missing, unexpected)\n",
        "    return fft_model.to(device).eval(), fft_params, fft_threshold\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict_submission_for_config(\n",
        "    *,\n",
        "    config_path: Path,\n",
        "    data_root: Path,\n",
        "    split: str,\n",
        "    out_path: Path,\n",
        "    device: torch.device,\n",
        "    limit: int = 0,\n",
        ") -> None:\n",
        "    cfg = json.loads(config_path.read_text())\n",
        "    input_size = int(cfg[\"input_size\"])\n",
        "    post = PostprocessParams(**cfg.get(\"postprocess\", {}))\n",
        "\n",
        "    tta_cfg = cfg.get(\"tta\", {})\n",
        "    tta_transforms, tta_weights = default_tta(\n",
        "        zoom_scale=float(tta_cfg.get(\"zoom_scale\", 0.9)),\n",
        "        weights=tuple(tta_cfg.get(\"weights\", [0.5, 0.25, 0.25])),\n",
        "    )\n",
        "\n",
        "    model = _load_segmentation_model(cfg, device=device)\n",
        "    fft_gate = _load_fft_gate(cfg, device=device)\n",
        "\n",
        "    cases = list_cases(data_root, split, include_authentic=True, include_forged=True)\n",
        "    if split == \"test\":\n",
        "        sample = pd.read_csv(data_root / \"sample_submission.csv\")\n",
        "        sample[\"case_id\"] = sample[\"case_id\"].astype(str)\n",
        "        case_ids = sample[\"case_id\"].tolist()\n",
        "    else:\n",
        "        case_ids = [c.case_id for c in cases]\n",
        "\n",
        "    case_by_id = {c.case_id: c for c in cases}\n",
        "    if split == \"test\":\n",
        "        missing = [cid for cid in case_ids if cid not in case_by_id]\n",
        "        if missing:\n",
        "            raise RuntimeError(\n",
        "                f\"{len(missing)} case_id(s) do sample_submission não foram encontrados em {split}_images \"\n",
        "                f\"(ex.: {missing[:5]}). Verifique o DATA_ROOT.\"\n",
        "            )\n",
        "        ordered = [case_by_id[cid] for cid in case_ids]\n",
        "    else:\n",
        "        ordered = cases\n",
        "\n",
        "    if limit and limit > 0:\n",
        "        ordered = ordered[: int(limit)]\n",
        "\n",
        "    rows: list[dict[str, str]] = []\n",
        "    n_fft_overrides = 0\n",
        "    for case in tqdm(ordered, desc=f\"Predict ({config_path.name})\"):\n",
        "        image = load_rgb(case.image_path)\n",
        "\n",
        "        prob = predict_prob_map(\n",
        "            model,\n",
        "            image,\n",
        "            input_size=input_size,\n",
        "            device=device,\n",
        "            tta_transforms=tta_transforms,\n",
        "            tta_weights=tta_weights,\n",
        "        )\n",
        "        instances = postprocess_prob(prob, post)\n",
        "        ann = masks_to_annotation(instances)\n",
        "\n",
        "        if ann == \"authentic\" and fft_gate is not None:\n",
        "            fft_model, fft_params, fft_threshold = fft_gate\n",
        "            x_fft = fft_tensor(image, fft_params).unsqueeze(0).to(device)\n",
        "            p_forged = float(torch.sigmoid(fft_model(x_fft))[0].detach().cpu().item())\n",
        "\n",
        "            if p_forged >= float(fft_threshold):\n",
        "                relaxed_post = dataclasses.replace(post, authentic_area_max=None, authentic_conf_max=None)\n",
        "                instances_relaxed = postprocess_prob(prob, relaxed_post)\n",
        "                ann_relaxed = masks_to_annotation(instances_relaxed)\n",
        "                if ann_relaxed != \"authentic\":\n",
        "                    ann = ann_relaxed\n",
        "                    n_fft_overrides += 1\n",
        "\n",
        "        rows.append({\"case_id\": case.case_id, \"annotation\": ann})\n",
        "\n",
        "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    out_df = pd.DataFrame(rows)\n",
        "    out_df.to_csv(out_path, index=False)\n",
        "    n_auth = int((out_df[\"annotation\"] == \"authentic\").sum())\n",
        "    print(f\"Wrote {out_path} ({n_auth}/{len(out_df)} authentic)\")\n",
        "    if fft_gate is not None:\n",
        "        print(f\"fft_gate overrides: {n_fft_overrides}\")\n",
        "\n",
        "\n",
        "def ensemble_submissions_from_csvs(\n",
        "    *,\n",
        "    sub_paths: list[Path],\n",
        "    data_root: Path,\n",
        "    split: str,\n",
        "    out_path: Path,\n",
        "    method: str = \"weighted\",\n",
        "    weights: list[float] | None = None,\n",
        "    scores: list[float] | None = None,\n",
        "    threshold: float = 0.5,\n",
        ") -> None:\n",
        "    tables: list[dict[str, str]] = []\n",
        "    for p in sub_paths:\n",
        "        df = pd.read_csv(p)\n",
        "        if \"case_id\" not in df.columns or \"annotation\" not in df.columns:\n",
        "            raise ValueError(f\"{p} precisa ter colunas case_id,annotation\")\n",
        "        tables.append(dict(zip(df[\"case_id\"].astype(str), df[\"annotation\"], strict=True)))\n",
        "\n",
        "    if method == \"weighted\":\n",
        "        if weights is None:\n",
        "            if scores is None:\n",
        "                weights = [1.0 / len(sub_paths)] * len(sub_paths)\n",
        "            else:\n",
        "                weights = rank_weights_by_score(scores)\n",
        "        if len(weights) != len(sub_paths):\n",
        "            raise ValueError(\"weights precisa ter o mesmo tamanho de sub_paths\")\n",
        "        print(f\"ensemble weights={weights}\")\n",
        "\n",
        "    cases = list_cases(data_root, split, include_authentic=True, include_forged=True)\n",
        "    if split == \"test\":\n",
        "        sample = pd.read_csv(data_root / \"sample_submission.csv\")\n",
        "        sample[\"case_id\"] = sample[\"case_id\"].astype(str)\n",
        "        case_by_id = {c.case_id: c for c in cases}\n",
        "        case_ids = sample[\"case_id\"].tolist()\n",
        "        missing = [cid for cid in case_ids if cid not in case_by_id]\n",
        "        if missing:\n",
        "            raise RuntimeError(\n",
        "                f\"{len(missing)} case_id(s) do sample_submission não foram encontrados em {split}_images \"\n",
        "                f\"(ex.: {missing[:5]}). Verifique o DATA_ROOT.\"\n",
        "            )\n",
        "        cases = [case_by_id[cid] for cid in case_ids]\n",
        "\n",
        "    import cv2\n",
        "\n",
        "    rows: list[dict[str, str]] = []\n",
        "    for case in tqdm(cases, desc=\"Ensemble\"):\n",
        "        h, w = cv2.imread(str(case.image_path), cv2.IMREAD_UNCHANGED).shape[:2]\n",
        "        anns = [t.get(case.case_id, \"authentic\") for t in tables]\n",
        "        ann_out = ensemble_annotations(\n",
        "            anns,\n",
        "            shape=(h, w),\n",
        "            method=method,\n",
        "            weights=weights if method == \"weighted\" else None,\n",
        "            threshold=float(threshold),\n",
        "        )\n",
        "        rows.append({\"case_id\": case.case_id, \"annotation\": ann_out})\n",
        "\n",
        "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    out_df = pd.DataFrame(rows)\n",
        "    out_df.to_csv(out_path, index=False)\n",
        "    n_auth = int((out_df[\"annotation\"] == \"authentic\").sum())\n",
        "    print(f\"Wrote {out_path} ({n_auth}/{len(out_df)} authentic)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Run\n",
        "# -------------------------\n",
        "\n",
        "data_root = _find_recodai_root()\n",
        "print(f\"data_root={data_root}\")\n",
        "print(f\"configs={[p.as_posix() for p in CONFIG_PATHS]}\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"device={device}\")\n",
        "\n",
        "try:\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "sub_paths: list[Path] = []\n",
        "for cfg_path in CONFIG_PATHS:\n",
        "    if not cfg_path.exists():\n",
        "        msg = f\"[warn] Config não encontrado: {cfg_path}\"\n",
        "        if SKIP_MISSING_CONFIGS:\n",
        "            print(msg)\n",
        "            continue\n",
        "        raise FileNotFoundError(msg)\n",
        "\n",
        "    cfg = json.loads(cfg_path.read_text())\n",
        "    name = str(cfg.get(\"name\", cfg_path.stem))\n",
        "    out_path = OUT_DIR / f\"submission_{name}.csv\"\n",
        "    try:\n",
        "        predict_submission_for_config(\n",
        "            config_path=cfg_path,\n",
        "            data_root=data_root,\n",
        "            split=SPLIT,\n",
        "            out_path=out_path,\n",
        "            device=device,\n",
        "            limit=LIMIT,\n",
        "        )\n",
        "        sub_paths.append(out_path)\n",
        "    except FileNotFoundError as e:\n",
        "        if SKIP_MISSING_CONFIGS:\n",
        "            print(f\"[warn] {e} (pulando {cfg_path.name})\")\n",
        "            continue\n",
        "        raise\n",
        "\n",
        "if not sub_paths:\n",
        "    raise RuntimeError(\"Nenhuma submissão foi gerada (verifique configs/checkpoints).\")\n",
        "\n",
        "if DO_ENSEMBLE and len(sub_paths) > 1:\n",
        "    ensemble_submissions_from_csvs(\n",
        "        sub_paths=sub_paths,\n",
        "        data_root=data_root,\n",
        "        split=SPLIT,\n",
        "        out_path=FINAL_OUT,\n",
        "        method=str(ENSEMBLE_METHOD),\n",
        "        weights=WEIGHTS,\n",
        "        scores=SCORES,\n",
        "        threshold=float(ENSEMBLE_THRESHOLD),\n",
        "    )\n",
        "else:\n",
        "    FINAL_OUT.parent.mkdir(parents=True, exist_ok=True)\n",
        "    if sub_paths:\n",
        "        Path(sub_paths[0]).replace(FINAL_OUT)\n",
        "    print(f\"Wrote {FINAL_OUT}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
