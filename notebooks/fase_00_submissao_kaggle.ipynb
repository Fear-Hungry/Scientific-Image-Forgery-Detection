{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe2ed332",
   "metadata": {},
   "source": [
    "# Fase 00 — Submissão (Kaggle)\n",
    "\n",
    "Notebook **enxuto** para gerar `submission.csv` no Kaggle (preferencialmente com **internet OFF**).\n",
    "\n",
    "Ele assume que você já tem checkpoints em `outputs/models_seg` (e opcionalmente `outputs/models_cls`),\n",
    "normalmente gerados no **Fase 01** (pré-treinamento) e anexados como Kaggle Dataset.\n",
    "\n",
    "Saída:\n",
    "- Kaggle: `/kaggle/working/submission.csv`\n",
    "- Local: `outputs/submission.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78e653f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10c932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers de ambiente (mínimos)\n",
    "\n",
    "\n",
    "def is_kaggle() -> bool:\n",
    "    return bool(os.environ.get(\"KAGGLE_URL_BASE\")) or Path(\"/kaggle\").exists()\n",
    "\n",
    "\n",
    "def env_str(name: str, default: str = \"\") -> str:\n",
    "    value = os.environ.get(name, \"\")\n",
    "    return str(default) if value == \"\" else str(value)\n",
    "\n",
    "\n",
    "def env_bool(name: str, default: bool = False) -> bool:\n",
    "    value = env_str(name, \"\").strip().lower()\n",
    "    if value == \"\":\n",
    "        return bool(default)\n",
    "    return value in {\"1\", \"true\", \"yes\", \"y\", \"on\"}\n",
    "\n",
    "\n",
    "def env_path(name: str) -> Path | None:\n",
    "    value = env_str(name, \"\").strip()\n",
    "    return Path(value) if value else None\n",
    "\n",
    "\n",
    "def run_cmd(cmd: list[str], cwd: Path | None = None) -> None:\n",
    "    cmd_str = \" \".join(str(c) for c in cmd)\n",
    "    print(\"[cmd]\", cmd_str)\n",
    "    subprocess.run(cmd, check=True, cwd=str(cwd) if cwd else None)\n",
    "\n",
    "\n",
    "def find_repo_root() -> Path | None:\n",
    "    explicit = env_path(\"FORGERYSEG_REPO_ROOT\")\n",
    "    if explicit is not None:\n",
    "        return explicit if explicit.exists() else None\n",
    "\n",
    "    here = Path(\".\").resolve()\n",
    "    for cand in [here] + list(here.parents):\n",
    "        if (cand / \"src\" / \"forgeryseg\" / \"__init__.py\").exists() and (cand / \"scripts\").exists():\n",
    "            return cand\n",
    "\n",
    "    if is_kaggle():\n",
    "        ki = Path(\"/kaggle/input\")\n",
    "        if ki.exists():\n",
    "            for ds in sorted(ki.glob(\"*\")):\n",
    "                for base in (ds, ds / \"recodai_bundle\"):\n",
    "                    if (base / \"src\" / \"forgeryseg\" / \"__init__.py\").exists():\n",
    "                        return base\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_data_root() -> Path | None:\n",
    "    explicit = env_path(\"FORGERYSEG_DATA_ROOT\")\n",
    "    if explicit is not None and (explicit / \"train_images\").exists():\n",
    "        return explicit\n",
    "\n",
    "    candidates = [\n",
    "        Path(\"data/recodai\"),\n",
    "        Path(\"/kaggle/input/recodai-luc-scientific-image-forgery-detection/recodai\"),\n",
    "        Path(\"/kaggle/input/recodai-luc-scientific-image-forgery-detection\"),\n",
    "    ]\n",
    "    for cand in candidates:\n",
    "        if (cand / \"train_images\").exists():\n",
    "            return cand\n",
    "\n",
    "    if is_kaggle():\n",
    "        ki = Path(\"/kaggle/input\")\n",
    "        if ki.exists():\n",
    "            for ds in sorted(ki.glob(\"*\")):\n",
    "                if (ds / \"train_images\").exists():\n",
    "                    return ds\n",
    "                if (ds / \"recodai\" / \"train_images\").exists():\n",
    "                    return ds / \"recodai\"\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_wheels_root() -> Path | None:\n",
    "    explicit = env_path(\"FORGERYSEG_WHEELS_ROOT\")\n",
    "    if explicit is not None:\n",
    "        return explicit if explicit.exists() else None\n",
    "\n",
    "    local_candidates = [Path(\"recodai_bundle\") / \"wheels\", Path(\"wheels\")]\n",
    "    for cand in local_candidates:\n",
    "        if cand.exists() and any(cand.glob(\"*.whl\")):\n",
    "            return cand\n",
    "\n",
    "    if is_kaggle():\n",
    "        ki = Path(\"/kaggle/input\")\n",
    "        if ki.exists():\n",
    "            for ds in sorted(ki.glob(\"*\")):\n",
    "                for cand in (ds / \"wheels\", ds / \"recodai_bundle\" / \"wheels\"):\n",
    "                    if cand.exists() and any(cand.glob(\"*.whl\")):\n",
    "                        return cand\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_cache_root() -> Path | None:\n",
    "    explicit = env_path(\"FORGERYSEG_CACHE_ROOT\")\n",
    "    if explicit is not None:\n",
    "        return explicit if explicit.exists() else None\n",
    "\n",
    "    local_candidates = [Path(\"recodai_bundle\") / \"weights_cache\", Path(\"weights_cache\")]\n",
    "    for cand in local_candidates:\n",
    "        if cand.exists():\n",
    "            return cand\n",
    "\n",
    "    if is_kaggle():\n",
    "        ki = Path(\"/kaggle/input\")\n",
    "        if ki.exists():\n",
    "            for ds in sorted(ki.glob(\"*\")):\n",
    "                for cand in (ds / \"weights_cache\", ds / \"recodai_bundle\" / \"weights_cache\"):\n",
    "                    if cand.exists():\n",
    "                        return cand\n",
    "    return None\n",
    "\n",
    "\n",
    "def _missing_modules(mod_names: list[str]) -> list[str]:\n",
    "    missing: list[str] = []\n",
    "    for name in mod_names:\n",
    "        try:\n",
    "            __import__(name)\n",
    "        except Exception:\n",
    "            missing.append(name)\n",
    "    return missing\n",
    "\n",
    "\n",
    "def maybe_install_from_wheels(wheels_root: Path | None) -> None:\n",
    "    \"\"\"Instala apenas o que estiver faltando, via wheels locais (offline-safe).\"\"\"\n",
    "    if wheels_root is None:\n",
    "        return\n",
    "\n",
    "    module_to_pip = {\n",
    "        \"segmentation_models_pytorch\": \"segmentation-models-pytorch\",\n",
    "        \"timm\": \"timm\",\n",
    "        \"albumentations\": \"albumentations\",\n",
    "        \"huggingface_hub\": \"huggingface-hub\",\n",
    "        \"safetensors\": \"safetensors\",\n",
    "        \"tqdm\": \"tqdm\",\n",
    "    }\n",
    "    missing = _missing_modules(list(module_to_pip.keys()))\n",
    "    if not missing:\n",
    "        print(\"[wheels] ok (nada a instalar).\")\n",
    "        return\n",
    "\n",
    "    packages = [module_to_pip[m] for m in missing if m in module_to_pip]\n",
    "    if not packages:\n",
    "        return\n",
    "\n",
    "    print(\"[wheels] faltando:\", \", \".join(missing))\n",
    "    print(\"[wheels] instalando via --no-index/--find-links:\", wheels_root)\n",
    "    run_cmd(\n",
    "        [\n",
    "            sys.executable,\n",
    "            \"-m\",\n",
    "            \"pip\",\n",
    "            \"install\",\n",
    "            \"--no-index\",\n",
    "            \"--find-links\",\n",
    "            str(wheels_root),\n",
    "            *packages,\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def write_config(base_cfg: Path, out_path: Path, overrides: dict) -> Path:\n",
    "    with base_cfg.open(\"r\") as f:\n",
    "        cfg = json.load(f)\n",
    "    cfg.update(overrides)\n",
    "    out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with out_path.open(\"w\") as f:\n",
    "        json.dump(cfg, f, indent=2)\n",
    "    return out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ebca4a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Setup Kaggle offline + dependências\n",
    "\n",
    "KAGGLE = is_kaggle()\n",
    "ALLOW_DOWNLOAD = env_bool(\"FORGERYSEG_ALLOW_DOWNLOAD\", default=not KAGGLE)\n",
    "OFFLINE = bool(KAGGLE and not ALLOW_DOWNLOAD)\n",
    "\n",
    "INSTALL_WHEELS = env_bool(\"FORGERYSEG_INSTALL_WHEELS\", default=KAGGLE and OFFLINE)\n",
    "WHEELS_ROOT = find_wheels_root() if INSTALL_WHEELS else None\n",
    "if INSTALL_WHEELS:\n",
    "    if WHEELS_ROOT is None:\n",
    "        print(\"[wheels] nenhum wheel root encontrado (ok se já tiver as libs no ambiente).\")\n",
    "    else:\n",
    "        maybe_install_from_wheels(WHEELS_ROOT)\n",
    "\n",
    "# Checagem mínima de deps críticas (falha cedo, com mensagem clara)\n",
    "required_modules = [\"torch\", \"numpy\", \"cv2\", \"timm\", \"segmentation_models_pytorch\"]\n",
    "missing = _missing_modules(required_modules)\n",
    "if missing:\n",
    "    raise ImportError(\n",
    "        \"Dependências Python faltando: \"\n",
    "        + \", \".join(missing)\n",
    "        + \"\\n- No Kaggle offline: anexe um Dataset com wheels em `.../recodai_bundle/wheels/` e rode com \"\n",
    "        + \"`FORGERYSEG_INSTALL_WHEELS=1`.\"\n",
    "    )\n",
    "\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Dispositivo:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096bdbbf",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Paths (repo, dados, cache)\n",
    "\n",
    "REPO_ROOT = find_repo_root() or Path(\".\").resolve()\n",
    "if not (REPO_ROOT / \"src\" / \"forgeryseg\" / \"__init__.py\").exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"Não encontrei o código do repo (src/forgeryseg). \"\n",
    "        \"No Kaggle, anexe um Dataset com `recodai_bundle/` e/ou defina `FORGERYSEG_REPO_ROOT`.\"\n",
    "        f\"\\nTentativa: {REPO_ROOT}\"\n",
    "    )\n",
    "\n",
    "DATA_ROOT = find_data_root()\n",
    "if DATA_ROOT is None or not (DATA_ROOT / \"train_images\").exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"Dataset não encontrado. Anexe o dataset da competição e/ou defina `FORGERYSEG_DATA_ROOT`.\"\n",
    "        f\"\\nTentativa: {DATA_ROOT}\"\n",
    "    )\n",
    "\n",
    "# Onde escrever artefatos (sempre gravável no Kaggle)\n",
    "WORK_DIR = Path(\"/kaggle/working\") if KAGGLE else REPO_ROOT\n",
    "OUTPUTS_ROOT = (WORK_DIR / \"outputs\").resolve()\n",
    "OUTPUTS_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"REPO_ROOT:\", REPO_ROOT)\n",
    "print(\"DATA_ROOT:\", DATA_ROOT)\n",
    "print(\"OUTPUTS_ROOT:\", OUTPUTS_ROOT)\n",
    "\n",
    "# Cache offline (opcional). Ex.: /kaggle/input/<dataset>/weights_cache\n",
    "if str(REPO_ROOT / \"src\") not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT / \"src\"))\n",
    "\n",
    "from forgeryseg.offline import configure_cache_dirs\n",
    "\n",
    "CACHE_ROOT = find_cache_root()\n",
    "if CACHE_ROOT is not None:\n",
    "    configure_cache_dirs(CACHE_ROOT)\n",
    "    print(\"[CACHE] using\", CACHE_ROOT)\n",
    "\n",
    "if OFFLINE:\n",
    "    os.environ.setdefault(\"HF_HUB_OFFLINE\", \"1\")\n",
    "    os.environ.setdefault(\"TRANSFORMERS_OFFLINE\", \"1\")\n",
    "    print(\"[OFFLINE] downloads disabled (Kaggle submission-safe).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5e1d09",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Config de inferência (edite se quiser)\n",
    "\n",
    "INFER_CONFIG = REPO_ROOT / \"configs\" / \"infer_ensemble.json\"\n",
    "if not INFER_CONFIG.exists():\n",
    "    raise FileNotFoundError(f\"Config não encontrado: {INFER_CONFIG}\")\n",
    "\n",
    "# Se você não empacotou cache HF, é melhor remover modelos que dependem do HuggingFace no Kaggle offline.\n",
    "DISABLE_HF_MODELS = env_bool(\"FORGERYSEG_DISABLE_HF_MODELS\", default=True)\n",
    "\n",
    "infer_config_path = INFER_CONFIG\n",
    "if OFFLINE and DISABLE_HF_MODELS:\n",
    "    try:\n",
    "        with INFER_CONFIG.open(\"r\") as f:\n",
    "            infer_cfg = json.load(f)\n",
    "        models = infer_cfg.get(\"models\", [])\n",
    "        filtered = []\n",
    "        dropped = []\n",
    "        for m in models:\n",
    "            mid = str(m.get(\"model_id\", \"\"))\n",
    "            if \"dinov2\" in mid.lower():\n",
    "                dropped.append(mid)\n",
    "                continue\n",
    "            filtered.append(m)\n",
    "        if filtered and dropped:\n",
    "            total_w = sum(float(m.get(\"weight\", 1.0)) for m in filtered) or 1.0\n",
    "            for m in filtered:\n",
    "                m[\"weight\"] = float(m.get(\"weight\", 1.0)) / total_w\n",
    "            infer_cfg[\"models\"] = filtered\n",
    "            infer_config_path = write_config(INFER_CONFIG, OUTPUTS_ROOT / \"configs\" / \"infer_offline.json\", infer_cfg)\n",
    "            print(\"[INFER] OFFLINE: removendo modelos HF:\", \", \".join(dropped))\n",
    "    except Exception as exc:\n",
    "        print(\"[warn] não consegui filtrar modelos HF:\", exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a227be8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Gerar submission.csv\n",
    "\n",
    "submit_script = REPO_ROOT / \"scripts\" / \"submit_ensemble.py\"\n",
    "if not submit_script.exists():\n",
    "    raise FileNotFoundError(f\"Não encontrei {submit_script}.\")\n",
    "\n",
    "submission_path = Path(\"/kaggle/working/submission.csv\") if KAGGLE else (OUTPUTS_ROOT / \"submission.csv\")\n",
    "\n",
    "cmd = [\n",
    "    sys.executable,\n",
    "    str(submit_script),\n",
    "    \"--data-root\",\n",
    "    str(DATA_ROOT),\n",
    "    \"--out-csv\",\n",
    "    str(submission_path),\n",
    "    \"--config\",\n",
    "    str(infer_config_path),\n",
    "]\n",
    "\n",
    "run_cmd(cmd)\n",
    "print(\"submission.csv ->\", submission_path)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent",
   "notebook_metadata_filter": "language_info"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
