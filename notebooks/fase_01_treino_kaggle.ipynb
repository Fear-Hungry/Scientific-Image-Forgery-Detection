{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Recod.ai/LUC — Training (Kaggle, internet ON)\n",
        "\n",
        "Este notebook gera os **pesos (`*.pth`)** necessários para rodar a submissão offline:\n",
        "\n",
        "- Segmentação (DINOv2 + decoder) → `outputs/models/r69.pth`\n",
        "- (Opcional) Classificador FFT → `outputs/models/fft_cls.pth`\n",
        "\n",
        "Fluxo recomendado:\n",
        "\n",
        "1. Kaggle Notebook **com internet ON** + **GPU**.\n",
        "2. Anexe o dataset da competição.\n",
        "3. Anexe um dataset com **este repo** (ou clone).\n",
        "4. Rode as células para treinar e salvar os checkpoints em `/kaggle/working/outputs/models/`.\n",
        "5. Empacote um folder `kaggle_bundle/` para criar um Kaggle Dataset com código + pesos.\n",
        "\n",
        "Observação: por regra do repo, a lógica nasce aqui (`.py`) e é espelhada no `.ipynb`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import platform\n",
        "import shutil\n",
        "import subprocess\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "\n",
        "print(f\"python={sys.version.split()[0]} platform={platform.platform()}\")\n",
        "print(f\"torch={torch.__version__} cuda_available={torch.cuda.is_available()}\")\n",
        "\n",
        "\n",
        "def _find_code_root() -> Path:\n",
        "    cwd = Path.cwd()\n",
        "    for p in [cwd, *cwd.parents]:\n",
        "        if (p / \"src\" / \"forgeryseg\").exists():\n",
        "            return p\n",
        "\n",
        "    kaggle_input = Path(\"/kaggle/input\")\n",
        "    if kaggle_input.exists():\n",
        "        for d in kaggle_input.iterdir():\n",
        "            if not d.is_dir():\n",
        "                continue\n",
        "            if (d / \"src\" / \"forgeryseg\").exists():\n",
        "                return d\n",
        "            # common: dataset root contains a single folder with the repo inside\n",
        "            try:\n",
        "                for child in d.iterdir():\n",
        "                    if child.is_dir() and (child / \"src\" / \"forgeryseg\").exists():\n",
        "                        return child\n",
        "            except PermissionError:\n",
        "                continue\n",
        "\n",
        "    raise FileNotFoundError(\n",
        "        \"Não encontrei o código (src/forgeryseg). \"\n",
        "        \"No Kaggle: anexe um Dataset contendo este repo (com pastas src/ e configs/).\"\n",
        "    )\n",
        "\n",
        "\n",
        "CODE_ROOT = _find_code_root()\n",
        "SRC = CODE_ROOT / \"src\"\n",
        "CONFIG_ROOT = CODE_ROOT / \"configs\"\n",
        "print(f\"code_root={CODE_ROOT}\")\n",
        "\n",
        "if str(SRC) not in sys.path:\n",
        "    sys.path.insert(0, str(SRC))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# (Opcional) Instalar deps\n",
        "# -------------------------\n",
        "#\n",
        "# No Kaggle, normalmente já existe torch/torchvision. Se faltar timm/albumentations/etc,\n",
        "# use INSTALL_DEPS=True com internet ON.\n",
        "INSTALL_DEPS = False\n",
        "\n",
        "if INSTALL_DEPS:\n",
        "    req = CODE_ROOT / \"requirements-kaggle.txt\"\n",
        "    print(f\"Installing: {req}\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", str(req)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from forgeryseg.kaggle import package_kaggle_dataset\n",
        "from forgeryseg.submission import write_submission_csv\n",
        "from forgeryseg.training.dino_decoder import train_dino_decoder\n",
        "from forgeryseg.training.fft_classifier import train_fft_classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Config (edite aqui)\n",
        "# -------------------------\n",
        "\n",
        "DATA_ROOT: Path | None = None  # None => auto-detect (Kaggle -> local)\n",
        "\n",
        "SEG_CONFIGS = [\n",
        "    # Base + FFT gate + TTA forte (bom custo/benefício)\n",
        "    CONFIG_ROOT / \"dino_v3_518_r69_fft_gate_tta_plus.json\",\n",
        "    # Multi-escala (melhor para regiões pequenas + grandes)\n",
        "    CONFIG_ROOT / \"dino_v4_518_r69_multiscale_fft_gate_tta_plus.json\",\n",
        "    # Fusão espacial+frequência (diversidade)\n",
        "    CONFIG_ROOT / \"dino_v3_518_r69_freq_fusion_fft_gate_tta_plus.json\",\n",
        "]\n",
        "FFT_TRAIN_CONFIG = CONFIG_ROOT / \"fft_classifier_logmag_256.json\"\n",
        "\n",
        "TRAIN_SEG = True\n",
        "TRAIN_FFT = True\n",
        "\n",
        "USE_CONFIG_TRAIN_DEFAULTS = True  # True => usa train.* do config; False => usa overrides abaixo\n",
        "\n",
        "SEG_FOLDS = 5  # override quando USE_CONFIG_TRAIN_DEFAULTS=False\n",
        "FFT_FOLDS = 1  # use 1 para gerar fft_cls.pth diretamente; >1 cria fft_cls_fold{i}.pth\n",
        "\n",
        "SEG_EPOCHS = 10\n",
        "SEG_BATCH = 4\n",
        "SEG_LR = 1e-3\n",
        "SEG_WD = 1e-4\n",
        "SEG_NUM_WORKERS = 2\n",
        "SEG_AUG = \"robust\"  # none | basic | robust (inclui rot90 + JPEG artifacts)\n",
        "SEG_SCHEDULER = \"cosine\"  # none | cosine | onecycle\n",
        "SEG_PATIENCE = 3  # early stopping em val_of1 (0 desliga)\n",
        "\n",
        "# CutMix (opcional, treino de segmentação)\n",
        "SEG_CUTMIX_PROB: float | None = None  # None => usa o valor do config; ex.: 0.3–0.7\n",
        "SEG_CUTMIX_ALPHA: float | None = None\n",
        "\n",
        "FFT_EPOCHS = 5\n",
        "FFT_BATCH = 32\n",
        "FFT_LR = 1e-3\n",
        "FFT_WD = 1e-4\n",
        "FFT_NUM_WORKERS = 2\n",
        "FFT_SCHEDULER = \"cosine\"  # none | cosine | onecycle\n",
        "\n",
        "OUT_DIR = Path(\"/kaggle/working\") if Path(\"/kaggle/working\").exists() else Path(\"outputs\")\n",
        "OUT_MODELS = OUT_DIR / \"outputs\" / \"models\"\n",
        "\n",
        "FFT_OUT = OUT_MODELS / \"fft_cls.pth\"\n",
        "\n",
        "# (Opcional) checar score local rapidamente após treinar:\n",
        "EVAL_AFTER_TRAIN = True\n",
        "EVAL_SPLIT = \"train\"  # train | supplemental\n",
        "EVAL_LIMIT = 0  # 0 = sem limite (usa tudo)\n",
        "EVAL_CONFIGS = SEG_CONFIGS  # escreve CSV + score local para cada config\n",
        "\n",
        "# -------------------------\n",
        "# Sanity-check (evitar under/overfitting)\n",
        "# -------------------------\n",
        "#\n",
        "# Objetivo: detectar cedo problemas clássicos (máscara errada, pipeline desalinhado, LR absurda,\n",
        "# modelo \"não aprende\") antes de gastar muito tempo de GPU.\n",
        "RUN_SANITY = True\n",
        "SANITY_SPLIT = \"train\"  # train | supplemental\n",
        "SANITY_N_SAMPLES = 24  # total (mistura forged + authentic, estratificado)\n",
        "SANITY_VAL_FRACTION = 0.25\n",
        "SANITY_SEED = 42\n",
        "\n",
        "# Overfit test (mini-set): deve melhorar bastante em poucos passos\n",
        "SANITY_OVERFIT_TEST = True\n",
        "SANITY_TRAIN_STEPS = 80  # ~50–150 já costuma bastar para detectar bug\n",
        "SANITY_BATCH = 4\n",
        "SANITY_LR = 3e-3\n",
        "SANITY_WEIGHT_DECAY = 0.0\n",
        "SANITY_FREEZE_ENCODER = True  # deixe True para refletir o treino real; False overfita mais fácil (mais lento)\n",
        "\n",
        "# Postprocess \"relaxado\" só para medir tendência (não é tuning final!)\n",
        "SANITY_PROB_THRESHOLD = 0.30\n",
        "\n",
        "# (Opcional) tunar pós-processamento (rápido) num subset de validação.\n",
        "#\n",
        "# Meta: aumentar mean_forged (e reduzir forg_pred_as_auth) sem destruir mean_authentic.\n",
        "#\n",
        "# Observação: este sweep roda por padrão em um subset (val_fraction) para ser viável no Kaggle.\n",
        "TUNE_POSTPROCESS = True\n",
        "TUNE_METHOD = \"optuna\"  # \"optuna\" (melhor) | \"grid\" (fallback sem Optuna)\n",
        "REQUIRE_OPTUNA = True  # True => não faz fallback; falha se Optuna não estiver disponível\n",
        "TUNE_CONFIGS = SEG_CONFIGS  # roda tuner por config (gera tuned_*.json)\n",
        "TUNE_SPLIT = EVAL_SPLIT\n",
        "TUNE_VAL_FRACTION = 0.10\n",
        "TUNE_SEED = 42\n",
        "TUNE_LIMIT = 0  # 0 = usa todo o subset de validação\n",
        "TUNE_BATCH = 4  # ajuste conforme VRAM\n",
        "TUNE_USE_TTA = True  # mais fiel ao config (tende a dar melhor tuning, mas é mais lento)\n",
        "TUNE_THR_START = 0.20\n",
        "TUNE_THR_STOP = 0.60\n",
        "TUNE_THR_STEP = 0.05\n",
        "TUNE_WRITE_TUNED_CONFIG = True\n",
        "\n",
        "# Optuna (Bayesian Optimization)\n",
        "OPTUNA_TRIALS = 200\n",
        "OPTUNA_TIMEOUT_SEC = None  # ex.: 1800 (30 min)\n",
        "OPTUNA_OBJECTIVE = \"combo\"  # mean_score | mean_forged | combo\n",
        "\n",
        "# Empacotar um folder pronto para upload como Kaggle Dataset (offline):\n",
        "DO_PACKAGE = True\n",
        "PKG_OUT = OUT_DIR / \"kaggle_bundle\"\n",
        "\n",
        "# (preenchido durante tuning)\n",
        "tuned_config_paths: list[Path] = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def _find_recodai_root() -> Path:\n",
        "    if DATA_ROOT is not None:\n",
        "        return Path(DATA_ROOT)\n",
        "\n",
        "    kaggle_input = Path(\"/kaggle/input\")\n",
        "    if kaggle_input.exists():\n",
        "        for d in kaggle_input.iterdir():\n",
        "            if not d.is_dir():\n",
        "                continue\n",
        "            if (d / \"recodai\" / \"sample_submission.csv\").exists():\n",
        "                return d / \"recodai\"\n",
        "            if (d / \"sample_submission.csv\").exists() and (\n",
        "                (d / \"train_images\").exists() or (d / \"test_images\").exists()\n",
        "            ):\n",
        "                return d\n",
        "\n",
        "    local = Path(\"data/recodai\")\n",
        "    if local.exists():\n",
        "        return local\n",
        "    local2 = CODE_ROOT / \"data\" / \"recodai\"\n",
        "    if local2.exists():\n",
        "        return local2\n",
        "\n",
        "    raise FileNotFoundError(\n",
        "        \"Não encontrei o data root. Defina DATA_ROOT manualmente \"\n",
        "        \"(ex.: /kaggle/input/<dataset>/recodai ou data/recodai).\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Run\n",
        "# -------------------------\n",
        "\n",
        "data_root = _find_recodai_root()\n",
        "print(f\"data_root={data_root}\")\n",
        "\n",
        "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = torch.device(device_str)\n",
        "print(f\"device={device} (Dica: ative GPU em Settings -> Accelerator)\")\n",
        "\n",
        "OUT_MODELS.mkdir(parents=True, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Sanity-check (data + mini overfit)\n",
        "# -------------------------\n",
        "\n",
        "if RUN_SANITY:\n",
        "    import dataclasses\n",
        "\n",
        "    import numpy as np\n",
        "    from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "    from forgeryseg.config import load_segmentation_config\n",
        "    from forgeryseg.dataset import RecodaiDataset\n",
        "    from forgeryseg.losses import bce_dice_loss\n",
        "    from forgeryseg.postprocess import PostprocessParams\n",
        "    from forgeryseg.training.eval_of1 import evaluate_of1\n",
        "    from forgeryseg.training.trainer import _build_model\n",
        "    from forgeryseg.training.utils import seed_everything, stratified_splits\n",
        "    from forgeryseg.transforms import make_transforms\n",
        "\n",
        "    print(\"\\n[sanity] --- dataset quick stats ---\")\n",
        "    seed_everything(int(SANITY_SEED))\n",
        "\n",
        "    # Load a dataset with deterministic transforms (resize+pad only) for sanity checks.\n",
        "    cfg_sanity = load_segmentation_config(SEG_CONFIGS[0])\n",
        "    cfg_sanity.model.freeze_encoder = bool(SANITY_FREEZE_ENCODER)\n",
        "\n",
        "    tf_sanity = make_transforms(int(cfg_sanity.model.input_size), train=True, aug=\"none\")\n",
        "    ds = RecodaiDataset(\n",
        "        data_root,\n",
        "        SANITY_SPLIT,  # type: ignore[arg-type]\n",
        "        training=True,\n",
        "        include_authentic=True,\n",
        "        include_forged=True,\n",
        "        transforms=tf_sanity,\n",
        "        cache_images=True,\n",
        "        cache_masks=True,\n",
        "    )\n",
        "\n",
        "    n_total = len(ds)\n",
        "    n_forg = sum(1 for c in ds.cases if c.mask_path is not None)\n",
        "    n_auth = n_total - n_forg\n",
        "    print(f\"[sanity] split={SANITY_SPLIT} n={n_total} forged={n_forg} authentic={n_auth}\")\n",
        "    if n_total == 0 or n_forg == 0 or n_auth == 0:\n",
        "        raise RuntimeError(\"[sanity] split sem exemplos suficientes (precisa forged+authentic).\")\n",
        "\n",
        "    # Pick a small stratified subset.\n",
        "    idx_auth = [i for i, c in enumerate(ds.cases) if c.mask_path is None]\n",
        "    idx_forg = [i for i, c in enumerate(ds.cases) if c.mask_path is not None]\n",
        "    p_forg = len(idx_forg) / max(1, n_total)\n",
        "    n_forg_s = int(round(int(SANITY_N_SAMPLES) * p_forg))\n",
        "    n_forg_s = int(np.clip(n_forg_s, 1, len(idx_forg)))\n",
        "    n_auth_s = int(np.clip(int(SANITY_N_SAMPLES) - n_forg_s, 1, len(idx_auth)))\n",
        "\n",
        "    rng = np.random.default_rng(int(SANITY_SEED))\n",
        "    chosen = rng.choice(idx_auth, size=n_auth_s, replace=False).tolist() + rng.choice(idx_forg, size=n_forg_s, replace=False).tolist()\n",
        "    rng.shuffle(chosen)\n",
        "\n",
        "    labels = np.asarray([1 if ds.cases[i].mask_path is not None else 0 for i in chosen], dtype=np.int64)\n",
        "    splits = stratified_splits(labels, folds=1, val_fraction=float(SANITY_VAL_FRACTION), seed=int(SANITY_SEED))\n",
        "    _, tr_sub, va_sub = splits[0]\n",
        "    train_idx = [chosen[int(i)] for i in tr_sub.tolist()]\n",
        "    val_idx = [chosen[int(i)] for i in va_sub.tolist()]\n",
        "\n",
        "    def _sample_stats(ix: int) -> None:\n",
        "        s = ds[int(ix)]\n",
        "        x = s.image\n",
        "        y = s.mask\n",
        "        uniq = torch.unique(y).detach().cpu().numpy().tolist()\n",
        "        print(\n",
        "            f\"[sanity] sample case_id={s.case_id} x={tuple(x.shape)} x_minmax=({float(x.min()):.3f},{float(x.max()):.3f}) \"\n",
        "            f\"y_sum={float(y.sum()):.0f} y_unique={uniq}\"\n",
        "        )\n",
        "\n",
        "    print(\"[sanity] sample inspection:\")\n",
        "    for ix in train_idx[:2] + val_idx[:2]:\n",
        "        _sample_stats(ix)\n",
        "\n",
        "    # Build model and run a quick forward/backward to catch shape/device issues.\n",
        "    model = _build_model(cfg_sanity).to(device)\n",
        "    model.train()\n",
        "    loader = DataLoader(Subset(ds, train_idx), batch_size=int(max(1, SANITY_BATCH)), shuffle=True, num_workers=0)\n",
        "    batch0 = next(iter(loader))\n",
        "    x0 = batch0.image.to(device)\n",
        "    y0 = batch0.mask.to(device)\n",
        "    with torch.no_grad():\n",
        "        logits0 = model(x0)\n",
        "    print(f\"[sanity] forward ok: logits={tuple(logits0.shape)}\")\n",
        "\n",
        "    if SANITY_OVERFIT_TEST:\n",
        "        print(\"\\n[sanity] --- mini overfit test ---\")\n",
        "        post_relaxed = PostprocessParams(\n",
        "            prob_threshold=float(SANITY_PROB_THRESHOLD),\n",
        "            min_area=0,\n",
        "            min_mean_conf=0.0,\n",
        "            min_prob_std=0.0,\n",
        "        )\n",
        "\n",
        "        train_cases = [ds.cases[i] for i in train_idx]\n",
        "        val_cases = [ds.cases[i] for i in val_idx]\n",
        "\n",
        "        with torch.no_grad():\n",
        "            before_train = evaluate_of1(\n",
        "                model,\n",
        "                train_cases,\n",
        "                device=device,\n",
        "                input_size=int(cfg_sanity.model.input_size),\n",
        "                postprocess=post_relaxed,\n",
        "                use_tta=False,\n",
        "                progress=False,\n",
        "            )\n",
        "            before_val = evaluate_of1(\n",
        "                model,\n",
        "                val_cases,\n",
        "                device=device,\n",
        "                input_size=int(cfg_sanity.model.input_size),\n",
        "                postprocess=post_relaxed,\n",
        "                use_tta=False,\n",
        "                progress=False,\n",
        "            )\n",
        "\n",
        "        opt = torch.optim.AdamW(\n",
        "            model.parameters(),\n",
        "            lr=float(SANITY_LR),\n",
        "            weight_decay=float(SANITY_WEIGHT_DECAY),\n",
        "        )\n",
        "\n",
        "        losses = []\n",
        "        steps = int(max(1, SANITY_TRAIN_STEPS))\n",
        "        it = iter(loader)\n",
        "        for step in range(1, steps + 1):\n",
        "            try:\n",
        "                batch = next(it)\n",
        "            except StopIteration:\n",
        "                it = iter(loader)\n",
        "                batch = next(it)\n",
        "            x = batch.image.to(device)\n",
        "            y = batch.mask.to(device)\n",
        "            logits = model(x)\n",
        "            loss = bce_dice_loss(logits, y)\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            losses.append(float(loss.detach().cpu().item()))\n",
        "            if step % 20 == 0 or step == 1:\n",
        "                print(f\"[sanity] step={step}/{steps} loss={losses[-1]:.6f}\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            after_train = evaluate_of1(\n",
        "                model,\n",
        "                train_cases,\n",
        "                device=device,\n",
        "                input_size=int(cfg_sanity.model.input_size),\n",
        "                postprocess=post_relaxed,\n",
        "                use_tta=False,\n",
        "                progress=False,\n",
        "            )\n",
        "            after_val = evaluate_of1(\n",
        "                model,\n",
        "                val_cases,\n",
        "                device=device,\n",
        "                input_size=int(cfg_sanity.model.input_size),\n",
        "                postprocess=post_relaxed,\n",
        "                use_tta=False,\n",
        "                progress=False,\n",
        "            )\n",
        "\n",
        "        def _loss_mean(xs: list[float], n: int) -> float:\n",
        "            if not xs:\n",
        "                return 0.0\n",
        "            n = int(min(len(xs), max(1, n)))\n",
        "            return float(np.mean(xs[:n]))\n",
        "\n",
        "        l0 = _loss_mean(losses, 5)\n",
        "        l1 = float(np.mean(losses[-5:])) if len(losses) >= 5 else float(np.mean(losses))\n",
        "        print(\n",
        "            \"\\n[sanity] results (relaxed postprocess):\\n\"\n",
        "            f\"  loss: first5={l0:.4f} last5={l1:.4f}\\n\"\n",
        "            f\"  train oF1: before={before_train.mean_of1:.4f} after={after_train.mean_of1:.4f}\\n\"\n",
        "            f\"  val   oF1: before={before_val.mean_of1:.4f} after={after_val.mean_of1:.4f}\\n\"\n",
        "        )\n",
        "\n",
        "        # Heurísticas simples para guiar decisão (não bloqueia o notebook).\n",
        "        if after_train.mean_of1 < 0.20 and l1 >= (0.95 * l0):\n",
        "            print(\n",
        "                \"[sanity][warn] Parece UNDERFIT/bug: não melhorou no mini-set.\\n\"\n",
        "                \"- cheque masks (0/1), alinhamento img↔mask, normalização, LR.\\n\"\n",
        "                \"- tente SANITY_FREEZE_ENCODER=False ou aumente SANITY_TRAIN_STEPS.\\n\"\n",
        "            )\n",
        "        elif after_train.mean_of1 > 0.70 and after_val.mean_of1 < 0.20:\n",
        "            print(\n",
        "                \"[sanity][warn] Parece OVERFIT forte no mini-set.\\n\"\n",
        "                \"- aumente aug (SEG_AUG=robust), use CutMix (train.cutmix_prob>0), weight_decay.\\n\"\n",
        "                \"- use k-fold e early stopping por val_of1.\\n\"\n",
        "            )\n",
        "        else:\n",
        "            print(\"[sanity] OK: pipeline parece aprender (seguindo para treino completo).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -----\n",
        "# Train (Segmentation)\n",
        "# -----\n",
        "\n",
        "seg_results: dict[str, object] = {}\n",
        "if TRAIN_SEG:\n",
        "    for cfg_path in SEG_CONFIGS:\n",
        "        cfg_path = Path(cfg_path)\n",
        "        cfg_json = json.loads(cfg_path.read_text(encoding=\"utf-8\"))\n",
        "        name = str(cfg_json.get(\"name\", cfg_path.stem))\n",
        "        ckpt_rel = str(cfg_json.get(\"model\", {}).get(\"checkpoint\", \"outputs/models/model.pth\"))\n",
        "        out_path = OUT_DIR / ckpt_rel\n",
        "\n",
        "        seg_overrides: list[str] = []\n",
        "        if not bool(USE_CONFIG_TRAIN_DEFAULTS):\n",
        "            seg_overrides.extend(\n",
        "                [\n",
        "                    f\"train.epochs={int(SEG_EPOCHS)}\",\n",
        "                    f\"train.batch_size={int(SEG_BATCH)}\",\n",
        "                    f\"train.lr={float(SEG_LR)}\",\n",
        "                    f\"train.weight_decay={float(SEG_WD)}\",\n",
        "                    f\"train.num_workers={int(SEG_NUM_WORKERS)}\",\n",
        "                    f\"train.folds={int(SEG_FOLDS)}\",\n",
        "                    f\"train.aug={json.dumps(str(SEG_AUG))}\",\n",
        "                    f\"train.scheduler={json.dumps(str(SEG_SCHEDULER))}\",\n",
        "                    f\"train.patience={int(SEG_PATIENCE)}\",\n",
        "                ]\n",
        "            )\n",
        "\n",
        "        # Overrides opcionais (aplicados apenas se definidos no notebook)\n",
        "        if SEG_CUTMIX_PROB is not None:\n",
        "            seg_overrides.append(f\"train.cutmix_prob={float(SEG_CUTMIX_PROB)}\")\n",
        "        if SEG_CUTMIX_ALPHA is not None:\n",
        "            seg_overrides.append(f\"train.cutmix_alpha={float(SEG_CUTMIX_ALPHA)}\")\n",
        "\n",
        "        print(f\"\\n[train:seg] config={cfg_path.name} name={name} out={out_path}\")\n",
        "        seg_result = train_dino_decoder(\n",
        "            config_path=cfg_path,\n",
        "            data_root=data_root,\n",
        "            out_path=out_path,\n",
        "            device=device_str,\n",
        "            split=\"train\",\n",
        "            overrides=seg_overrides if seg_overrides else None,\n",
        "            epochs=None,\n",
        "            batch_size=None,\n",
        "            lr=None,\n",
        "            weight_decay=None,\n",
        "            num_workers=None,\n",
        "            folds=None,\n",
        "            fold=None,\n",
        "            aug=None,\n",
        "            scheduler=None,\n",
        "            patience=None,\n",
        "        )\n",
        "        seg_results[name] = seg_result\n",
        "\n",
        "        # Se treinou k-fold, copia o melhor fold para o path \"base\" (ex.: r69.pth),\n",
        "        # para facilitar o uso em configs que apontam para outputs/models/*.pth.\n",
        "        if getattr(seg_result, \"fold_results\", None) is not None and len(seg_result.fold_results) > 1:\n",
        "            best = max(seg_result.fold_results, key=lambda fr: fr.best_val_of1)\n",
        "            if Path(best.checkpoint_path) != Path(out_path):\n",
        "                Path(out_path).parent.mkdir(parents=True, exist_ok=True)\n",
        "                shutil.copy2(best.checkpoint_path, out_path)\n",
        "                print(f\"[train:seg] Copied best fold -> {out_path} (from {best.checkpoint_path})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -----\n",
        "# Train (FFT classifier)\n",
        "# -----\n",
        "\n",
        "fft_saved = None\n",
        "if TRAIN_FFT:\n",
        "    fft_saved = train_fft_classifier(\n",
        "        config_path=FFT_TRAIN_CONFIG,\n",
        "        data_root=data_root,\n",
        "        out_path=FFT_OUT,\n",
        "        device=device,\n",
        "        epochs=int(FFT_EPOCHS),\n",
        "        batch_size=int(FFT_BATCH),\n",
        "        lr=float(FFT_LR),\n",
        "        weight_decay=float(FFT_WD),\n",
        "        num_workers=int(FFT_NUM_WORKERS),\n",
        "        folds=int(FFT_FOLDS),\n",
        "        scheduler=FFT_SCHEDULER,  # type: ignore[arg-type]\n",
        "    )\n",
        "\n",
        "    if fft_saved and int(FFT_FOLDS) > 1:\n",
        "        # escolhe melhor fold por menor val_loss no checkpoint\n",
        "        best_path = min(\n",
        "            fft_saved,\n",
        "            key=lambda p: float(torch.load(p, map_location=\"cpu\").get(\"val_loss\", float(\"inf\"))),\n",
        "        )\n",
        "        if best_path != FFT_OUT:\n",
        "            FFT_OUT.parent.mkdir(parents=True, exist_ok=True)\n",
        "            shutil.copy2(best_path, FFT_OUT)\n",
        "            print(f\"Copied best FFT fold -> {FFT_OUT} (from {best_path})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Quick evaluation (local)\n",
        "# -------------------------\n",
        "#\n",
        "# Gera um submission no split train/supplemental e calcula oF1 local.\n",
        "\n",
        "if EVAL_AFTER_TRAIN:\n",
        "    from forgeryseg.eval import score_submission_csv, validate_submission_format\n",
        "\n",
        "    for eval_cfg in EVAL_CONFIGS:\n",
        "        eval_cfg = Path(eval_cfg)\n",
        "        cfg = json.loads(eval_cfg.read_text(encoding=\"utf-8\"))\n",
        "        name = str(cfg.get(\"name\", eval_cfg.stem))\n",
        "        eval_csv = OUT_DIR / f\"submission_{name}_{EVAL_SPLIT}.csv\"\n",
        "\n",
        "        stats = write_submission_csv(\n",
        "            config_path=eval_cfg,\n",
        "            data_root=data_root,\n",
        "            split=EVAL_SPLIT,  # type: ignore[arg-type]\n",
        "            out_path=eval_csv,\n",
        "            device=device,\n",
        "            limit=int(EVAL_LIMIT),\n",
        "            path_roots=[OUT_DIR, CODE_ROOT, CONFIG_ROOT],\n",
        "            amp=True,\n",
        "        )\n",
        "        print(stats)\n",
        "\n",
        "        fmt = validate_submission_format(eval_csv, data_root=data_root, split=EVAL_SPLIT)  # type: ignore[arg-type]\n",
        "        print(\"\\n[Format check]\")\n",
        "        print(json.dumps(fmt, indent=2, ensure_ascii=False))\n",
        "\n",
        "        score = score_submission_csv(eval_csv, data_root=data_root, split=EVAL_SPLIT)  # type: ignore[arg-type]\n",
        "        print(\"\\n[Local score]\")\n",
        "        print(json.dumps(score.as_dict(csv_path=eval_csv, split=EVAL_SPLIT), indent=2, ensure_ascii=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Postprocess tuning (threshold / optuna)\n",
        "# -------------------------\n",
        "#\n",
        "# Faz tuning do pós-processamento em um subset de validação estratificado (authentic vs forged):\n",
        "# - método \"optuna\": otimização bayesiana (melhor, tunando vários parâmetros)\n",
        "# - método \"grid\": sweep simples só em `prob_threshold` (fallback)\n",
        "\n",
        "if TUNE_POSTPROCESS:\n",
        "    import dataclasses\n",
        "    import math\n",
        "    import time\n",
        "\n",
        "    import numpy as np\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    from forgeryseg.config import apply_overrides, load_config_data\n",
        "    from forgeryseg.dataset import list_cases, load_mask_instances\n",
        "    from forgeryseg.eval import ScoreSummary\n",
        "    from forgeryseg.inference import load_rgb\n",
        "    from forgeryseg.inference_engine import InferenceEngine\n",
        "    from forgeryseg.metric import of1_score\n",
        "    from forgeryseg.postprocess import PostprocessParams, postprocess_prob\n",
        "    from forgeryseg.training.utils import stratified_splits\n",
        "\n",
        "    tuned_config_paths.clear()\n",
        "\n",
        "    def _frange(start: float, stop: float, step: float) -> list[float]:\n",
        "        if step <= 0:\n",
        "            raise ValueError(\"step must be > 0\")\n",
        "        out: list[float] = []\n",
        "        x = float(start)\n",
        "        while x <= float(stop) + 1e-12:\n",
        "            out.append(float(x))\n",
        "            x += float(step)\n",
        "        return out\n",
        "\n",
        "    def _select_stratified_subset(cases: list, *, seed: int, limit: int) -> list:\n",
        "        if limit <= 0 or len(cases) <= limit:\n",
        "            return cases\n",
        "        rng = np.random.default_rng(int(seed))\n",
        "        idx_auth = [i for i, c in enumerate(cases) if c.mask_path is None]\n",
        "        idx_forg = [i for i, c in enumerate(cases) if c.mask_path is not None]\n",
        "        p_forg = len(idx_forg) / max(1, len(cases))\n",
        "        n_forg = int(round(limit * p_forg))\n",
        "        n_forg = min(n_forg, len(idx_forg))\n",
        "        n_auth = int(limit - n_forg)\n",
        "        n_auth = min(n_auth, len(idx_auth))\n",
        "        chosen = []\n",
        "        if n_auth > 0:\n",
        "            chosen.extend(rng.choice(idx_auth, size=n_auth, replace=False).tolist())\n",
        "        if n_forg > 0:\n",
        "            chosen.extend(rng.choice(idx_forg, size=n_forg, replace=False).tolist())\n",
        "        rng.shuffle(chosen)\n",
        "        return [cases[i] for i in chosen]\n",
        "\n",
        "    # Overrides sugeridos (relaxar filtros agressivos)\n",
        "    base_overrides = [\n",
        "        \"inference.fft_gate.enabled=false\",\n",
        "        \"inference.postprocess.min_prob_std=0.0\",\n",
        "        \"inference.postprocess.small_area=null\",\n",
        "        \"inference.postprocess.small_min_mean_conf=null\",\n",
        "        \"inference.postprocess.authentic_area_max=null\",\n",
        "        \"inference.postprocess.authentic_conf_max=null\",\n",
        "        \"inference.postprocess.min_area=32\",\n",
        "        \"inference.postprocess.open_kernel=0\",\n",
        "        \"inference.postprocess.close_kernel=0\",\n",
        "        \"inference.postprocess.gaussian_sigma=0.0\",\n",
        "        \"inference.postprocess.sobel_weight=0.0\",\n",
        "    ]\n",
        "\n",
        "    tune_method = str(TUNE_METHOD).lower()\n",
        "\n",
        "    if tune_method == \"optuna\":\n",
        "        try:\n",
        "            from forgeryseg.tuning import tune_postprocess_optuna\n",
        "\n",
        "            optuna_out = OUT_DIR / \"optuna\"\n",
        "            for cfg_path in TUNE_CONFIGS:\n",
        "                cfg_path = Path(cfg_path)\n",
        "                if not cfg_path.exists():\n",
        "                    print(f\"[warn] Config não encontrado: {cfg_path} (pulando tuning)\")\n",
        "                    continue\n",
        "\n",
        "                print(f\"\\n[tune:optuna] config={cfg_path.name} objective={OPTUNA_OBJECTIVE}\")\n",
        "                res = tune_postprocess_optuna(\n",
        "                    config_path=cfg_path,\n",
        "                    data_root=data_root,\n",
        "                    split=TUNE_SPLIT,  # type: ignore[arg-type]\n",
        "                    out_dir=optuna_out,\n",
        "                    device=device,\n",
        "                    base_overrides=base_overrides,\n",
        "                    val_fraction=float(TUNE_VAL_FRACTION),\n",
        "                    seed=int(TUNE_SEED),\n",
        "                    limit=int(TUNE_LIMIT),\n",
        "                    use_tta=bool(TUNE_USE_TTA),\n",
        "                    batch_size=int(TUNE_BATCH),\n",
        "                    n_trials=int(OPTUNA_TRIALS),\n",
        "                    timeout_sec=OPTUNA_TIMEOUT_SEC,\n",
        "                    objective=OPTUNA_OBJECTIVE,  # type: ignore[arg-type]\n",
        "                )\n",
        "                tuned_config_paths.append(res.tuned_config_path)\n",
        "                print(json.dumps(res.as_dict(), indent=2, ensure_ascii=False))\n",
        "        except ImportError as e:\n",
        "            msg = f\"Optuna não disponível ({type(e).__name__}: {e})\"\n",
        "            if REQUIRE_OPTUNA:\n",
        "                raise RuntimeError(\n",
        "                    msg\n",
        "                    + \".\\n\"\n",
        "                    + \"No Kaggle (internet ON): ative `INSTALL_DEPS=True` ou rode `pip install -r requirements-kaggle.txt`.\"\n",
        "                ) from e\n",
        "            print(f\"[warn] {msg}. Caindo para grid sweep.\")\n",
        "            tune_method = \"grid\"\n",
        "\n",
        "    if tune_method == \"grid\":\n",
        "        thresholds = _frange(float(TUNE_THR_START), float(TUNE_THR_STOP), float(TUNE_THR_STEP))\n",
        "        if not thresholds:\n",
        "            raise RuntimeError(\"No thresholds configured\")\n",
        "\n",
        "        print(f\"[tune:grid] configs={len(TUNE_CONFIGS)} thresholds={len(thresholds)} objective=mean_score\")\n",
        "\n",
        "        for cfg_path in TUNE_CONFIGS:\n",
        "            cfg_path = Path(cfg_path)\n",
        "            if not cfg_path.exists():\n",
        "                print(f\"[warn] Config não encontrado: {cfg_path} (pulando tuning)\")\n",
        "                continue\n",
        "\n",
        "            print(\n",
        "                f\"\\n[tune:grid] config={cfg_path.name} split={TUNE_SPLIT} val_fraction={TUNE_VAL_FRACTION} \"\n",
        "                f\"n_thresholds={len(thresholds)} use_tta={TUNE_USE_TTA} batch={TUNE_BATCH}\"\n",
        "            )\n",
        "\n",
        "            # Load engine once (model + input_size). Postprocess will be replaced per-threshold.\n",
        "            engine = InferenceEngine.from_config(\n",
        "                config_path=cfg_path,\n",
        "                device=device,\n",
        "                overrides=base_overrides,\n",
        "                path_roots=[OUT_DIR, CODE_ROOT, CONFIG_ROOT],\n",
        "                amp=True,\n",
        "            )\n",
        "\n",
        "            # Define validation subset (stratified).\n",
        "            all_cases = list_cases(data_root, TUNE_SPLIT, include_authentic=True, include_forged=True)\n",
        "            labels = np.asarray([1 if c.mask_path is not None else 0 for c in all_cases], dtype=np.int64)\n",
        "            split_iter = stratified_splits(\n",
        "                labels,\n",
        "                folds=1,\n",
        "                val_fraction=float(TUNE_VAL_FRACTION),\n",
        "                seed=int(TUNE_SEED),\n",
        "            )\n",
        "            _, _, val_idx = next(iter(split_iter))\n",
        "            val_cases = [all_cases[int(i)] for i in val_idx.tolist()]\n",
        "            val_cases = _select_stratified_subset(val_cases, seed=int(TUNE_SEED), limit=int(TUNE_LIMIT))\n",
        "            n_auth = sum(1 for c in val_cases if c.mask_path is None)\n",
        "            n_forg = sum(1 for c in val_cases if c.mask_path is not None)\n",
        "            print(f\"[tune:grid] val_cases={len(val_cases)} authentic={n_auth} forged={n_forg}\")\n",
        "\n",
        "            # Fixed postprocess (with overrides applied), except prob_threshold.\n",
        "            base_post: PostprocessParams = engine.postprocess\n",
        "\n",
        "            # Accumulators per threshold\n",
        "            acc: dict[float, dict[str, float | int]] = {\n",
        "                thr: {\n",
        "                    \"sum_all\": 0.0,\n",
        "                    \"sum_auth\": 0.0,\n",
        "                    \"sum_forg\": 0.0,\n",
        "                    \"n_all\": 0,\n",
        "                    \"n_auth\": 0,\n",
        "                    \"n_forg\": 0,\n",
        "                    \"auth_pred_as_forged\": 0,\n",
        "                    \"forg_pred_as_auth\": 0,\n",
        "                }\n",
        "                for thr in thresholds\n",
        "            }\n",
        "\n",
        "            def _predict_prob_maps_no_tta(images: list[np.ndarray]) -> list[np.ndarray]:\n",
        "                from forgeryseg.image import letterbox_reflect, unletterbox\n",
        "\n",
        "                padded = []\n",
        "                metas = []\n",
        "                for img in images:\n",
        "                    pad, meta = letterbox_reflect(img, int(engine.input_size))\n",
        "                    padded.append(pad)\n",
        "                    metas.append(meta)\n",
        "\n",
        "                x = torch.stack(\n",
        "                    [torch.from_numpy(im).permute(2, 0, 1).contiguous().float() / 255.0 for im in padded],\n",
        "                    dim=0,\n",
        "                ).to(engine.device)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    if engine.amp and engine.device.type == \"cuda\":\n",
        "                        with torch.autocast(device_type=\"cuda\", dtype=torch.float16):\n",
        "                            logits = engine.model(x)\n",
        "                    else:\n",
        "                        logits = engine.model(x)\n",
        "                    prob = torch.sigmoid(logits)[:, 0].float()\n",
        "\n",
        "                prob_np = prob.detach().cpu().numpy().astype(np.float32)\n",
        "                return [unletterbox(prob_np[i], metas[i]).astype(np.float32) for i in range(len(metas))]\n",
        "\n",
        "            t0 = time.time()\n",
        "            bs = int(max(1, TUNE_BATCH))\n",
        "            for i in tqdm(range(0, len(val_cases), bs), desc=\"[tune:grid] infer\"):\n",
        "                batch_cases = val_cases[i : i + bs]\n",
        "                images = [load_rgb(c.image_path) for c in batch_cases]\n",
        "\n",
        "                if bool(TUNE_USE_TTA):\n",
        "                    probs = engine._predict_prob_maps_batched(images)\n",
        "                else:\n",
        "                    probs = _predict_prob_maps_no_tta(images)\n",
        "\n",
        "                for case, prob in zip(batch_cases, probs, strict=True):\n",
        "                    gt_instances = [] if case.mask_path is None else load_mask_instances(case.mask_path)\n",
        "                    gt_is_auth = case.mask_path is None\n",
        "\n",
        "                    for thr in thresholds:\n",
        "                        post = dataclasses.replace(base_post, prob_threshold=float(thr))\n",
        "                        pred_instances = postprocess_prob(prob, post)\n",
        "                        pred_is_auth = len(pred_instances) == 0\n",
        "\n",
        "                        if gt_is_auth:\n",
        "                            s = 1.0 if pred_is_auth else 0.0\n",
        "                            if not pred_is_auth:\n",
        "                                acc[thr][\"auth_pred_as_forged\"] = int(acc[thr][\"auth_pred_as_forged\"]) + 1\n",
        "                            acc[thr][\"sum_auth\"] = float(acc[thr][\"sum_auth\"]) + float(s)\n",
        "                            acc[thr][\"n_auth\"] = int(acc[thr][\"n_auth\"]) + 1\n",
        "                        else:\n",
        "                            if pred_is_auth:\n",
        "                                acc[thr][\"forg_pred_as_auth\"] = int(acc[thr][\"forg_pred_as_auth\"]) + 1\n",
        "                                s = 0.0\n",
        "                            else:\n",
        "                                s = float(of1_score(pred_instances, gt_instances))\n",
        "                            acc[thr][\"sum_forg\"] = float(acc[thr][\"sum_forg\"]) + float(s)\n",
        "                            acc[thr][\"n_forg\"] = int(acc[thr][\"n_forg\"]) + 1\n",
        "\n",
        "                        acc[thr][\"sum_all\"] = float(acc[thr][\"sum_all\"]) + float(s)\n",
        "                        acc[thr][\"n_all\"] = int(acc[thr][\"n_all\"]) + 1\n",
        "\n",
        "            dt = time.time() - t0\n",
        "            print(f\"[tune:grid] done in {dt:.1f}s\")\n",
        "\n",
        "            best_thr = None\n",
        "            best_score = -math.inf\n",
        "            results: list[tuple[float, ScoreSummary]] = []\n",
        "            for thr in thresholds:\n",
        "                a = acc[thr]\n",
        "                n_all = int(a[\"n_all\"])\n",
        "                n_auth = int(a[\"n_auth\"])\n",
        "                n_forg = int(a[\"n_forg\"])\n",
        "                mean_all = float(a[\"sum_all\"]) / max(1, n_all)\n",
        "                mean_auth = float(a[\"sum_auth\"]) / max(1, n_auth)\n",
        "                mean_forg = float(a[\"sum_forg\"]) / max(1, n_forg)\n",
        "                summary = ScoreSummary(\n",
        "                    mean_score=mean_all,\n",
        "                    mean_authentic=mean_auth,\n",
        "                    mean_forged=mean_forg,\n",
        "                    n_cases=n_all,\n",
        "                    n_authentic=n_auth,\n",
        "                    n_forged=n_forg,\n",
        "                    auth_pred_as_forged=int(a[\"auth_pred_as_forged\"]),\n",
        "                    forg_pred_as_auth=int(a[\"forg_pred_as_auth\"]),\n",
        "                    decode_errors_scoring=0,\n",
        "                )\n",
        "                results.append((thr, summary))\n",
        "                if mean_all > best_score:\n",
        "                    best_score = mean_all\n",
        "                    best_thr = thr\n",
        "\n",
        "            assert best_thr is not None\n",
        "            results.sort(key=lambda x: x[0])\n",
        "            print(\"\\n[tune:grid] Results (val subset):\")\n",
        "            for thr, s in results:\n",
        "                print(\n",
        "                    f\"thr={thr:.2f} mean={s.mean_score:.4f} mean_forged={s.mean_forged:.4f} \"\n",
        "                    f\"auth_pred_as_forged={s.auth_pred_as_forged} forg_pred_as_auth={s.forg_pred_as_auth}\"\n",
        "                )\n",
        "\n",
        "            best_summary = dict(results)[best_thr]\n",
        "            best_overrides = list(base_overrides) + [f\"inference.postprocess.prob_threshold={best_thr}\"]\n",
        "            print(\n",
        "                f\"\\n[tune:grid] BEST thr={best_thr:.2f} mean={best_summary.mean_score:.4f} \"\n",
        "                f\"mean_forged={best_summary.mean_forged:.4f}\"\n",
        "            )\n",
        "            print(\"[tune:grid] Suggested overrides:\")\n",
        "            print(json.dumps(best_overrides, indent=2, ensure_ascii=False))\n",
        "\n",
        "            tuned_path = OUT_DIR / f\"tuned_postprocess_{cfg_path.stem}.json\"\n",
        "            tuned_path.write_text(\n",
        "                json.dumps(\n",
        "                    {\n",
        "                        \"config\": str(cfg_path),\n",
        "                        \"split\": str(TUNE_SPLIT),\n",
        "                        \"val_fraction\": float(TUNE_VAL_FRACTION),\n",
        "                        \"seed\": int(TUNE_SEED),\n",
        "                        \"limit\": int(TUNE_LIMIT),\n",
        "                        \"best_threshold\": float(best_thr),\n",
        "                        \"best_summary\": best_summary.as_dict(),\n",
        "                        \"overrides\": best_overrides,\n",
        "                    },\n",
        "                    indent=2,\n",
        "                    ensure_ascii=False,\n",
        "                )\n",
        "                + \"\\n\",\n",
        "                encoding=\"utf-8\",\n",
        "            )\n",
        "            print(f\"[tune:grid] Wrote {tuned_path}\")\n",
        "\n",
        "            if TUNE_WRITE_TUNED_CONFIG:\n",
        "\n",
        "                def _slug_float(x: float) -> str:\n",
        "                    s = f\"{float(x):.4f}\".rstrip(\"0\").rstrip(\".\")\n",
        "                    return s.replace(\".\", \"p\")\n",
        "\n",
        "                tuned_cfg = load_config_data(cfg_path)\n",
        "                tuned_cfg = apply_overrides(tuned_cfg, best_overrides)\n",
        "                tuned_config_path = OUT_DIR / f\"tuned_{cfg_path.stem}_thr{_slug_float(best_thr)}.json\"\n",
        "                tuned_config_path.write_text(\n",
        "                    json.dumps(tuned_cfg, indent=2, ensure_ascii=False) + \"\\n\", encoding=\"utf-8\"\n",
        "                )\n",
        "                tuned_config_paths.append(tuned_config_path)\n",
        "                print(f\"[tune:grid] Wrote {tuned_config_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Package Kaggle Dataset folder\n",
        "# -------------------------\n",
        "#\n",
        "# Cria um folder pronto para upload como Kaggle Dataset:\n",
        "# - código (src/scripts/configs/notebooks/docs)\n",
        "# - + `outputs/models/*.pth` (opcional)\n",
        "#\n",
        "# Depois, anexe esse dataset no notebook de submissão (internet OFF).\n",
        "\n",
        "if DO_PACKAGE:\n",
        "    out_root = package_kaggle_dataset(\n",
        "        out_dir=PKG_OUT,\n",
        "        include_models=True,\n",
        "        models_dir=OUT_MODELS,\n",
        "        repo_root=CODE_ROOT,\n",
        "    )\n",
        "    print(f\"Wrote Kaggle bundle at: {out_root.resolve()}\")\n",
        "\n",
        "    if tuned_config_paths:\n",
        "        copied = 0\n",
        "        for p in tuned_config_paths:\n",
        "            p = Path(p)\n",
        "            if not p.exists():\n",
        "                continue\n",
        "            dst = out_root / \"configs\" / p.name\n",
        "            dst.parent.mkdir(parents=True, exist_ok=True)\n",
        "            shutil.copy2(p, dst)\n",
        "            copied += 1\n",
        "            print(f\"Copied tuned config into bundle: {dst}\")\n",
        "        print(f\"Copied tuned configs: {copied}/{len(tuned_config_paths)}\")\n",
        "\n",
        "    print(\"Crie um Kaggle Dataset a partir desse folder e anexe no notebook de submissão offline.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
