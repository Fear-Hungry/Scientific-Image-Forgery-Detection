{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Recod.ai/LUC — Training (Kaggle, internet ON)\n",
        "\n",
        "Este notebook gera os **pesos (`*.pth`)** necessários para rodar a submissão offline:\n",
        "\n",
        "- Segmentação (DINOv2 + decoder) → `outputs/models/r69.pth`\n",
        "- (Opcional) Classificador FFT → `outputs/models/fft_cls.pth`\n",
        "\n",
        "Fluxo recomendado:\n",
        "\n",
        "1. Kaggle Notebook **com internet ON** + **GPU**.\n",
        "2. Anexe o dataset da competição.\n",
        "3. Anexe um dataset com **este repo** (ou clone).\n",
        "4. Rode as células para treinar e salvar os checkpoints em `/kaggle/working/outputs/models/`.\n",
        "5. Empacote um folder `kaggle_bundle/` para criar um Kaggle Dataset com código + pesos.\n",
        "\n",
        "Observação: por regra do repo, a lógica nasce aqui (`.py`) e é espelhada no `.ipynb`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import platform\n",
        "import shutil\n",
        "import subprocess\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "\n",
        "print(f\"python={sys.version.split()[0]} platform={platform.platform()}\")\n",
        "print(f\"torch={torch.__version__} cuda_available={torch.cuda.is_available()}\")\n",
        "\n",
        "\n",
        "def _find_code_root() -> Path:\n",
        "    cwd = Path.cwd()\n",
        "    for p in [cwd, *cwd.parents]:\n",
        "        if (p / \"src\" / \"forgeryseg\").exists():\n",
        "            return p\n",
        "\n",
        "    kaggle_input = Path(\"/kaggle/input\")\n",
        "    if kaggle_input.exists():\n",
        "        for d in kaggle_input.iterdir():\n",
        "            if not d.is_dir():\n",
        "                continue\n",
        "            if (d / \"src\" / \"forgeryseg\").exists():\n",
        "                return d\n",
        "            # common: dataset root contains a single folder with the repo inside\n",
        "            try:\n",
        "                for child in d.iterdir():\n",
        "                    if child.is_dir() and (child / \"src\" / \"forgeryseg\").exists():\n",
        "                        return child\n",
        "            except PermissionError:\n",
        "                continue\n",
        "\n",
        "    raise FileNotFoundError(\n",
        "        \"Não encontrei o código (src/forgeryseg). \"\n",
        "        \"No Kaggle: anexe um Dataset contendo este repo (com pastas src/ e configs/).\"\n",
        "    )\n",
        "\n",
        "\n",
        "CODE_ROOT = _find_code_root()\n",
        "SRC = CODE_ROOT / \"src\"\n",
        "CONFIG_ROOT = CODE_ROOT / \"configs\"\n",
        "print(f\"code_root={CODE_ROOT}\")\n",
        "\n",
        "if str(SRC) not in sys.path:\n",
        "    sys.path.insert(0, str(SRC))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# (Opcional) Instalar deps\n",
        "# -------------------------\n",
        "#\n",
        "# No Kaggle, normalmente já existe torch/torchvision. Se faltar timm/albumentations/etc,\n",
        "# use INSTALL_DEPS=True com internet ON.\n",
        "INSTALL_DEPS = False\n",
        "\n",
        "if INSTALL_DEPS:\n",
        "    req = CODE_ROOT / \"requirements-kaggle.txt\"\n",
        "    print(f\"Installing: {req}\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", str(req)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from forgeryseg.kaggle import package_kaggle_dataset\n",
        "from forgeryseg.submission import write_submission_csv\n",
        "from forgeryseg.training.dino_decoder import train_dino_decoder\n",
        "from forgeryseg.training.fft_classifier import train_fft_classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Config (edite aqui)\n",
        "# -------------------------\n",
        "\n",
        "DATA_ROOT: Path | None = None  # None => auto-detect (Kaggle -> local)\n",
        "\n",
        "SEG_TRAIN_CONFIG = CONFIG_ROOT / \"dino_v3_518_r69.json\"\n",
        "FFT_TRAIN_CONFIG = CONFIG_ROOT / \"fft_classifier_logmag_256.json\"\n",
        "\n",
        "TRAIN_SEG = True\n",
        "TRAIN_FFT = True\n",
        "\n",
        "SEG_FOLDS = 1  # use 1 para gerar r69.pth diretamente; >1 cria r69_fold{i}.pth\n",
        "FFT_FOLDS = 1  # use 1 para gerar fft_cls.pth diretamente; >1 cria fft_cls_fold{i}.pth\n",
        "\n",
        "SEG_EPOCHS = 5\n",
        "SEG_BATCH = 4\n",
        "SEG_LR = 1e-3\n",
        "SEG_WD = 1e-4\n",
        "SEG_NUM_WORKERS = 2\n",
        "SEG_AUG = \"robust\"  # none | basic | robust\n",
        "SEG_SCHEDULER = \"cosine\"  # none | cosine | onecycle\n",
        "SEG_PATIENCE = 3  # early stopping em val_of1 (0 desliga)\n",
        "\n",
        "FFT_EPOCHS = 5\n",
        "FFT_BATCH = 32\n",
        "FFT_LR = 1e-3\n",
        "FFT_WD = 1e-4\n",
        "FFT_NUM_WORKERS = 2\n",
        "FFT_SCHEDULER = \"cosine\"  # none | cosine | onecycle\n",
        "\n",
        "OUT_DIR = Path(\"/kaggle/working\") if Path(\"/kaggle/working\").exists() else Path(\"outputs\")\n",
        "OUT_MODELS = OUT_DIR / \"outputs\" / \"models\"\n",
        "\n",
        "SEG_OUT = OUT_MODELS / \"r69.pth\"\n",
        "FFT_OUT = OUT_MODELS / \"fft_cls.pth\"\n",
        "\n",
        "# (Opcional) checar score local rapidamente após treinar:\n",
        "EVAL_AFTER_TRAIN = True\n",
        "EVAL_SPLIT = \"train\"  # train | supplemental\n",
        "EVAL_LIMIT = 0  # 0 = sem limite (usa tudo)\n",
        "\n",
        "# Empacotar um folder pronto para upload como Kaggle Dataset (offline):\n",
        "DO_PACKAGE = True\n",
        "PKG_OUT = OUT_DIR / \"kaggle_bundle\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def _find_recodai_root() -> Path:\n",
        "    if DATA_ROOT is not None:\n",
        "        return Path(DATA_ROOT)\n",
        "\n",
        "    kaggle_input = Path(\"/kaggle/input\")\n",
        "    if kaggle_input.exists():\n",
        "        for d in kaggle_input.iterdir():\n",
        "            if not d.is_dir():\n",
        "                continue\n",
        "            if (d / \"recodai\" / \"sample_submission.csv\").exists():\n",
        "                return d / \"recodai\"\n",
        "            if (d / \"sample_submission.csv\").exists() and (\n",
        "                (d / \"train_images\").exists() or (d / \"test_images\").exists()\n",
        "            ):\n",
        "                return d\n",
        "\n",
        "    local = Path(\"data/recodai\")\n",
        "    if local.exists():\n",
        "        return local\n",
        "    local2 = CODE_ROOT / \"data\" / \"recodai\"\n",
        "    if local2.exists():\n",
        "        return local2\n",
        "\n",
        "    raise FileNotFoundError(\n",
        "        \"Não encontrei o data root. Defina DATA_ROOT manualmente \"\n",
        "        \"(ex.: /kaggle/input/<dataset>/recodai ou data/recodai).\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Run\n",
        "# -------------------------\n",
        "\n",
        "data_root = _find_recodai_root()\n",
        "print(f\"data_root={data_root}\")\n",
        "\n",
        "device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device = torch.device(device_str)\n",
        "print(f\"device={device} (Dica: ative GPU em Settings -> Accelerator)\")\n",
        "\n",
        "OUT_MODELS.mkdir(parents=True, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -----\n",
        "# Train (Segmentation)\n",
        "# -----\n",
        "\n",
        "seg_result = None\n",
        "if TRAIN_SEG:\n",
        "    seg_result = train_dino_decoder(\n",
        "        config_path=SEG_TRAIN_CONFIG,\n",
        "        data_root=data_root,\n",
        "        out_path=SEG_OUT,\n",
        "        device=device_str,\n",
        "        split=\"train\",\n",
        "        epochs=int(SEG_EPOCHS),\n",
        "        batch_size=int(SEG_BATCH),\n",
        "        lr=float(SEG_LR),\n",
        "        weight_decay=float(SEG_WD),\n",
        "        num_workers=int(SEG_NUM_WORKERS),\n",
        "        folds=int(SEG_FOLDS),\n",
        "        fold=None,\n",
        "        aug=SEG_AUG,  # type: ignore[arg-type]\n",
        "        scheduler=SEG_SCHEDULER,  # type: ignore[arg-type]\n",
        "        patience=int(SEG_PATIENCE),\n",
        "    )\n",
        "\n",
        "    # Se treinou k-fold, copia o melhor fold para o path \"base\" (r69.pth),\n",
        "    # para facilitar o uso em configs que apontam para outputs/models/r69.pth.\n",
        "    if seg_result is not None and int(SEG_FOLDS) > 1:\n",
        "        best = max(seg_result.fold_results, key=lambda fr: fr.best_val_of1)\n",
        "        if best.checkpoint_path != SEG_OUT:\n",
        "            SEG_OUT.parent.mkdir(parents=True, exist_ok=True)\n",
        "            shutil.copy2(best.checkpoint_path, SEG_OUT)\n",
        "            print(f\"Copied best fold checkpoint -> {SEG_OUT} (from {best.checkpoint_path})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -----\n",
        "# Train (FFT classifier)\n",
        "# -----\n",
        "\n",
        "fft_saved = None\n",
        "if TRAIN_FFT:\n",
        "    fft_saved = train_fft_classifier(\n",
        "        config_path=FFT_TRAIN_CONFIG,\n",
        "        data_root=data_root,\n",
        "        out_path=FFT_OUT,\n",
        "        device=device,\n",
        "        epochs=int(FFT_EPOCHS),\n",
        "        batch_size=int(FFT_BATCH),\n",
        "        lr=float(FFT_LR),\n",
        "        weight_decay=float(FFT_WD),\n",
        "        num_workers=int(FFT_NUM_WORKERS),\n",
        "        folds=int(FFT_FOLDS),\n",
        "        scheduler=FFT_SCHEDULER,  # type: ignore[arg-type]\n",
        "    )\n",
        "\n",
        "    if fft_saved and int(FFT_FOLDS) > 1:\n",
        "        # escolhe melhor fold por menor val_loss no checkpoint\n",
        "        best_path = min(\n",
        "            fft_saved,\n",
        "            key=lambda p: float(torch.load(p, map_location=\"cpu\").get(\"val_loss\", float(\"inf\"))),\n",
        "        )\n",
        "        if best_path != FFT_OUT:\n",
        "            FFT_OUT.parent.mkdir(parents=True, exist_ok=True)\n",
        "            shutil.copy2(best_path, FFT_OUT)\n",
        "            print(f\"Copied best FFT fold -> {FFT_OUT} (from {best_path})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Quick evaluation (local)\n",
        "# -------------------------\n",
        "#\n",
        "# Gera um submission no split train/supplemental e calcula oF1 local.\n",
        "\n",
        "if EVAL_AFTER_TRAIN:\n",
        "    from forgeryseg.eval import score_submission_csv, validate_submission_format\n",
        "\n",
        "    eval_cfg = CONFIG_ROOT / \"dino_v3_518_r69_fft_gate.json\"\n",
        "    eval_csv = OUT_DIR / f\"submission_{EVAL_SPLIT}.csv\"\n",
        "\n",
        "    stats = write_submission_csv(\n",
        "        config_path=eval_cfg,\n",
        "        data_root=data_root,\n",
        "        split=EVAL_SPLIT,  # type: ignore[arg-type]\n",
        "        out_path=eval_csv,\n",
        "        device=device,\n",
        "        limit=int(EVAL_LIMIT),\n",
        "        path_roots=[OUT_DIR, CODE_ROOT, CONFIG_ROOT],\n",
        "    )\n",
        "    print(stats)\n",
        "\n",
        "    fmt = validate_submission_format(eval_csv, data_root=data_root, split=EVAL_SPLIT)  # type: ignore[arg-type]\n",
        "    print(\"\\n[Format check]\")\n",
        "    print(json.dumps(fmt, indent=2, ensure_ascii=False))\n",
        "\n",
        "    score = score_submission_csv(eval_csv, data_root=data_root, split=EVAL_SPLIT)  # type: ignore[arg-type]\n",
        "    print(\"\\n[Local score]\")\n",
        "    print(json.dumps(score.as_dict(csv_path=eval_csv, split=EVAL_SPLIT), indent=2, ensure_ascii=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -------------------------\n",
        "# Package Kaggle Dataset folder\n",
        "# -------------------------\n",
        "#\n",
        "# Cria um folder pronto para upload como Kaggle Dataset:\n",
        "# - código (src/scripts/configs/notebooks/docs)\n",
        "# - + `outputs/models/*.pth` (opcional)\n",
        "#\n",
        "# Depois, anexe esse dataset no notebook de submissão (internet OFF).\n",
        "\n",
        "if DO_PACKAGE:\n",
        "    out_root = package_kaggle_dataset(\n",
        "        out_dir=PKG_OUT,\n",
        "        include_models=True,\n",
        "        models_dir=OUT_MODELS,\n",
        "        repo_root=CODE_ROOT,\n",
        "    )\n",
        "    print(f\"Wrote Kaggle bundle at: {out_root.resolve()}\")\n",
        "    print(\"Crie um Kaggle Dataset a partir desse folder e anexe no notebook de submissão offline.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
