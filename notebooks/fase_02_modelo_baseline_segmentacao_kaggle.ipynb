{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "722d60d9",
   "metadata": {},
   "source": [
    "Fase 2 — Baseline de Segmentação (Kaggle / Notebook-only)\n",
    "\n",
    "Objetivo desta etapa:\n",
    "- Preparar o dataset (carregar imagens + máscaras)\n",
    "- Padronizar entrada (resize + pad) e binarizar máscaras\n",
    "- Definir augmentations consistentes (imagem + máscara + área válida)\n",
    "- Criar K folds (K=5) para validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7759c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celula 1 — Regras do Kaggle (sanidade)\n",
    "print(\"Kaggle submission constraints (lembrete):\")\n",
    "print(\"- Submissions via Notebook\")\n",
    "print(\"- Runtime <= 4h (CPU/GPU)\")\n",
    "print(\"- Internet: OFF\")\n",
    "print(\"- Output: submission.csv ou submission.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37285ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celula 2 — Imports + ambiente\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"opencv:\", cv2.__version__)\n",
    "print(\"albumentations:\", A.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd50abb",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Celula 3 — Paths + seed\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "def is_kaggle() -> bool:\n",
    "    return bool(os.environ.get(\"KAGGLE_URL_BASE\")) or Path(\"/kaggle\").exists()\n",
    "\n",
    "\n",
    "def find_dataset_root() -> Path:\n",
    "    # Kaggle: padrão da competição\n",
    "    if is_kaggle():\n",
    "        base = Path(\"/kaggle/input/recodai-luc-scientific-image-forgery-detection\")\n",
    "        if base.exists():\n",
    "            return base\n",
    "\n",
    "        # fallback: procura qualquer dataset anexado que tenha a estrutura esperada\n",
    "        kaggle_input = Path(\"/kaggle/input\")\n",
    "        if kaggle_input.exists():\n",
    "            for ds in sorted(kaggle_input.glob(\"*\")):\n",
    "                if (ds / \"train_images\").exists() and (ds / \"test_images\").exists():\n",
    "                    return ds\n",
    "\n",
    "    # Local (repo): `data/`\n",
    "    base = Path(\"data\").resolve()\n",
    "    if (base / \"train_images\").exists() and (base / \"test_images\").exists():\n",
    "        return base\n",
    "\n",
    "    raise FileNotFoundError(\n",
    "        \"Dataset não encontrado.\\n\"\n",
    "        \"- No Kaggle: anexe o dataset da competição (Add data) e garanta que existe `train_images/`.\\n\"\n",
    "        \"- Local: espere `data/train_images` e `data/train_masks`.\"\n",
    "    )\n",
    "\n",
    "\n",
    "DATA_ROOT = find_dataset_root()\n",
    "TRAIN_IMAGES = DATA_ROOT / \"train_images\"\n",
    "TRAIN_MASKS = DATA_ROOT / \"train_masks\"\n",
    "\n",
    "print(\"DATA_ROOT:\", DATA_ROOT)\n",
    "print(\"Train images dir:\", TRAIN_IMAGES)\n",
    "print(\"Train masks dir:\", TRAIN_MASKS)\n",
    "num_auth = len(list((TRAIN_IMAGES / \"authentic\").glob(\"*.png\")))\n",
    "num_forged = len(list((TRAIN_IMAGES / \"forged\").glob(\"*.png\")))\n",
    "num_masks = len(list(TRAIN_MASKS.glob(\"*.npy\")))\n",
    "print(\"Train/authentic:\", num_auth)\n",
    "print(\"Train/forged:\", num_forged)\n",
    "print(\"Masks:\", num_masks)\n",
    "if num_auth == 0 and num_forged == 0:\n",
    "    raise FileNotFoundError(\n",
    "        \"Nenhuma imagem encontrada em `train_images/authentic` e `train_images/forged`.\\n\"\n",
    "        f\"DATA_ROOT={DATA_ROOT}\\n\"\n",
    "        \"No Kaggle, isso normalmente significa que o dataset da competição não foi anexado ao notebook.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcffb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celula 4 — Index do dataset (DataFrame principal)\n",
    "@dataclass(frozen=True)\n",
    "class Sample:\n",
    "    case_id: str\n",
    "    label: str  # authentic/forged\n",
    "    img_path: Path\n",
    "    mask_path: Path | None\n",
    "\n",
    "\n",
    "def build_train_index(train_images_dir: Path, train_masks_dir: Path) -> pd.DataFrame:\n",
    "    rows: list[dict] = []\n",
    "    for label in [\"authentic\", \"forged\"]:\n",
    "        for img_path in sorted((train_images_dir / label).glob(\"*.png\")):\n",
    "            case_id = img_path.stem\n",
    "            mask_path = train_masks_dir / f\"{case_id}.npy\" if label == \"forged\" else None\n",
    "            file_size = img_path.stat().st_size\n",
    "\n",
    "            width = height = None\n",
    "            mode = None\n",
    "            read_error = None\n",
    "            try:\n",
    "                with Image.open(img_path) as img:\n",
    "                    width, height = img.size\n",
    "                    mode = img.mode\n",
    "            except Exception as exc:\n",
    "                read_error = f\"{type(exc).__name__}: {exc}\"\n",
    "\n",
    "            mask_instances = 0\n",
    "            mask_area = 0\n",
    "            mask_area_frac = 0.0\n",
    "            if mask_path is not None:\n",
    "                mask = np.load(mask_path)\n",
    "                if mask.ndim == 2:\n",
    "                    mask = mask[None, ...]\n",
    "                mask_instances = int(mask.shape[0])\n",
    "                union = mask.max(axis=0)\n",
    "                mask_area = int((union > 0).sum())\n",
    "                if width is not None and height is not None:\n",
    "                    mask_area_frac = mask_area / float(width * height)\n",
    "                else:\n",
    "                    mask_area_frac = np.nan\n",
    "\n",
    "            rows.append(\n",
    "                {\n",
    "                    \"case_id\": case_id,\n",
    "                    \"split\": \"train\",\n",
    "                    \"label\": label,\n",
    "                    \"img_path\": str(img_path),\n",
    "                    \"mask_path\": None if mask_path is None else str(mask_path),\n",
    "                    \"width\": width,\n",
    "                    \"height\": height,\n",
    "                    \"mode\": mode,\n",
    "                    \"file_size\": file_size,\n",
    "                    \"mask_instances\": mask_instances,\n",
    "                    \"mask_area\": mask_area,\n",
    "                    \"mask_area_frac\": mask_area_frac,\n",
    "                    \"read_error\": read_error,\n",
    "                }\n",
    "            )\n",
    "    if not rows:\n",
    "        raise FileNotFoundError(\n",
    "            \"Index vazio: não encontrei arquivos `*.png`.\\n\"\n",
    "            f\"train_images_dir={train_images_dir}\\n\"\n",
    "            \"Verifique se o dataset correto foi anexado no Kaggle (Add data).\"\n",
    "        )\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "df = build_train_index(TRAIN_IMAGES, TRAIN_MASKS)\n",
    "display(df.head())\n",
    "print(\"Rows:\", len(df))\n",
    "if \"label\" not in df.columns:\n",
    "    raise KeyError(f\"df não tem coluna 'label'. colunas={df.columns.tolist()}\")\n",
    "display(df[\"label\"].value_counts())\n",
    "print(\"Read errors:\", int(df[\"read_error\"].notna().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd57032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celula 5 — Estatísticas rápidas (tamanho / área de máscara)\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.scatter(df[\"width\"], df[\"height\"], s=4, alpha=0.3)\n",
    "plt.title(\"Image sizes (width x height)\")\n",
    "plt.xlabel(\"width\")\n",
    "plt.ylabel(\"height\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "df[df[\"label\"] == \"forged\"][\"mask_area_frac\"].hist(bins=40)\n",
    "plt.title(\"Mask area fraction (forged)\")\n",
    "plt.xlabel(\"mask_area_frac\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071ac50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celula 6 — Preprocess (resize+pad para 512x512) + máscara binária\n",
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "\n",
    "TARGET_SIZE = 512\n",
    "\n",
    "\n",
    "def load_image_rgb(path: str | Path) -> np.ndarray:\n",
    "    path = Path(path)\n",
    "    with Image.open(path) as img:\n",
    "        img = img.convert(\"RGB\")\n",
    "        return np.array(img)\n",
    "\n",
    "\n",
    "def load_mask_union(path: str | Path | None, shape_hw: tuple[int, int]) -> np.ndarray:\n",
    "    if path is None:\n",
    "        return np.zeros(shape_hw, dtype=np.uint8)\n",
    "    masks = np.load(Path(path))\n",
    "    if masks.ndim == 2:\n",
    "        union = masks\n",
    "    else:\n",
    "        union = masks.max(axis=0)\n",
    "    union = (union > 0).astype(np.uint8)\n",
    "    if union.shape != shape_hw:\n",
    "        raise ValueError(f\"Mask shape {union.shape} does not match image shape {shape_hw}\")\n",
    "    return union\n",
    "\n",
    "\n",
    "def resize_pad_to_square(\n",
    "    image: np.ndarray,\n",
    "    mask: np.ndarray,\n",
    "    size: int = TARGET_SIZE,\n",
    ") -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    h, w = image.shape[:2]\n",
    "    scale = size / float(max(h, w))\n",
    "    new_w = int(round(w * scale))\n",
    "    new_h = int(round(h * scale))\n",
    "    image_rs = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "    mask_rs = cv2.resize(mask, (new_w, new_h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    pad_h = size - new_h\n",
    "    pad_w = size - new_w\n",
    "    image_pad = np.pad(image_rs, ((0, pad_h), (0, pad_w), (0, 0)), mode=\"constant\")\n",
    "    mask_pad = np.pad(mask_rs, ((0, pad_h), (0, pad_w)), mode=\"constant\")\n",
    "    valid = np.zeros((size, size), dtype=np.uint8)\n",
    "    valid[:new_h, :new_w] = 1\n",
    "    return image_pad, mask_pad, valid\n",
    "\n",
    "\n",
    "row = df[df[\"label\"] == \"forged\"].iloc[0]\n",
    "img = load_image_rgb(row[\"img_path\"])\n",
    "mask = load_mask_union(row[\"mask_path\"], img.shape[:2])\n",
    "img_p, mask_p, valid = resize_pad_to_square(img, mask, size=TARGET_SIZE)\n",
    "print(\"Original:\", img.shape, \"Processed:\", img_p.shape, \"mask sum:\", int(mask.sum()), \"proc mask sum:\", int(mask_p.sum()))\n",
    "\n",
    "\n",
    "def overlay_mask(image: np.ndarray, mask: np.ndarray, color=(255, 0, 0), alpha: float = 0.45) -> np.ndarray:\n",
    "    mask = mask.astype(bool)\n",
    "    out = image.copy().astype(np.float32)\n",
    "    out[mask] = (1 - alpha) * out[mask] + alpha * np.array(color, dtype=np.float32)\n",
    "    return out.astype(np.uint8)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "axes[0].imshow(img)\n",
    "axes[0].set_title(\"original\")\n",
    "axes[0].axis(\"off\")\n",
    "axes[1].imshow(overlay_mask(img, mask))\n",
    "axes[1].set_title(\"original + mask\")\n",
    "axes[1].axis(\"off\")\n",
    "axes[2].imshow(overlay_mask(img_p, mask_p))\n",
    "axes[2].set_title(\"processed 512 + mask\")\n",
    "axes[2].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9e75a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celula 7 — Augmentations (imagem + máscara + valid_mask) + preview\n",
    "train_aug = A.Compose(\n",
    "    [\n",
    "        # Random crop + resize (mantem saida 512x512)\n",
    "        A.RandomResizedCrop(\n",
    "            size=(TARGET_SIZE, TARGET_SIZE),\n",
    "            scale=(0.6, 1.0),\n",
    "            ratio=(0.75, 1.3333333333333333),\n",
    "            interpolation=cv2.INTER_AREA,\n",
    "            mask_interpolation=cv2.INTER_NEAREST,\n",
    "            p=0.5,\n",
    "        ),\n",
    "        # Geometria (flips + rotacao 0-360 + zoom in/out)\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.Affine(\n",
    "            scale=(0.75, 1.25),\n",
    "            translate_percent=(-0.1, 0.1),\n",
    "            rotate=(-180, 180),\n",
    "            shear=(-8, 8),\n",
    "            interpolation=cv2.INTER_LINEAR,\n",
    "            mask_interpolation=cv2.INTER_NEAREST,\n",
    "            border_mode=cv2.BORDER_CONSTANT,\n",
    "            fill=0,\n",
    "            fill_mask=0,\n",
    "            p=0.8,\n",
    "        ),\n",
    "        # Deformacoes locais leves\n",
    "        A.ElasticTransform(\n",
    "            alpha=1.0,\n",
    "            sigma=30.0,\n",
    "            interpolation=cv2.INTER_LINEAR,\n",
    "            mask_interpolation=cv2.INTER_NEAREST,\n",
    "            border_mode=cv2.BORDER_CONSTANT,\n",
    "            fill=0,\n",
    "            fill_mask=0,\n",
    "            p=0.15,\n",
    "        ),\n",
    "        A.GridDistortion(\n",
    "            num_steps=5,\n",
    "            distort_limit=(-0.03, 0.03),\n",
    "            interpolation=cv2.INTER_LINEAR,\n",
    "            mask_interpolation=cv2.INTER_NEAREST,\n",
    "            border_mode=cv2.BORDER_CONSTANT,\n",
    "            fill=0,\n",
    "            fill_mask=0,\n",
    "            p=0.1,\n",
    "        ),\n",
    "        # Cor/contraste/ruido (robustez a intensidades e artefatos)\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=1.0),\n",
    "                A.ColorJitter(\n",
    "                    brightness=(0.8, 1.2),\n",
    "                    contrast=(0.8, 1.2),\n",
    "                    saturation=(0.8, 1.2),\n",
    "                    hue=(-0.05, 0.05),\n",
    "                    p=1.0,\n",
    "                ),\n",
    "                A.RandomGamma(gamma_limit=(80, 120), p=1.0),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.GaussianBlur(blur_limit=(3, 7), p=1.0),\n",
    "                A.MedianBlur(blur_limit=(3, 7), p=1.0),\n",
    "                A.MotionBlur(blur_limit=(3, 7), p=1.0),\n",
    "            ],\n",
    "            p=0.25,\n",
    "        ),\n",
    "        A.GaussNoise(std_range=(0.01, 0.08), p=0.2),\n",
    "        A.ImageCompression(quality_range=(60, 100), p=0.2),\n",
    "        # Cutout: aplica na imagem, mas NAO altera mask/valid (fill_mask=None)\n",
    "        A.CoarseDropout(\n",
    "            num_holes_range=(1, 6),\n",
    "            hole_height_range=(0.05, 0.25),\n",
    "            hole_width_range=(0.05, 0.25),\n",
    "            fill=0,\n",
    "            fill_mask=None,\n",
    "            p=0.3,\n",
    "        ),\n",
    "    ],\n",
    "    additional_targets={\"valid\": \"mask\"},\n",
    ")\n",
    "\n",
    "aug = train_aug(image=img_p, mask=mask_p, valid=valid)\n",
    "img_a = aug[\"image\"]\n",
    "mask_a = aug[\"mask\"]\n",
    "valid_a = aug[\"valid\"]\n",
    "print(\"Augmented shapes:\", img_a.shape, mask_a.shape, valid_a.shape)\n",
    "print(\"Aug config: aggressive geometric + color + local distort + cutout\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "axes[0].imshow(overlay_mask(img_p, mask_p))\n",
    "axes[0].set_title(\"processed + mask\")\n",
    "axes[0].axis(\"off\")\n",
    "axes[1].imshow(overlay_mask(img_a, mask_a))\n",
    "axes[1].set_title(\"augmented + mask\")\n",
    "axes[1].axis(\"off\")\n",
    "axes[2].imshow(overlay_mask(img_a, (1 - valid_a).astype(np.uint8), color=(0, 255, 255)))\n",
    "axes[2].set_title(\"augmented padding area\")\n",
    "axes[2].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67eff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celula 8 — K-fold (5 folds) sem sklearn (estratificado por label + bins de area)\n",
    "AREA_BINS = [0.0, 0.001, 0.005, 0.01, 0.05, 0.2, 1.0]\n",
    "\n",
    "df[\"area_bin\"] = pd.cut(df[\"mask_area_frac\"].fillna(0), bins=AREA_BINS, include_lowest=True, labels=False)\n",
    "df[\"area_bin\"] = df[\"area_bin\"].fillna(0).astype(int)\n",
    "df[\"stratify_key\"] = df[\"label\"].astype(str) + \"_b\" + df[\"area_bin\"].astype(str)\n",
    "df[\"fold\"] = -1\n",
    "\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "for key, idxs in df.groupby(\"stratify_key\").indices.items():\n",
    "    idxs = np.array(list(idxs), dtype=int)\n",
    "    rng.shuffle(idxs)\n",
    "    for i, idx in enumerate(idxs):\n",
    "        df.loc[idx, \"fold\"] = int(i % 5)\n",
    "\n",
    "assert int((df[\"fold\"] < 0).sum()) == 0\n",
    "fold_counts = pd.crosstab(df[\"fold\"], df[\"label\"])\n",
    "display(fold_counts)\n",
    "print(\"Fold sizes:\", df[\"fold\"].value_counts().sort_index().to_dict())\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "df[df[\"label\"] == \"forged\"].groupby(\"fold\")[\"mask_area_frac\"].mean().plot(kind=\"bar\")\n",
    "plt.title(\"Mean mask_area_frac (forged) por fold\")\n",
    "plt.ylabel(\"mean mask_area_frac\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
