{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b33eecb",
   "metadata": {},
   "source": [
    "# Fase 3 — Pipeline completo (treino + inferência + submissão)\n",
    "\n",
    "Este notebook é um \"guia executável\" para:\n",
    "1) Treinar um baseline de segmentação (opcional),\n",
    "2) Validar com oF1 (opcional, depende de `scipy`),\n",
    "3) Rodar inferência no `test_images/` e gerar `submission.csv`.\n",
    "\n",
    "**Modo Kaggle (Code Competition)**\n",
    "- Internet: OFF no momento da submissão.\n",
    "- Tempo típico: até 4h.\n",
    "- Saída esperada: `submission.csv` (ou `submission.parquet`).\n",
    "\n",
    "**Importante**\n",
    "- Por padrão, este notebook usa o código do projeto em `src/forgeryseg/`.\n",
    "- No Kaggle, a forma mais prática é adicionar este repositório (código + pesos)\n",
    "  como um *Dataset* e o notebook automaticamente encontra e adiciona no `sys.path`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6bf779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 1 — Regras do Kaggle (sanidade)\n",
    "print(\"Kaggle submission constraints (lembrete):\")\n",
    "print(\"- Submissions via Notebook\")\n",
    "print(\"- Runtime <= 4h (CPU/GPU)\")\n",
    "print(\"- Internet: OFF no submit\")\n",
    "print(\"- Output: submission.csv ou submission.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cf891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 2 — Imports + ambiente\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import Iterable\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "print(\"python:\", sys.version.split()[0])\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"cuda available:\", torch.cuda.is_available())\n",
    "\n",
    "\n",
    "def is_kaggle() -> bool:\n",
    "    return bool(os.environ.get(\"KAGGLE_URL_BASE\")) or Path(\"/kaggle\").exists()\n",
    "\n",
    "\n",
    "def set_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "set_seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eec229",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 3 — Localizar o código do repo (Kaggle/local) e habilitar imports\n",
    "\n",
    "\n",
    "def find_project_root() -> Path:\n",
    "    \"\"\"\n",
    "    Encontra um diretório que contenha `src/forgeryseg/`.\n",
    "    - Local: procura no CWD e ancestrais.\n",
    "    - Kaggle: procura também em `/kaggle/input/*`.\n",
    "    \"\"\"\n",
    "    cwd = Path.cwd().resolve()\n",
    "    for p in [cwd, *cwd.parents]:\n",
    "        if (p / \"src\" / \"forgeryseg\").exists():\n",
    "            return p\n",
    "\n",
    "    kaggle_input = Path(\"/kaggle/input\")\n",
    "    if kaggle_input.exists():\n",
    "        for ds in sorted(kaggle_input.glob(\"*\")):\n",
    "            if (ds / \"src\" / \"forgeryseg\").exists():\n",
    "                return ds\n",
    "            for sub in sorted(ds.glob(\"*\")):\n",
    "                if (sub / \"src\" / \"forgeryseg\").exists():\n",
    "                    return sub\n",
    "\n",
    "    raise FileNotFoundError(\"Não achei `src/forgeryseg/` (adicione o repo como Dataset no Kaggle ou rode no repo local).\")\n",
    "\n",
    "\n",
    "PROJECT_ROOT = find_project_root()\n",
    "SRC_ROOT = PROJECT_ROOT / \"src\"\n",
    "sys.path.insert(0, str(SRC_ROOT))\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"SRC_ROOT:\", SRC_ROOT)\n",
    "\n",
    "from forgeryseg.augment import get_train_augment, get_val_augment\n",
    "from forgeryseg.dataset import PatchDataset, build_test_index, build_train_index, load_image, load_mask_instances\n",
    "from forgeryseg.inference import predict_image\n",
    "from forgeryseg.losses import BCEDiceLoss, BCETverskyLoss\n",
    "from forgeryseg.metric import score_image\n",
    "from forgeryseg.postprocess import binarize\n",
    "from forgeryseg.rle import encode_instances\n",
    "from forgeryseg.train import train_one_epoch, validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6354b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 4 — Paths do dataset (Kaggle/local) + config\n",
    "\n",
    "KAGGLE_COMP_DATASET = Path(\"/kaggle/input/recodai-luc-scientific-image-forgery-detection\")\n",
    "if (KAGGLE_COMP_DATASET / \"train_images\").exists():\n",
    "    DATA_ROOT = KAGGLE_COMP_DATASET\n",
    "else:\n",
    "    DATA_ROOT = PROJECT_ROOT / \"data\" / \"recodai\"\n",
    "\n",
    "OUTPUT_ROOT = Path(\"/kaggle/working/outputs\") if is_kaggle() else (PROJECT_ROOT / \"outputs\")\n",
    "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CONFIG_PATH = PROJECT_ROOT / \"configs\" / \"baseline_fpn_convnext.json\"\n",
    "cfg: dict = {}\n",
    "if CONFIG_PATH.exists():\n",
    "    cfg = json.loads(CONFIG_PATH.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "print(\"DATA_ROOT:\", DATA_ROOT)\n",
    "print(\"OUTPUT_ROOT:\", OUTPUT_ROOT)\n",
    "print(\"Config loaded:\", bool(cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc113d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 5 — Index (train/test) + contagens\n",
    "\n",
    "train_samples = build_train_index(DATA_ROOT)\n",
    "test_samples = build_test_index(DATA_ROOT)\n",
    "\n",
    "print(\"Train samples:\", len(train_samples))\n",
    "print(\"Test samples:\", len(test_samples))\n",
    "print(\"Train authentic:\", sum(1 for s in train_samples if s.is_authentic))\n",
    "print(\"Train forged:\", sum(1 for s in train_samples if s.is_authentic is False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d7ecec",
   "metadata": {},
   "source": [
    "## Análise dos Dados e Pré-processamento\n",
    "\n",
    "Antes de treinar modelos, é útil realizar uma exploração dos dados. Cada imagem possui um identificador `case_id`.\n",
    "No dataset de treino, existe um subconjunto de imagens **autênticas** (sem manipulação) e imagens **forjadas**\n",
    "(copy-move). Para as imagens forjadas, há uma máscara de segmentação indicando os pixels duplicados; para imagens\n",
    "autênticas, não há máscara (equivalente a \"nenhum pixel forjado\").\n",
    "\n",
    "**Observação importante (treino):** no snapshot do Kaggle, o mesmo `case_id` pode aparecer em **`authentic/` e\n",
    "`forged/`** (duas imagens diferentes). Para indexar sem colisões, use o caminho relativo (`rel_path`) ou uma chave\n",
    "composta (ex.: `f\\\"{label}/{case_id}\\\"`).\n",
    "\n",
    "O que precisamos construir:\n",
    "\n",
    "- **Segmentação:** pares `(imagem, máscara)` (aqui usamos a **união** das instâncias como máscara binária, e depois\n",
    "  recuperamos instâncias via componentes conexos na hora do `submission`).\n",
    "- **Classificação (opcional):** rótulo binário `y_cls` para decidir se é `authentic` (0) ou `forged` (1).\n",
    "\n",
    "Pré-processamento (baseline deste repo):\n",
    "\n",
    "- Leitura com PIL e conversão para **RGB**.\n",
    "- Conversão para `float32`, escala para `[0, 1]` e **normalização ImageNet**.\n",
    "- Treino *patch-based* (`PatchDataset`): amostra crops de tamanho `patch_size`, com *oversampling* de regiões positivas\n",
    "  em imagens forjadas (controlado por `positive_prob`/`min_pos_pixels`).\n",
    "- Inferência em imagem inteira via **tiling** (`tile_size`/`overlap`) para lidar com imagens grandes.\n",
    "\n",
    "### Dimensionamento e formato (decisão do baseline)\n",
    "\n",
    "- **Canais:** padronizamos todas as imagens para **3 canais (RGB)**. Se a imagem for originalmente em escala de cinza,\n",
    "  duplicamos o canal (via `PIL.Image.convert(\"RGB\")`), o que funciona bem para *backbones* pré-treinados em ImageNet.\n",
    "- **Tamanho no treino:** ao invés de fazer *downscale* agressivo da figura inteira (que pode apagar falsificações\n",
    "  pequenas), treinamos com **patches 512×512** (crop) e fazemos **padding** quando a imagem é menor. Isso fixa o shape\n",
    "  de entrada e mantém detalhes locais.\n",
    "- **Tamanho na inferência:** rodamos em **tiles** (ex.: `tile_size=1024`, `overlap=128`) para preservar resolução em\n",
    "  imagens grandes. Se o runtime ficar inviável, use `MAX_SIZE` para limitar o lado maior (trade-off controlado).\n",
    "\n",
    "### Normalização (decisão do baseline)\n",
    "\n",
    "- **Escala:** convertemos para `float32` e, quando a imagem vem em `uint8`, reescalamos para **[0, 1]**.\n",
    "- **Padronização por canal:** aplicamos **média/desvio do ImageNet** (o padrão esperado por encoders pré-treinados).\n",
    "- **Sem equalização fixa:** não aplicamos equalização/histogram matching como pré-processamento determinístico para não\n",
    "  correr o risco de mascarar/alterar evidências sutis de copy-move. Em vez disso, lidamos com variações de contraste\n",
    "  via **data augmentation** (ex.: `RandomBrightnessContrast`, `RandomGamma`, `CLAHE`) e pela robustez do modelo.\n",
    "\n",
    "### Divisão de dados (decisão do baseline: 5-fold CV + ensemble)\n",
    "\n",
    "Em *code competitions*, o conjunto de teste real é **oculto** e não existe um \"val set oficial\" fixo. Para\n",
    "desenvolvimento local, precisamos criar uma validação a partir do treino:\n",
    "\n",
    "- **Opção simples:** holdout (ex.: 80/20 estratificado).\n",
    "- **Opção de performance:** **K-fold cross-validation** (ex.: 5-fold), treinando 5 modelos e fazendo **ensemble** na\n",
    "  inferência. Isso melhora o uso do treino e tende a reduzir overfitting, mas custa ~5× mais tempo de treino.\n",
    "\n",
    "**Escolha aqui:** usamos **5 folds** e fazemos **ensemble** dos modelos finais.\n",
    "Para evitar vazamento, fazemos o split **agrupando por `case_id`** (quando existe par `authentic/` e `forged/` com o\n",
    "mesmo id, eles caem no mesmo fold).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf04b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 5b — Exemplo: carregando (imagem, máscara) e label binário\n",
    "sample0 = train_samples[0]\n",
    "image0 = load_image(sample0.image_path)\n",
    "gt_instances0 = load_mask_instances(sample0.mask_path) if sample0.mask_path else []\n",
    "\n",
    "if gt_instances0:\n",
    "    union_mask0 = np.max(np.stack(gt_instances0, axis=0), axis=0).astype(np.uint8)\n",
    "else:\n",
    "    union_mask0 = np.zeros(image0.shape[:2], dtype=np.uint8)\n",
    "\n",
    "y_cls0 = 0 if sample0.is_authentic else 1\n",
    "\n",
    "print(\"case_id:\", sample0.case_id)\n",
    "print(\"label:\", sample0.label, \"| y_cls:\", y_cls0)\n",
    "print(\"image shape:\", image0.shape, \"dtype:\", image0.dtype)\n",
    "print(\"instances:\", len(gt_instances0), \"| union mask sum:\", int(union_mask0.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcb2264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 5c — EDA rápida (opcional): tamanhos e áreas de máscara\n",
    "RUN_EDA = False  # deixe False no submit; True para explorar interativamente\n",
    "\n",
    "if RUN_EDA:\n",
    "    import pandas as pd\n",
    "    from IPython.display import display\n",
    "    from PIL import Image\n",
    "\n",
    "    rows = []\n",
    "    for s in train_samples:\n",
    "        width = height = None\n",
    "        mode = None\n",
    "        with Image.open(s.image_path) as img:\n",
    "            width, height = img.size\n",
    "            mode = img.mode\n",
    "\n",
    "        mask_instances = 0\n",
    "        mask_area = 0\n",
    "        mask_area_frac = 0.0\n",
    "        if s.mask_path is not None:\n",
    "            masks = np.load(s.mask_path)\n",
    "            if masks.ndim == 2:\n",
    "                masks = masks[None, ...]\n",
    "            mask_instances = int(masks.shape[0])\n",
    "            union = masks.max(axis=0)\n",
    "            mask_area = int((union > 0).sum())\n",
    "            mask_area_frac = mask_area / float(width * height)\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"case_id\": s.case_id,\n",
    "                \"label\": s.label,\n",
    "                \"rel_path\": str(s.rel_path),\n",
    "                \"width\": width,\n",
    "                \"height\": height,\n",
    "                \"mode\": mode,\n",
    "                \"mask_instances\": mask_instances,\n",
    "                \"mask_area\": mask_area,\n",
    "                \"mask_area_frac\": mask_area_frac,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df_train = pd.DataFrame(rows)\n",
    "    display(df_train.head())\n",
    "    display(df_train[\"label\"].value_counts())\n",
    "    display(df_train[\"mode\"].value_counts())\n",
    "    print(\"unique case_id:\", int(df_train[\"case_id\"].nunique()))\n",
    "    print(\"duplicated case_id (train):\", int(df_train.duplicated(\"case_id\").sum()))\n",
    "\n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.scatter(df_train[\"width\"], df_train[\"height\"], s=3, alpha=0.25)\n",
    "        plt.title(\"Train image sizes (width x height)\")\n",
    "        plt.xlabel(\"width\")\n",
    "        plt.ylabel(\"height\")\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        df_train[df_train[\"label\"] == \"forged\"][\"mask_area_frac\"].hist(bins=40)\n",
    "        plt.title(\"Mask area fraction (forged)\")\n",
    "        plt.xlabel(\"mask_area_frac\")\n",
    "        plt.show()\n",
    "    except Exception as exc:\n",
    "        print(\"plots indisponíveis:\", repr(exc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19ea0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 6 — Split em folds (5-fold) com agrupamento por case_id\n",
    "\n",
    "\n",
    "def _case_id_groups(samples) -> dict[str, list[int]]:\n",
    "    groups: dict[str, list[int]] = {}\n",
    "    for idx, s in enumerate(samples):\n",
    "        groups.setdefault(str(s.case_id), []).append(int(idx))\n",
    "    return groups\n",
    "\n",
    "\n",
    "def iter_case_id_folds(samples, n_splits: int, seed: int) -> Iterable[tuple[np.ndarray, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    Gera folds garantindo que o mesmo case_id não apareça em treino e validação.\n",
    "    A estratificação é feita no nível do case_id por \"tipo de grupo\" (par vs solo),\n",
    "    o que ajuda a manter a proporção authentic/forged por fold no snapshot deste dataset.\n",
    "    \"\"\"\n",
    "    groups = _case_id_groups(samples)\n",
    "    case_ids = sorted(groups.keys())\n",
    "    # 0 = par (authentic+forged), 1 = solo (apenas forged)\n",
    "    y_group = np.array([0 if len(groups[cid]) >= 2 else 1 for cid in case_ids], dtype=int)\n",
    "\n",
    "    try:\n",
    "        from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "        splitter = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "        for train_g, val_g in splitter.split(np.zeros(len(case_ids)), y_group):\n",
    "            train_idx: list[int] = []\n",
    "            val_idx: list[int] = []\n",
    "            for gi in train_g:\n",
    "                train_idx.extend(groups[case_ids[int(gi)]])\n",
    "            for gi in val_g:\n",
    "                val_idx.extend(groups[case_ids[int(gi)]])\n",
    "            yield np.array(sorted(train_idx), dtype=int), np.array(sorted(val_idx), dtype=int)\n",
    "        return\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    indices = np.arange(len(case_ids))\n",
    "    folds: list[list[int]] = [[] for _ in range(n_splits)]\n",
    "    for label in np.unique(y_group):\n",
    "        label_indices = indices[y_group == label]\n",
    "        rng.shuffle(label_indices)\n",
    "        for i, idx in enumerate(label_indices):\n",
    "            folds[i % n_splits].append(int(idx))\n",
    "\n",
    "    for fold_idx in range(n_splits):\n",
    "        val_g = np.array(sorted(folds[fold_idx]), dtype=int)\n",
    "        val_g_set = set(val_g.tolist())\n",
    "        train_g = np.array([int(i) for i in indices if int(i) not in val_g_set], dtype=int)\n",
    "\n",
    "        train_idx: list[int] = []\n",
    "        val_idx: list[int] = []\n",
    "        for gi in train_g:\n",
    "            train_idx.extend(groups[case_ids[int(gi)]])\n",
    "        for gi in val_g:\n",
    "            val_idx.extend(groups[case_ids[int(gi)]])\n",
    "\n",
    "        yield np.array(sorted(train_idx), dtype=int), np.array(sorted(val_idx), dtype=int)\n",
    "\n",
    "\n",
    "N_FOLDS = int(cfg.get(\"folds\", 5)) if cfg else 5\n",
    "FOLD = 0\n",
    "\n",
    "folds = list(iter_case_id_folds(train_samples, n_splits=N_FOLDS, seed=SEED))\n",
    "train_idx, val_idx = folds[FOLD]\n",
    "\n",
    "train_fold_samples = [train_samples[int(i)] for i in train_idx]\n",
    "val_fold_samples = [train_samples[int(i)] for i in val_idx]\n",
    "\n",
    "print(f\"fold {FOLD}/{N_FOLDS}: train={len(train_fold_samples)} val={len(val_fold_samples)}\")\n",
    "print(\"val forged:\", sum(1 for s in val_fold_samples if s.is_authentic is False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a09cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 7 — Config de treino (patch-based)\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "PATCH_SIZE = int(cfg.get(\"patch_size\", 512)) if cfg else 512\n",
    "BATCH_SIZE = int(cfg.get(\"batch_size\", 8)) if cfg else 8\n",
    "NUM_WORKERS = int(cfg.get(\"num_workers\", 2)) if cfg else 2\n",
    "\n",
    "POSITIVE_PROB = float(cfg.get(\"positive_prob\", 0.7)) if cfg else 0.7\n",
    "MIN_POS_PIXELS = int(cfg.get(\"min_pos_pixels\", 32)) if cfg else 32\n",
    "MAX_TRIES = int(cfg.get(\"max_tries\", 10)) if cfg else 10\n",
    "POS_SAMPLE_WEIGHT = float(cfg.get(\"pos_sample_weight\", 2.0)) if cfg else 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b5f73d",
   "metadata": {},
   "source": [
    "## Data Augmentation (Aumento de Dados)\n",
    "\n",
    "Este baseline usa **Albumentations** para aplicar aumentos **coerentes** entre `image` e `mask` (para geometria),\n",
    "e aumentos **apenas na imagem** (para ruído/cor/blur).\n",
    "\n",
    "Geometria (image + mask):\n",
    "\n",
    "- **Flips** horizontal/vertical\n",
    "- **Rotação 90°** aleatória e **pequenas rotações** (Affine)\n",
    "- **Escala/zoom e translação** (Affine + RandomResizedCrop)\n",
    "\n",
    "Robustez fotométrica (apenas image):\n",
    "\n",
    "- **Brilho/contraste**, **gamma** e **CLAHE** (leve)\n",
    "- **Ruído gaussiano** e **blur** (gauss/motion)\n",
    "- **Compressão** (artefatos tipo JPEG) e **cutout**\n",
    "\n",
    "Copy-move sintético (image + mask):\n",
    "\n",
    "- Para patches com máscara vazia (amostra autêntica), aplicamos um **copy-move on-the-fly**:\n",
    "  copiamos uma região e colamos em outra posição no mesmo patch, marcando **origem e destino** na máscara.\n",
    "  Opcionalmente aplicamos pequena rotação/escala no patch colado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645f7b38",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Célula 7b — Config do augmentation (inclui copy-move sintético)\n",
    "COPY_MOVE_PROB = float(cfg.get(\"copy_move_prob\", 0.25)) if cfg else 0.25\n",
    "COPY_MOVE_MIN_AREA_FRAC = float(cfg.get(\"copy_move_min_area_frac\", 0.05)) if cfg else 0.05\n",
    "COPY_MOVE_MAX_AREA_FRAC = float(cfg.get(\"copy_move_max_area_frac\", 0.20)) if cfg else 0.20\n",
    "COPY_MOVE_ROTATION_LIMIT = float(cfg.get(\"copy_move_rotation_limit\", 15.0)) if cfg else 15.0\n",
    "\n",
    "scale_range = cfg.get(\"copy_move_scale_range\", [0.9, 1.1]) if cfg else [0.9, 1.1]\n",
    "if isinstance(scale_range, (list, tuple)) and len(scale_range) == 2:\n",
    "    COPY_MOVE_SCALE_RANGE = (float(scale_range[0]), float(scale_range[1]))\n",
    "else:\n",
    "    COPY_MOVE_SCALE_RANGE = (0.9, 1.1)\n",
    "\n",
    "try:\n",
    "    train_aug = get_train_augment(\n",
    "        patch_size=PATCH_SIZE,\n",
    "        copy_move_prob=COPY_MOVE_PROB,\n",
    "        copy_move_min_area_frac=COPY_MOVE_MIN_AREA_FRAC,\n",
    "        copy_move_max_area_frac=COPY_MOVE_MAX_AREA_FRAC,\n",
    "        copy_move_rotation_limit=COPY_MOVE_ROTATION_LIMIT,\n",
    "        copy_move_scale_range=COPY_MOVE_SCALE_RANGE,\n",
    "    )\n",
    "    val_aug = get_val_augment()\n",
    "except ImportError as exc:\n",
    "    print(\"albumentations indisponível; desativando augmentations de treino. Motivo:\", repr(exc))\n",
    "    train_aug = None\n",
    "    val_aug = None\n",
    "\n",
    "def make_loaders(train_samples_fold, val_samples_fold, *, train_aug, val_aug):\n",
    "    train_ds = PatchDataset(\n",
    "        train_samples_fold,\n",
    "        patch_size=PATCH_SIZE,\n",
    "        train=True,\n",
    "        augment=train_aug,\n",
    "        positive_prob=POSITIVE_PROB,\n",
    "        min_pos_pixels=MIN_POS_PIXELS,\n",
    "        max_tries=MAX_TRIES,\n",
    "        seed=SEED,\n",
    "    )\n",
    "    val_ds = PatchDataset(\n",
    "        val_samples_fold,\n",
    "        patch_size=PATCH_SIZE,\n",
    "        train=False,\n",
    "        augment=val_aug,\n",
    "        seed=SEED,\n",
    "    )\n",
    "\n",
    "    weights = [POS_SAMPLE_WEIGHT if s.is_authentic is False else 1.0 for s in train_samples_fold]\n",
    "    sampler = WeightedRandomSampler(weights, num_samples=len(train_samples_fold), replacement=True)\n",
    "\n",
    "    train_loader_fold = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        sampler=sampler,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=DEVICE.startswith(\"cuda\"),\n",
    "    )\n",
    "    val_loader_fold = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        pin_memory=DEVICE.startswith(\"cuda\"),\n",
    "    )\n",
    "    return train_loader_fold, val_loader_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee779c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 8 — Modelo (SMP FPN+ConvNeXt se disponível; fallback: torchvision DeepLabV3)\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def build_fallback_deeplab(pretrained: bool = True) -> nn.Module:\n",
    "    from torchvision.models.segmentation import DeepLabV3_ResNet50_Weights, deeplabv3_resnet50\n",
    "\n",
    "    weights = DeepLabV3_ResNet50_Weights.DEFAULT if pretrained else None\n",
    "    base = deeplabv3_resnet50(weights=weights)\n",
    "    in_ch = int(base.classifier[-1].in_channels)\n",
    "    base.classifier[-1] = nn.Conv2d(in_ch, 1, kernel_size=1)\n",
    "    base.aux_classifier = None\n",
    "\n",
    "    class Wrapper(nn.Module):\n",
    "        def __init__(self, model: nn.Module) -> None:\n",
    "            super().__init__()\n",
    "            self.model = model\n",
    "\n",
    "        def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "            out = self.model(x)\n",
    "            if isinstance(out, dict):\n",
    "                return out[\"out\"]\n",
    "            return out\n",
    "\n",
    "    return Wrapper(base)\n",
    "\n",
    "\n",
    "def build_model_auto() -> nn.Module:\n",
    "    encoder_name = cfg.get(\"encoder_name\", \"convnext_tiny\") if cfg else \"convnext_tiny\"\n",
    "    encoder_weights = cfg.get(\"encoder_weights\", \"imagenet\") if cfg else \"imagenet\"\n",
    "    if encoder_weights == \"\":\n",
    "        encoder_weights = None\n",
    "    try:\n",
    "        from forgeryseg.models.fpn_convnext import build_model as build_fpn\n",
    "\n",
    "        print(\"backend: segmentation_models_pytorch (FPN)\")\n",
    "        try:\n",
    "            return build_fpn(\n",
    "                encoder_name=encoder_name,\n",
    "                encoder_weights=encoder_weights,\n",
    "                in_channels=3,\n",
    "                classes=1,\n",
    "            )\n",
    "        except Exception as exc:\n",
    "            # Em runtime sem internet (ex.: Kaggle submit), baixar pesos pode falhar.\n",
    "            print(\"FPN com pesos falhou; tentando sem pesos. Motivo:\", repr(exc))\n",
    "            return build_fpn(\n",
    "                encoder_name=encoder_name,\n",
    "                encoder_weights=None,\n",
    "                in_channels=3,\n",
    "                classes=1,\n",
    "            )\n",
    "    except Exception as exc:\n",
    "        print(\"backend fallback: torchvision (DeepLabV3) — motivo:\", repr(exc))\n",
    "        try:\n",
    "            return build_fallback_deeplab(pretrained=True)\n",
    "        except Exception as exc2:\n",
    "            print(\"DeepLabV3 com pesos falhou; tentando sem pesos. Motivo:\", repr(exc2))\n",
    "            return build_fallback_deeplab(pretrained=False)\n",
    "\n",
    "\n",
    "print(\"model builder ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d160ba2",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Célula 9 — Loss, otimizador e loop de treino (opcional)\n",
    "\n",
    "LOSS_NAME = (cfg.get(\"loss\", \"bce_dice\") if cfg else \"bce_dice\").lower()\n",
    "LR = float(cfg.get(\"learning_rate\", 1e-4)) if cfg else 1e-4\n",
    "WEIGHT_DECAY = float(cfg.get(\"weight_decay\", 1e-4)) if cfg else 1e-4\n",
    "EPOCHS = int(cfg.get(\"epochs\", 10)) if cfg else 10\n",
    "USE_AMP = bool(cfg.get(\"use_amp\", True)) if cfg else True\n",
    "USE_AMP = USE_AMP and DEVICE.startswith(\"cuda\")\n",
    "\n",
    "fold_dir = OUTPUT_ROOT / \"models\" / f\"fold_{FOLD}\"\n",
    "fold_dir.mkdir(parents=True, exist_ok=True)\n",
    "ckpt_path = fold_dir / \"best.pt\"\n",
    "\n",
    "RUN_TRAIN = False  # mude para True para treinar aqui\n",
    "TRAIN_FOLDS = [FOLD]  # para CV, use: list(range(N_FOLDS))\n",
    "\n",
    "if RUN_TRAIN:\n",
    "    for fold_id in TRAIN_FOLDS:\n",
    "        train_idx, val_idx = folds[int(fold_id)]\n",
    "        train_samples_fold = [train_samples[int(i)] for i in train_idx]\n",
    "        val_samples_fold = [train_samples[int(i)] for i in val_idx]\n",
    "        train_loader_fold, val_loader_fold = make_loaders(\n",
    "            train_samples_fold,\n",
    "            val_samples_fold,\n",
    "            train_aug=train_aug,\n",
    "            val_aug=val_aug,\n",
    "        )\n",
    "\n",
    "        fold_dir = OUTPUT_ROOT / \"models\" / f\"fold_{int(fold_id)}\"\n",
    "        fold_dir.mkdir(parents=True, exist_ok=True)\n",
    "        ckpt_path = fold_dir / \"best.pt\"\n",
    "\n",
    "        model = build_model_auto().to(DEVICE)\n",
    "        if LOSS_NAME == \"bce_tversky\":\n",
    "            criterion = BCETverskyLoss(\n",
    "                alpha=float(cfg.get(\"tversky_alpha\", 0.7)) if cfg else 0.7,\n",
    "                beta=float(cfg.get(\"tversky_beta\", 0.3)) if cfg else 0.3,\n",
    "                tversky_weight=float(cfg.get(\"tversky_weight\", 1.0)) if cfg else 1.0,\n",
    "            )\n",
    "        else:\n",
    "            criterion = BCEDiceLoss(dice_weight=float(cfg.get(\"dice_weight\", 1.0)) if cfg else 1.0)\n",
    "\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "        best_loss = float(\"inf\")\n",
    "        for epoch in range(1, EPOCHS + 1):\n",
    "            train_stats = train_one_epoch(model, train_loader_fold, criterion, optimizer, DEVICE, use_amp=USE_AMP)\n",
    "            val_stats, val_dice = validate(model, val_loader_fold, criterion, DEVICE)\n",
    "            print(\n",
    "                f\"fold {int(fold_id)} epoch {epoch:02d}/{EPOCHS} \"\n",
    "                f\"train_loss={train_stats.loss:.4f} val_loss={val_stats.loss:.4f} val_dice={val_dice:.4f}\"\n",
    "            )\n",
    "\n",
    "            if val_stats.loss < best_loss:\n",
    "                best_loss = val_stats.loss\n",
    "                torch.save(\n",
    "                    {\n",
    "                        \"model_state\": model.state_dict(),\n",
    "                        \"epoch\": epoch,\n",
    "                        \"val_loss\": val_stats.loss,\n",
    "                        \"config\": cfg,\n",
    "                    },\n",
    "                    ckpt_path,\n",
    "                )\n",
    "        print(\"saved:\", ckpt_path)\n",
    "\n",
    "        del model, optimizer\n",
    "        if DEVICE.startswith(\"cuda\"):\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "print(\"checkpoint exists:\", ckpt_path.exists(), str(ckpt_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2603a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 10 — Carregar checkpoint (necessário para inferência/submissão)\n",
    "\n",
    "def _load_checkpoint(path: Path) -> tuple[dict, dict]:\n",
    "    ckpt = torch.load(path, map_location=\"cpu\")\n",
    "    if isinstance(ckpt, dict) and \"model_state\" in ckpt:\n",
    "        return ckpt[\"model_state\"], ckpt.get(\"config\", {})\n",
    "    return ckpt, {}\n",
    "\n",
    "\n",
    "def _ckpt_path_for_fold(fold: int) -> Path:\n",
    "    return (OUTPUT_ROOT / \"models\" / f\"fold_{fold}\") / \"best.pt\"\n",
    "\n",
    "\n",
    "USE_ENSEMBLE = True\n",
    "INFER_FOLDS = list(range(N_FOLDS)) if USE_ENSEMBLE else [FOLD]\n",
    "\n",
    "models: list[nn.Module] = []\n",
    "loaded_folds: list[int] = []\n",
    "missing_folds: list[int] = []\n",
    "\n",
    "for fold_id in INFER_FOLDS:\n",
    "    fold_ckpt = _ckpt_path_for_fold(fold_id)\n",
    "    if not fold_ckpt.exists():\n",
    "        missing_folds.append(int(fold_id))\n",
    "        continue\n",
    "\n",
    "    m = build_model_auto()\n",
    "    state, _ = _load_checkpoint(fold_ckpt)\n",
    "    m.load_state_dict(state)\n",
    "    m.to(DEVICE)\n",
    "    m.eval()\n",
    "    models.append(m)\n",
    "    loaded_folds.append(int(fold_id))\n",
    "\n",
    "print(\"loaded folds:\", loaded_folds)\n",
    "if missing_folds:\n",
    "    print(\"missing folds:\", missing_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1223f9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 11 — Pós-processamento (componentes conexos) com fallback se faltar SciPy\n",
    "try:\n",
    "    from forgeryseg.postprocess import extract_components as extract_components_impl\n",
    "\n",
    "    _cc_backend = \"scipy\"\n",
    "except Exception:\n",
    "    extract_components_impl = None\n",
    "    _cc_backend = \"none\"\n",
    "\n",
    "\n",
    "def extract_components_safe(mask: np.ndarray, min_area: int = 0) -> list[np.ndarray]:\n",
    "    if extract_components_impl is not None:\n",
    "        return extract_components_impl(mask, min_area=min_area)\n",
    "\n",
    "    import cv2\n",
    "\n",
    "    m = (np.asarray(mask) > 0).astype(np.uint8)\n",
    "    if m.max() == 0:\n",
    "        return []\n",
    "    num_labels, labels = cv2.connectedComponents(m, connectivity=4)\n",
    "    instances: list[np.ndarray] = []\n",
    "    for idx in range(1, int(num_labels)):\n",
    "        comp = (labels == idx)\n",
    "        if min_area and int(comp.sum()) < int(min_area):\n",
    "            continue\n",
    "        instances.append(comp.astype(np.uint8))\n",
    "    return instances\n",
    "\n",
    "\n",
    "print(\"connected components backend:\", _cc_backend, \"(fallback=opencv)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b0702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 12 — Validação em imagem inteira (oF1) + tuning simples de threshold (opcional)\n",
    "\n",
    "RUN_VAL_FULL = False  # mude para True para validar com oF1 em imagem inteira\n",
    "\n",
    "TILE_SIZE = 1024\n",
    "OVERLAP = 128\n",
    "MAX_SIZE = 0  # se quiser, defina ex.: 2048 para reduzir custo\n",
    "\n",
    "THRESHOLD = 0.5\n",
    "MIN_AREA = 32\n",
    "VAL_LIMIT = 200  # limite para não ficar gigante\n",
    "\n",
    "\n",
    "def predict_prob_ensemble(image: np.ndarray) -> np.ndarray:\n",
    "    if not models:\n",
    "        raise RuntimeError(\"Sem modelos carregados (nenhum checkpoint encontrado em outputs/models/fold_*/best.pt).\")\n",
    "\n",
    "    prob_sum: np.ndarray | None = None\n",
    "    for m in models:\n",
    "        prob = predict_image(m, image, DEVICE, tile_size=TILE_SIZE, overlap=OVERLAP, max_size=MAX_SIZE)\n",
    "        if prob_sum is None:\n",
    "            prob_sum = prob.astype(np.float32, copy=False)\n",
    "        else:\n",
    "            prob_sum += prob.astype(np.float32, copy=False)\n",
    "    return prob_sum / float(len(models))\n",
    "\n",
    "\n",
    "def predict_instances_for_sample(sample, threshold: float, min_area: int) -> list[np.ndarray]:\n",
    "    image = load_image(sample.image_path)\n",
    "    prob = predict_prob_ensemble(image)\n",
    "    bin_mask = binarize(prob, threshold=threshold)\n",
    "    return extract_components_safe(bin_mask, min_area=min_area)\n",
    "\n",
    "\n",
    "def mean_of1(samples, threshold: float, min_area: int, limit: int = 0) -> float | None:\n",
    "    scores: list[float] = []\n",
    "    for i, sample in enumerate(samples):\n",
    "        if limit and i >= limit:\n",
    "            break\n",
    "        gt_instances = load_mask_instances(sample.mask_path) if sample.mask_path else []\n",
    "        pred_instances = predict_instances_for_sample(sample, threshold=threshold, min_area=min_area)\n",
    "        try:\n",
    "            scores.append(float(score_image(gt_instances, pred_instances)))\n",
    "        except Exception as exc:\n",
    "            print(\"metric indisponível (provável falta de scipy):\", repr(exc))\n",
    "            return None\n",
    "    if not scores:\n",
    "        return None\n",
    "    return float(np.mean(scores))\n",
    "\n",
    "\n",
    "if RUN_VAL_FULL and models:\n",
    "    score = mean_of1(val_fold_samples, threshold=THRESHOLD, min_area=MIN_AREA, limit=VAL_LIMIT)\n",
    "    print(\"val mean oF1:\", score)\n",
    "\n",
    "    # grid simples (faixa curta; ajuste conforme custo)\n",
    "    thresholds = [0.3, 0.4, 0.5, 0.6]\n",
    "    min_areas = [0, 16, 32, 64, 128]\n",
    "    best = (None, None, -1.0)\n",
    "    for t in thresholds:\n",
    "        for a in min_areas:\n",
    "            s = mean_of1(val_fold_samples, threshold=t, min_area=a, limit=VAL_LIMIT)\n",
    "            if s is None:\n",
    "                break\n",
    "            print(f\"t={t:.2f} a={a:4d} -> {s:.5f}\")\n",
    "            if s > best[2]:\n",
    "                best = (t, a, s)\n",
    "    print(\"best:\", best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb05d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 13 — Gerar submission.csv (test)\n",
    "\n",
    "SUBMISSION_PATH = Path(\"/kaggle/working/submission.csv\") if is_kaggle() else (OUTPUT_ROOT / \"submission.csv\")\n",
    "\n",
    "RUN_SUBMISSION = True  # deixe True no Kaggle submit\n",
    "\n",
    "if RUN_SUBMISSION:\n",
    "    if not models:\n",
    "        print(\"Sem checkpoint(s) para inferência. Treine e salve em outputs/models/fold_*/best.pt (ou use scripts/).\")\n",
    "    else:\n",
    "        SUBMISSION_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with SUBMISSION_PATH.open(\"w\", newline=\"\") as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=[\"case_id\", \"annotation\"])\n",
    "            writer.writeheader()\n",
    "            for sample in test_samples:\n",
    "                instances = predict_instances_for_sample(sample, threshold=THRESHOLD, min_area=MIN_AREA)\n",
    "                annotation = encode_instances(instances)\n",
    "                writer.writerow({\"case_id\": sample.case_id, \"annotation\": annotation})\n",
    "\n",
    "        print(\"wrote:\", SUBMISSION_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d929e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 14 — Preview do CSV\n",
    "try:\n",
    "    import pandas as pd\n",
    "\n",
    "    from IPython.display import display\n",
    "\n",
    "    if not SUBMISSION_PATH.exists():\n",
    "        print(\"submission ainda não foi gerada:\", SUBMISSION_PATH)\n",
    "    else:\n",
    "        df_sub = pd.read_csv(SUBMISSION_PATH)\n",
    "        display(df_sub.head())\n",
    "        print(\"rows:\", len(df_sub))\n",
    "except Exception as exc:\n",
    "    print(\"preview indisponível:\", repr(exc))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
